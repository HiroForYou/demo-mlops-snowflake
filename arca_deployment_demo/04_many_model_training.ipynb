{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "924756f1-9abd-4f3f-a50e-849aa15dba1f",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "# ARCA Beverage Demo: Many Model Training (MMT)\n",
        "\n",
        "## Overview\n",
        "This notebook demonstrates **parallel model training** using Snowflake ML's Many Model Training (MMT).\n",
        "\n",
        "## Business Challenge (ARCA Real Scenario):\n",
        "- **Before**: Sequential training of 16 models = **23 hours**\n",
        "- **After**: Parallel training with MMT = **~1 hour** (20x faster!)\n",
        "\n",
        "## What We'll Do:\n",
        "1. Train **6 models in parallel** (one per customer segment)\n",
        "2. Test **3 algorithms** per segment (XGBoost, RandomForest, LinearRegression)\n",
        "3. **Auto-select** best model per segment based on RMSE\n",
        "4. **Register** all models in Model Registry\n",
        "\n",
        "## Target Variable:\n",
        "**WEEKLY_SALES_UNITS** - Predict next week's unit sales per customer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cba06fc6-2705-4515-b8e2-498367d76ebd",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "from snowflake.snowpark.context import get_active_session\n",
        "from snowflake.ml.modeling.distributors.many_model import ManyModelTraining\n",
        "from snowflake.ml.registry import Registry\n",
        "from snowflake.ml.model import task\n",
        "from snowflake.ml.model import target_platform\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Use active Snowsight session (no credentials needed)\n",
        "session = get_active_session()\n",
        "\n",
        "# Set context\n",
        "session.sql(\"USE WAREHOUSE ARCA_DEMO_WH\").collect()\n",
        "session.sql(\"USE DATABASE ARCA_BEVERAGE_DEMO\").collect()\n",
        "session.sql(\"USE SCHEMA ML_DATA\").collect()\n",
        "\n",
        "print(f\"Connected to Snowflake\")\n",
        "print(f\"   Database: {session.get_current_database()}\")\n",
        "print(f\"   Schema: {session.get_current_schema()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2e097db-4fa9-469b-8aac-84840275a297",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 1. Setup Model Registry & Staging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62c2c508-c77e-4533-9cc6-a69ee6ce22da",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "session.sql(\"CREATE SCHEMA IF NOT EXISTS ARCA_BEVERAGE_DEMO.MODEL_REGISTRY\").collect()\n",
        "session.sql(\"CREATE STAGE IF NOT EXISTS ARCA_BEVERAGE_DEMO.MODEL_REGISTRY.MMT_MODELS\").collect()\n",
        "\n",
        "registry = Registry(\n",
        "    session=session,\n",
        "    database_name=\"ARCA_BEVERAGE_DEMO\",\n",
        "    schema_name=\"MODEL_REGISTRY\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Model Registry initialized\")\n",
        "print(\"‚úÖ Stage for MMT models created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e1a98b3-1dfa-4a8a-a06e-2da200bdaa87",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 2. Prepare Training Data from Feature Store\n",
        "\n",
        "We'll use the features we created in the Feature Store notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53277fc9-3247-4c8a-a3d7-660e74660f3c",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "training_df = session.table(\"ARCA_BEVERAGE_DEMO.ML_DATA.TRAINING_DATA\")\n",
        "\n",
        "print(f\"\\nüìä Training Data Overview:\")\n",
        "print(f\"   Total records: {training_df.count():,}\")\n",
        "print(f\"   Unique customers: {training_df.select('CUSTOMER_ID').distinct().count():,}\")\n",
        "print(f\"\\n   Columns: {training_df.columns}\")\n",
        "\n",
        "segment_counts = training_df.group_by('SEGMENT').count().sort('SEGMENT')\n",
        "print(\"\\nüìä Records per Segment:\")\n",
        "segment_counts.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49788caa-c917-4df6-8633-ea558de3273c",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 3. Define Training Function\n",
        "\n",
        "This function will be executed **in parallel** for each segment.\n",
        "\n",
        "It tests 3 algorithms and selects the best one based on RMSE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b711967a-05d5-4c9f-a562-7bd2469c3107",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "HYPERPARAMETER_SETS = {\n",
        "    0: {\n",
        "        'XGBoost': {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.1},\n",
        "        'RandomForest': {'n_estimators': 100, 'max_depth': 10},\n",
        "        'LinearRegression': {}\n",
        "    },\n",
        "    1: {\n",
        "        'XGBoost': {'n_estimators': 200, 'max_depth': 2, 'learning_rate': 0.05},\n",
        "        'RandomForest': {'n_estimators': 200, 'max_depth': 6},\n",
        "        'LinearRegression': {}\n",
        "    },\n",
        "    2: {\n",
        "        'XGBoost': {'n_estimators': 50, 'max_depth': 6, 'learning_rate': 0.2},\n",
        "        'RandomForest': {'n_estimators': 50, 'max_depth': 15},\n",
        "        'LinearRegression': {}\n",
        "    }\n",
        "}\n",
        "\n",
        "def train_segment_model(data_connector, context, hyperparameter_set=0):\n",
        "    \"\"\"\n",
        "    Train and select best model for a customer segment.\n",
        "    \n",
        "    This function:\n",
        "    1. Receives data for ONE segment (via MMT partitioning)\n",
        "    2. Tests 3 algorithms: XGBoost, RandomForest, LinearRegression\n",
        "    3. Selects best model based on RMSE\n",
        "    4. Returns the winning model\n",
        "    \n",
        "    Args:\n",
        "        data_connector: Snowflake data connector (provided by MMT)\n",
        "        context: Contains partition_id (segment name)\n",
        "        hyperparameter_set: Which hyperparameter set to use (0, 1, or 2)\n",
        "    \n",
        "    Returns:\n",
        "        Trained model object (best of 3 algorithms)\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    from xgboost import XGBRegressor\n",
        "    from sklearn.ensemble import RandomForestRegressor\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "    import numpy as np\n",
        "    \n",
        "    segment_name = context.partition_id\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"üöÄ Training models for {segment_name} (hyperparameter_set={hyperparameter_set})\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    df = data_connector.to_pandas()\n",
        "    print(f\"üìä Data shape: {df.shape}\")\n",
        "    \n",
        "    feature_cols = [\n",
        "        'CUSTOMER_TOTAL_UNITS_4W',\n",
        "        'WEEKS_WITH_PURCHASE',\n",
        "        'VOLUME_QUARTILE',\n",
        "        'WEEK_OF_YEAR',\n",
        "        'MONTH',\n",
        "        'QUARTER',\n",
        "        'TRANSACTION_COUNT',\n",
        "        'UNIQUE_PRODUCTS_PURCHASED',\n",
        "        'AVG_UNITS_PER_TRANSACTION'\n",
        "    ]\n",
        "    \n",
        "    target_col = 'WEEKLY_SALES_UNITS'\n",
        "    \n",
        "    X = df[feature_cols]\n",
        "    y = df[target_col]\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "    \n",
        "    print(f\"   Training set: {X_train.shape[0]:,} samples\")\n",
        "    print(f\"   Test set: {X_test.shape[0]:,} samples\")\n",
        "    \n",
        "    hp = HYPERPARAMETER_SETS[hyperparameter_set]\n",
        "    \n",
        "    models_to_test = {\n",
        "        'XGBoost': XGBRegressor(\n",
        "            n_estimators=hp['XGBoost']['n_estimators'],\n",
        "            max_depth=hp['XGBoost']['max_depth'],\n",
        "            learning_rate=hp['XGBoost']['learning_rate'],\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        ),\n",
        "        'RandomForest': RandomForestRegressor(\n",
        "            n_estimators=hp['RandomForest']['n_estimators'],\n",
        "            max_depth=hp['RandomForest']['max_depth'],\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        ),\n",
        "        'LinearRegression': LinearRegression()\n",
        "    }\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    for model_name, model in models_to_test.items():\n",
        "        print(f\"\\n   Training {model_name}...\")\n",
        "        \n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        \n",
        "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        \n",
        "        results[model_name] = {\n",
        "            'model': model,\n",
        "            'rmse': rmse,\n",
        "            'mae': mae\n",
        "        }\n",
        "        \n",
        "        print(f\"      RMSE: {rmse:.2f}\")\n",
        "        print(f\"      MAE: {mae:.2f}\")\n",
        "    \n",
        "    best_model_name = min(results, key=lambda k: results[k]['rmse'])\n",
        "    best_model = results[best_model_name]['model']\n",
        "    best_rmse = results[best_model_name]['rmse']\n",
        "    best_mae = results[best_model_name]['mae']\n",
        "    \n",
        "    print(f\"\\nüèÜ WINNER: {best_model_name}\")\n",
        "    print(f\"   RMSE: {best_rmse:.2f}\")\n",
        "    print(f\"   MAE: {best_mae:.2f}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "    \n",
        "    best_model.best_algorithm = best_model_name\n",
        "    best_model.rmse = best_rmse\n",
        "    best_model.mae = best_mae\n",
        "    best_model.segment = segment_name\n",
        "    best_model.training_samples = X_train.shape[0]\n",
        "    \n",
        "    return best_model\n",
        "\n",
        "print(\"‚úÖ Training function defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb839562-ac62-4386-97ab-0d4e0df1f23e",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 4. Execute Many Model Training (MMT)\n",
        "\n",
        "### ‚è±Ô∏è Performance Comparison:\n",
        "- **Sequential Training** (one after another): ~30-45 minutes\n",
        "- **Parallel Training** (MMT): ~5-10 minutes\n",
        "- **Real ARCA Scenario**: 23 hours ‚Üí 1 hour (20x faster!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "741e739c-ac4f-4b2a-b8a6-92cbafbc4198",
      "metadata": {
        "codeCollapsed": false,
        "collapsed": false,
        "language": "python"
      },
      "outputs": [],
      "source": [
        "HYPERPARAMETER_SET = 0  # Choose 0, 1, or 2\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üöÄ STARTING MANY MODEL TRAINING (MMT)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n‚ö° Mode: STANDARD (Hyperparameter Set {HYPERPARAMETER_SET})\")\n",
        "from functools import partial\n",
        "training_func = partial(train_segment_model, hyperparameter_set=HYPERPARAMETER_SET)\n",
        "\n",
        "print(f\"\\nTraining 6 models in PARALLEL (one per segment)\\n\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "trainer = ManyModelTraining(\n",
        "    training_func,\n",
        "    \"ARCA_BEVERAGE_DEMO.MODEL_REGISTRY.MMT_MODELS\"\n",
        ")\n",
        "\n",
        "training_run = trainer.run(\n",
        "    partition_by=\"SEGMENT\",\n",
        "    snowpark_dataframe=training_df,\n",
        "    run_id=f\"arca_weekly_sales_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        ")\n",
        "\n",
        "print(\"\\n‚è≥ Training in progress... Monitoring completion...\\n\")\n",
        "\n",
        "import time as time_module\n",
        "max_wait = 180\n",
        "check_interval = 5\n",
        "elapsed = 0\n",
        "completed = False\n",
        "\n",
        "while elapsed < max_wait:\n",
        "    time_module.sleep(check_interval)\n",
        "    elapsed += check_interval\n",
        "    \n",
        "    try:\n",
        "        done_count = 0\n",
        "        total_count = 0\n",
        "        for partition_id in training_run.partition_details:\n",
        "            total_count += 1\n",
        "            status = training_run.partition_details[partition_id].status\n",
        "            if status.name == 'DONE' or status.name == 'FAILED':\n",
        "                done_count += 1\n",
        "        \n",
        "        print(f\"‚è±Ô∏è  {elapsed}s elapsed - Progress: {done_count}/{total_count} models completed\", end='\\r')\n",
        "        \n",
        "        if done_count == total_count:\n",
        "            print(\"\\n‚úÖ All models completed!\" + \" \"*50)\n",
        "            completed = True\n",
        "            break\n",
        "    except:\n",
        "        print(f\"‚è±Ô∏è  {elapsed}s elapsed - Waiting for status update...\", end='\\r')\n",
        "\n",
        "if not completed:\n",
        "    print(\"\\n‚è±Ô∏è  Timeout reached - Verifying completion via stage...\" + \" \"*30)\n",
        "    stage_files = session.sql(f\"LIST @ARCA_BEVERAGE_DEMO.MODEL_REGISTRY.MMT_MODELS PATTERN='.*{training_run.run_id}.*'\").collect()\n",
        "    if len(stage_files) > 0:\n",
        "        print(f\"‚úÖ Found {len(stage_files)} model files in stage - Training completed successfully!\")\n",
        "        completed = True\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  No model files found - Training may have failed\")\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_minutes = (end_time - start_time) / 60\n",
        "\n",
        "final_status = \"COMPLETED\" if completed else \"UNKNOWN\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"‚úÖ TRAINING COMPLETE! Status: {final_status}\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\n‚è±Ô∏è  Total training time: {elapsed_minutes:.2f} minutes\")\n",
        "print(f\"\\nüìä Performance Improvement:\")\n",
        "sequential_estimate = elapsed_minutes * 6\n",
        "speedup = sequential_estimate / elapsed_minutes if elapsed_minutes > 0 else 6.0\n",
        "print(f\"   Sequential (estimated): {sequential_estimate:.2f} minutes\")\n",
        "print(f\"   Parallel (actual): {elapsed_minutes:.2f} minutes\")\n",
        "print(f\"   Speedup: {speedup:.1f}x faster! üöÄ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed244d9e-c8c3-45e6-b799-282f267a7a1a",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Verificar estado sin interrumpir\n",
        "print(\"Checking training status...\")\n",
        "print(f\"\\nPartition Details:\")\n",
        "for partition_id, details in training_run.partition_details.items():\n",
        "    print(f\"  {partition_id}: {details.status}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b26fa46f-530f-430d-afb9-52c91e33abb4",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 5. Review Training Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5351e1f-d8b9-48e6-bd34-c0a8aab50389",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "print(\"\\nüìä Training Results by Segment:\\n\")\n",
        "\n",
        "for partition_id in training_run.partition_details:\n",
        "    details = training_run.partition_details[partition_id]\n",
        "    \n",
        "    if details.status == \"DONE\":\n",
        "        model = training_run.get_model(partition_id)\n",
        "        \n",
        "        print(f\"\\n{partition_id}:\")\n",
        "        print(f\"   Algorithm: {model.best_algorithm}\")\n",
        "        \n",
        "        # Display RMSE with CV standard deviation if available\n",
        "        if hasattr(model, 'rmse_std'):\n",
        "            print(f\"   CV RMSE: {model.rmse:.2f} (+/- {model.rmse_std:.2f})\")\n",
        "        else:\n",
        "            print(f\"   RMSE: {model.rmse:.2f}\")\n",
        "            \n",
        "        print(f\"   MAE: {model.mae:.2f}\")\n",
        "        print(f\"   Training samples: {model.training_samples:,}\")\n",
        "        \n",
        "        # Display HPO and CV-specific info if available\n",
        "        if hasattr(model, 'hpo_trials'):\n",
        "            print(f\"   HPO Trials: {model.hpo_trials}\")\n",
        "        if hasattr(model, 'cv_folds'):\n",
        "            print(f\"   CV Folds: {model.cv_folds}\")\n",
        "        if hasattr(model, 'best_hyperparameters'):\n",
        "            print(f\"   Best Hyperparameters:\")\n",
        "            for param, value in model.best_hyperparameters.items():\n",
        "                if isinstance(value, float):\n",
        "                    print(f\"      {param}: {value:.4f}\")\n",
        "                else:\n",
        "                    print(f\"      {param}: {value}\")\n",
        "    else:\n",
        "        print(f\"\\n‚ùå {partition_id}: Training failed\")\n",
        "        print(f\"   Status: {details.status}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "253bcfe5-c79f-4f29-8e74-24283c202d20",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 6. Register Models in Model Registry\n",
        "\n",
        "Register each segment's model with metadata and metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b992ba8-0d2a-41f4-9db9-5c02f7433abe",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "print(\"\\nüìù Registering models in Model Registry...\\n\")\n",
        "\n",
        "version_date = datetime.now().strftime('%Y%m%d_%H%M')  # Include hour:minute for uniqueness\n",
        "registered_models = {}\n",
        "\n",
        "for partition_id in training_run.partition_details:\n",
        "    details = training_run.partition_details[partition_id]\n",
        "    \n",
        "    if details.status.name == \"DONE\":\n",
        "        model = training_run.get_model(partition_id)\n",
        "        \n",
        "        model_name = f\"weekly_sales_forecast_{partition_id.lower()}\"\n",
        "        \n",
        "        sample_input = training_df.filter(\n",
        "            training_df['SEGMENT'] == partition_id\n",
        "        ).select([\n",
        "            'CUSTOMER_TOTAL_UNITS_4W',\n",
        "            'WEEKS_WITH_PURCHASE',\n",
        "            'VOLUME_QUARTILE',\n",
        "            'WEEK_OF_YEAR',\n",
        "            'MONTH',\n",
        "            'QUARTER',\n",
        "            'TRANSACTION_COUNT',\n",
        "            'UNIQUE_PRODUCTS_PURCHASED',\n",
        "            'AVG_UNITS_PER_TRANSACTION'\n",
        "        ]).limit(5)\n",
        "        \n",
        "        print(f\"Registering {partition_id}...\")\n",
        "        \n",
        "        mv = registry.log_model(\n",
        "            model,\n",
        "            model_name=model_name,\n",
        "            version_name=f\"v_{version_date}\",\n",
        "            comment=f\"Weekly sales forecast model for {partition_id} - Algorithm: {model.best_algorithm}\",\n",
        "            metrics={\n",
        "                \"rmse\": float(model.rmse),\n",
        "                \"mae\": float(model.mae),\n",
        "                \"training_samples\": int(model.training_samples),\n",
        "                \"algorithm\": model.best_algorithm,\n",
        "                \"segment\": model.segment\n",
        "            },\n",
        "            sample_input_data=sample_input,\n",
        "            task=task.Task.TABULAR_REGRESSION,\n",
        "            target_platforms=[\"WAREHOUSE\"]\n",
        "        )\n",
        "        \n",
        "        registered_models[partition_id] = {\n",
        "            'model_name': model_name,\n",
        "            'version': f\"v_{version_date}\",\n",
        "            'model_version': mv\n",
        "        }\n",
        "        \n",
        "        print(f\"‚úÖ {partition_id}: {model_name} v_{version_date}\")\n",
        "        print(f\"   Algorithm: {model.best_algorithm}, RMSE: {model.rmse:.2f}\")\n",
        "\n",
        "print(f\"\\n‚úÖ All {len(registered_models)} models registered successfully!\")\n",
        "print(\"\\nüí° Models registered for WAREHOUSE and SPCS inference\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bb44c2b-9dc3-4443-8937-8948cfa2b6e5",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 7. Test Quick Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "091e5fee-5866-4290-aca3-d8bfa4104063",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "print(\"\\nüß™ Quick Model Validation Test\\n\")\n",
        "\n",
        "test_segment = 'SEGMENT_1'\n",
        "model_info = registered_models[test_segment]\n",
        "model_name = model_info['model_name']\n",
        "version_name = model_info['version']\n",
        "\n",
        "print(f\"Testing {model_name}@{version_name}...\")\n",
        "\n",
        "model = registry.get_model(model_name)\n",
        "mv = model.version(version_name)\n",
        "\n",
        "sample_data = training_df.select(\n",
        "    'CUSTOMER_TOTAL_UNITS_4W', 'WEEKS_WITH_PURCHASE', 'VOLUME_QUARTILE',\n",
        "    'WEEK_OF_YEAR', 'MONTH', 'QUARTER', 'TRANSACTION_COUNT',\n",
        "    'UNIQUE_PRODUCTS_PURCHASED', 'AVG_UNITS_PER_TRANSACTION'\n",
        ").filter(f\"SEGMENT = '{test_segment}'\").limit(5)\n",
        "\n",
        "predictions = mv.run(sample_data, function_name=\"predict\")\n",
        "print(f\"\\nüìä Sample Predictions:\")\n",
        "print(predictions.to_pandas().to_string(index=False))\n",
        "\n",
        "print(\"\\n‚úÖ Model validation completed!\")\n",
        "\n",
        "print(\"\\nüí° Inference Options:\")\n",
        "print(\"   ‚Ä¢ Warehouse (default): mv.run(data)\")\n",
        "print(\"   ‚Ä¢ SPCS Service: mv.create_service(...) then mv.run(data, service_name='...')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce6c9316-9f53-4a90-94bb-8f25f547cde6",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 8. Train alternative models\n",
        "\n",
        "Train new versions of the models using different hyperparameter configurations. This version will be registered but not aliased, making it available for validation in notebook 05."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8740e136-6810-43d3-a3a1-0458c94f600f",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "### 8a. Hyperparameter Set 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "036f75fc-177d-49cc-83a0-d4167a0d49b8",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üîÑ TRAINING V2 MODELS (Hyperparameter Set 1)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "from functools import partial\n",
        "training_func_v2 = partial(train_segment_model, hyperparameter_set=1)\n",
        "\n",
        "start_time_v2 = time.time()\n",
        "\n",
        "trainer_v2 = ManyModelTraining(\n",
        "    training_func_v2,\n",
        "    \"ARCA_BEVERAGE_DEMO.MODEL_REGISTRY.MMT_MODELS\"\n",
        ")\n",
        "\n",
        "training_run_v2 = trainer_v2.run(\n",
        "    partition_by=\"SEGMENT\",\n",
        "    snowpark_dataframe=training_df,\n",
        "    run_id=f\"arca_weekly_sales_v2_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        ")\n",
        "\n",
        "print(f\"\\n‚è≥ Training V2 models in progress...\")\n",
        "\n",
        "import time as time_module\n",
        "max_wait = 180\n",
        "check_interval = 5\n",
        "elapsed = 0\n",
        "completed_v2 = False\n",
        "\n",
        "while elapsed < max_wait:\n",
        "    time_module.sleep(check_interval)\n",
        "    elapsed += check_interval\n",
        "    \n",
        "    try:\n",
        "        done_count = 0\n",
        "        total_count = 0\n",
        "        for partition_id in training_run_v2.partition_details:\n",
        "            total_count += 1\n",
        "            status = training_run_v2.partition_details[partition_id].status\n",
        "            if status.name == 'DONE' or status.name == 'FAILED':\n",
        "                done_count += 1\n",
        "        \n",
        "        print(f\"‚è±Ô∏è  {elapsed}s elapsed - Progress: {done_count}/{total_count} models completed\", end='\\r')\n",
        "        \n",
        "        if done_count == total_count:\n",
        "            print(\"\\n‚úÖ All V2 models completed!\" + \" \"*50)\n",
        "            completed_v2 = True\n",
        "            break\n",
        "    except:\n",
        "        print(f\"‚è±Ô∏è  {elapsed}s elapsed - Waiting for status update...\", end='\\r')\n",
        "\n",
        "end_time_v2 = time.time()\n",
        "elapsed_minutes_v2 = (end_time_v2 - start_time_v2) / 60\n",
        "print(f\"\\n‚è±Ô∏è  V2 Training time: {elapsed_minutes_v2:.2f} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2056f29-0394-4272-85b8-6b6f04548cbc",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "print(\"\\nüìù Registering V2 models in Model Registry...\\n\")\n",
        "\n",
        "version_date_v2 = datetime.now().strftime('%Y%m%d_%H%M')\n",
        "registered_models_v2 = {}\n",
        "\n",
        "for partition_id in training_run_v2.partition_details:\n",
        "    details = training_run_v2.partition_details[partition_id]\n",
        "    \n",
        "    if details.status.name == \"DONE\":\n",
        "        model = training_run_v2.get_model(partition_id)\n",
        "        model_name = f\"weekly_sales_forecast_{partition_id.lower()}\"\n",
        "        version_name = f\"v_{version_date_v2}\"\n",
        "        \n",
        "        sample_input = training_df.filter(\n",
        "            training_df['SEGMENT'] == partition_id\n",
        "        ).select([\n",
        "            'CUSTOMER_TOTAL_UNITS_4W',\n",
        "            'WEEKS_WITH_PURCHASE',\n",
        "            'VOLUME_QUARTILE',\n",
        "            'WEEK_OF_YEAR',\n",
        "            'MONTH',\n",
        "            'QUARTER',\n",
        "            'TRANSACTION_COUNT',\n",
        "            'UNIQUE_PRODUCTS_PURCHASED',\n",
        "            'AVG_UNITS_PER_TRANSACTION'\n",
        "        ]).limit(5)\n",
        "        \n",
        "        print(f\"Registering {partition_id}...\")\n",
        "        \n",
        "        mv = registry.log_model(\n",
        "            model,\n",
        "            model_name=model_name,\n",
        "            version_name=version_name,\n",
        "            comment=f\"Weekly sales forecast model for {partition_id} - Algorithm: {model.best_algorithm}\",\n",
        "            metrics={\n",
        "                \"rmse\": float(model.rmse),\n",
        "                \"mae\": float(model.mae),\n",
        "                \"training_samples\": int(model.training_samples),\n",
        "                \"algorithm\": model.best_algorithm,\n",
        "                \"segment\": model.segment\n",
        "            },\n",
        "            sample_input_data=sample_input,\n",
        "            task=task.Task.TABULAR_REGRESSION,\n",
        "            target_platforms=[\"WAREHOUSE\"]\n",
        "        )\n",
        "\n",
        "        \n",
        "        registered_models_v2[partition_id] = {\n",
        "            'model_name': model_name,\n",
        "            'version': f\"v_{version_date}\",\n",
        "            'model_version': mv\n",
        "        }\n",
        "        \n",
        "        print(f\"‚úÖ {partition_id}: {model_name} v_{version_date}\")\n",
        "        print(f\"   Algorithm: {model.best_algorithm}, RMSE: {model.rmse:.2f}\")\n",
        "\n",
        "print(f\"\\n‚úÖ All {len(registered_models)} models registered successfully!\")\n",
        "print(\"\\nüí° Models registered for WAREHOUSE and SPCS inference\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0fa0b20-1e4c-454e-82e4-63cc54a9b1f5",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "### 8b. Hyperparameter Set 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44af86dc-5012-4749-96dc-dd6df415cecb",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üîÑ TRAINING V3 MODELS (Hyperparameter Set 2)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "from functools import partial\n",
        "training_func_v3 = partial(train_segment_model, hyperparameter_set=2)\n",
        "\n",
        "start_time_v3 = time.time()\n",
        "\n",
        "trainer_v3 = ManyModelTraining(\n",
        "    training_func_v3,\n",
        "    \"ARCA_BEVERAGE_DEMO.MODEL_REGISTRY.MMT_MODELS\"\n",
        ")\n",
        "\n",
        "training_run_v3 = trainer_v3.run(\n",
        "    partition_by=\"SEGMENT\",\n",
        "    snowpark_dataframe=training_df,\n",
        "    run_id=f\"arca_weekly_sales_v3_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        ")\n",
        "\n",
        "print(f\"\\n‚è≥ Training V3 models in progress...\")\n",
        "\n",
        "import time as time_module\n",
        "max_wait = 180\n",
        "check_interval = 5\n",
        "elapsed = 0\n",
        "completed_v2 = False\n",
        "\n",
        "while elapsed < max_wait:\n",
        "    time_module.sleep(check_interval)\n",
        "    elapsed += check_interval\n",
        "    \n",
        "    try:\n",
        "        done_count = 0\n",
        "        total_count = 0\n",
        "        for partition_id in training_run_v3.partition_details:\n",
        "            total_count += 1\n",
        "            status = training_run_v3.partition_details[partition_id].status\n",
        "            if status.name == 'DONE' or status.name == 'FAILED':\n",
        "                done_count += 1\n",
        "        \n",
        "        print(f\"‚è±Ô∏è  {elapsed}s elapsed - Progress: {done_count}/{total_count} models completed\", end='\\r')\n",
        "        \n",
        "        if done_count == total_count:\n",
        "            print(\"\\n‚úÖ All V3 models completed!\" + \" \"*50)\n",
        "            completed_v3 = True\n",
        "            break\n",
        "    except:\n",
        "        print(f\"‚è±Ô∏è  {elapsed}s elapsed - Waiting for status update...\", end='\\r')\n",
        "\n",
        "end_time_v3 = time.time()\n",
        "elapsed_minutes_v3 = (end_time_v3 - start_time_v3) / 60\n",
        "print(f\"\\n‚è±Ô∏è  V3 Training time: {elapsed_minutes_v3:.2f} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a38da4e-511c-4406-8307-788ee69527d0",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "print(\"\\nüìù Registering V3 models in Model Registry...\\n\")\n",
        "\n",
        "version_date_v3 = datetime.now().strftime('%Y%m%d_%H%M')\n",
        "registered_models_v3 = {}\n",
        "\n",
        "for partition_id in training_run_v3.partition_details:\n",
        "    details = training_run_v3.partition_details[partition_id]\n",
        "    \n",
        "    if details.status.name == \"DONE\":\n",
        "        model = training_run_v3.get_model(partition_id)\n",
        "        model_name = f\"weekly_sales_forecast_{partition_id.lower()}\"\n",
        "        version_name = f\"v_{version_date_v3}\"\n",
        "        \n",
        "        sample_input = training_df.filter(\n",
        "            training_df['SEGMENT'] == partition_id\n",
        "        ).select([\n",
        "            'CUSTOMER_TOTAL_UNITS_4W',\n",
        "            'WEEKS_WITH_PURCHASE',\n",
        "            'VOLUME_QUARTILE',\n",
        "            'WEEK_OF_YEAR',\n",
        "            'MONTH',\n",
        "            'QUARTER',\n",
        "            'TRANSACTION_COUNT',\n",
        "            'UNIQUE_PRODUCTS_PURCHASED',\n",
        "            'AVG_UNITS_PER_TRANSACTION'\n",
        "        ]).limit(5)\n",
        "        \n",
        "        print(f\"Registering {partition_id}...\")\n",
        "        \n",
        "        mv = registry.log_model(\n",
        "            model,\n",
        "            model_name=model_name,\n",
        "            version_name=version_name,\n",
        "            comment=f\"Weekly sales forecast model for {partition_id} - Algorithm: {model.best_algorithm}\",\n",
        "            metrics={\n",
        "                \"rmse\": float(model.rmse),\n",
        "                \"mae\": float(model.mae),\n",
        "                \"training_samples\": int(model.training_samples),\n",
        "                \"algorithm\": model.best_algorithm,\n",
        "                \"segment\": model.segment\n",
        "            },\n",
        "            sample_input_data=sample_input,\n",
        "            task=task.Task.TABULAR_REGRESSION,\n",
        "            target_platforms=[\"WAREHOUSE\"]\n",
        "        )\n",
        "\n",
        "        \n",
        "        registered_models_v3[partition_id] = {\n",
        "            'model_name': model_name,\n",
        "            'version': f\"v_{version_date}\",\n",
        "            'model_version': mv\n",
        "        }\n",
        "        \n",
        "        print(f\"‚úÖ {partition_id}: {model_name} v_{version_date}\")\n",
        "        print(f\"   Algorithm: {model.best_algorithm}, RMSE: {model.rmse:.2f}\")\n",
        "\n",
        "print(f\"\\n‚úÖ All {len(registered_models)} models registered successfully!\")\n",
        "print(\"\\nüí° Models registered for WAREHOUSE and SPCS inference\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
