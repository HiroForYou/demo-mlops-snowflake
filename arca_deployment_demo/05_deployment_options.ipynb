{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0299fef3",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "# ARCA Beverage Demo: Model Deployment Strategies\n",
        "\n",
        "This notebook demonstrates different deployment options for ML models in Snowflake after training with Many Model Training (MMT).\n",
        "\n",
        "**Deployment Options Covered:**\n",
        "1. **Model Registry Verification** - Confirm models and versions exist\n",
        "2. **Model Aliases** - Version management with production/staging aliases\n",
        "3. **Batch Inference** - Scheduled and on-demand predictions using SQL\n",
        "4. **Blue-Green Deployment** - Zero-downtime model updates with traffic shifting\n",
        "\n",
        "**Prerequisites:**\n",
        "- Completed notebook `04_many_model_training.ipynb`\n",
        "- Models registered in Model Registry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61297803",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "from snowflake.snowpark.context import get_active_session\n",
        "from snowflake.ml.registry import Registry\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "session = get_active_session()\n",
        "session.sql(\"USE DATABASE ARCA_BEVERAGE_DEMO\").collect()\n",
        "session.sql(\"USE SCHEMA ML_DATA\").collect()\n",
        "session.sql(\"USE WAREHOUSE ARCA_DEMO_WH\").collect()\n",
        "\n",
        "registry = Registry(\n",
        "    session=session,\n",
        "    database_name=\"ARCA_BEVERAGE_DEMO\",\n",
        "    schema_name=\"MODEL_REGISTRY\"\n",
        ")\n",
        "print(\"‚úÖ Connected to Snowflake and Model Registry\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cd96662",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 1. Verify Model Registry Setup\n",
        "\n",
        "Before working with deployment strategies, let's verify that the models from notebook 04 exist in the registry.\n",
        "\n",
        "Set 'PRODUCTION' alias for V1 models trained in notebook 04."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "134935d8",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "expected_models = [f\"WEEKLY_SALES_FORECAST_SEGMENT_{i}\" for i in range(1, 7)]\n",
        "\n",
        "print(\"üîç Verifying Model Registry Setup\\n\")\n",
        "\n",
        "models_df = session.sql(\"SHOW MODELS IN SCHEMA ARCA_BEVERAGE_DEMO.MODEL_REGISTRY\").collect()\n",
        "existing_models = [row['name'] for row in models_df]\n",
        "\n",
        "missing = [m for m in expected_models if m not in existing_models]\n",
        "if missing:\n",
        "    print(f\"‚ùå Missing models: {missing}\")\n",
        "    print(\"   Please run notebook 04_many_model_training.ipynb first\")\n",
        "else:\n",
        "    print(f\"‚úÖ All {len(expected_models)} expected models found in registry\")\n",
        "    for name in expected_models:\n",
        "        print(f\"   ‚Ä¢ {name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dc7aed2",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "### 1a. Explore Segment 1 Model Versions and Tags\n",
        "\n",
        "Let's examine the model versions and their associated metadata for the Segment 1 forecast model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fa2f26f",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "model_name = \"WEEKLY_SALES_FORECAST_SEGMENT_1\"\n",
        "model = registry.get_model(model_name)\n",
        "\n",
        "print(f\"üì¶ Model: {model_name}\\n\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "versions = model.show_versions()\n",
        "print(f\"\\nüî¢ Versions ({len(versions)} total):\\n\")\n",
        "for _, v in versions.iterrows():\n",
        "    print(f\"   Version: {v['name']}\")\n",
        "    print(f\"   Created: {v['created_on']}\")\n",
        "    print(f\"   Comment: {v.get('comment', 'N/A')}\")\n",
        "    print()\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nüè∑Ô∏è  Aliases:\\n\")\n",
        "for alias_name in ['DEFAULT', 'FIRST', 'LAST']:\n",
        "    try:\n",
        "        alias_version = model.version(alias_name)\n",
        "        print(f\"   {alias_name:12} ‚Üí {alias_version.version_name}\")\n",
        "    except:\n",
        "        print(f\"   {alias_name:12} ‚Üí (not set)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5811f9d2",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 2. Model Aliases for Version Management\n",
        "\n",
        "Model aliases provide a way to manage model versions without changing downstream code. This enables pre-production validation by running candidate models alongside production before promotion.\n",
        "\n",
        "**Our Alias Strategy:**\n",
        "- **CANDIDATE** - Newest version being validated before promotion\n",
        "- **PRODUCTION** - Current live model serving predictions (also set as DEFAULT)\n",
        "- **BACKUP** - Previous production version for quick rollback\n",
        "\n",
        "```\n",
        "Model Lifecycle with Aliases:\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  CANDIDATE  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ PRODUCTION  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   BACKUP    ‚îÇ\n",
        "‚îÇ  (newest)   ‚îÇ    ‚îÇ (2nd newest)‚îÇ    ‚îÇ  (oldest)   ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "   Validation         Serving           Rollback\n",
        "   & Testing          Traffic           Safety\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3a30d94",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "print(\"üè∑Ô∏è  Setting Aliases Based on Version Recency\\n\")\n",
        "\n",
        "for segment_id in range(1, 7):\n",
        "    model_name = f\"WEEKLY_SALES_FORECAST_SEGMENT_{segment_id}\"\n",
        "    model = registry.get_model(model_name)\n",
        "    \n",
        "    versions = model.show_versions().sort_values('created_on', ascending=False)\n",
        "    version_names = versions['name'].tolist()\n",
        "    \n",
        "    for v_name in version_names:\n",
        "        for alias in ['CANDIDATE', 'PRODUCTION', 'BACKUP']:\n",
        "            try:\n",
        "                model.version(v_name).unset_alias(alias)\n",
        "            except:\n",
        "                pass\n",
        "    \n",
        "    alias_mapping = {\n",
        "        'CANDIDATE': version_names[0],   # newest\n",
        "        'PRODUCTION': version_names[1],  # 2nd newest\n",
        "        'BACKUP': version_names[2]       # 3rd newest (oldest)\n",
        "    }\n",
        "    \n",
        "    for alias, version in alias_mapping.items():\n",
        "        model.version(version).set_alias(alias)\n",
        "    \n",
        "    model.default = alias_mapping['PRODUCTION']\n",
        "    \n",
        "    print(f\"‚úÖ {model_name}\")\n",
        "    for alias, version in alias_mapping.items():\n",
        "        print(f\"      {alias:12} ‚Üí {version}\")\n",
        "    print(f\"      {'DEFAULT':12} ‚Üí {alias_mapping['PRODUCTION']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c5b2309",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "print(\"üîç Verify Alias Configuration\\n\")\n",
        "\n",
        "for segment_id in range(1, 7):\n",
        "    model_name = f\"WEEKLY_SALES_FORECAST_SEGMENT_{segment_id}\"\n",
        "    model = registry.get_model(model_name)\n",
        "    versions = model.show_versions()\n",
        "    \n",
        "    print(f\"üì¶ {model_name}\")\n",
        "    print(f\"   {'Version':<25} {'Aliases'}\")\n",
        "    print(\"   \" + \"-\" * 50)\n",
        "    for _, v in versions.iterrows():\n",
        "        aliases = v.get('aliases', '[]')\n",
        "        print(f\"   {v['name']:<25} {aliases}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0218f1a6",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "### 2a. Parallel Model Comparison: Candidate vs Production\n",
        "\n",
        "Compare CANDIDATE and PRODUCTION models on the same live data to validate before promotion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3d94229",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "print(\"üìä Parallel Comparison: CANDIDATE vs PRODUCTION for Segment 1\\n\")\n",
        "\n",
        "model_name = \"WEEKLY_SALES_FORECAST_SEGMENT_1\"\n",
        "model = registry.get_model(model_name)\n",
        "\n",
        "test_data = session.table(\"ARCA_BEVERAGE_DEMO.ML_DATA.TRAINING_DATA\").filter(\n",
        "    \"SEGMENT = 'SEGMENT_1'\"\n",
        ")\n",
        "\n",
        "feature_cols = [\n",
        "    'CUSTOMER_TOTAL_UNITS_4W', 'WEEKS_WITH_PURCHASE', 'VOLUME_QUARTILE',\n",
        "    'WEEK_OF_YEAR', 'MONTH', 'QUARTER', 'TRANSACTION_COUNT',\n",
        "    'UNIQUE_PRODUCTS_PURCHASED', 'AVG_UNITS_PER_TRANSACTION'\n",
        "]\n",
        "\n",
        "eval_df = test_data.select(['WEEKLY_SALES_UNITS'] + feature_cols)\n",
        "features_df = test_data.select(feature_cols)\n",
        "\n",
        "print(f\"Evaluation records: {eval_df.count():,}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3d6efd3",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "from snowflake.snowpark.functions import col, abs as sf_abs, pow as sf_pow, sqrt, mean, lit\n",
        "\n",
        "candidate_mv = model.version('CANDIDATE')\n",
        "production_mv = model.version('PRODUCTION')\n",
        "\n",
        "print(f\"CANDIDATE version:  {candidate_mv.version_name}\")\n",
        "print(f\"PRODUCTION version: {production_mv.version_name}\\n\")\n",
        "\n",
        "candidate_preds = candidate_mv.run(features_df, function_name=\"predict\")\n",
        "production_preds = production_mv.run(features_df, function_name=\"predict\")\n",
        "\n",
        "candidate_pdf = candidate_preds.to_pandas()\n",
        "production_pdf = production_preds.to_pandas()\n",
        "actuals_pdf = eval_df.to_pandas()\n",
        "\n",
        "candidate_pdf['ACTUAL'] = actuals_pdf['WEEKLY_SALES_UNITS']\n",
        "candidate_pdf['MODEL'] = 'CANDIDATE'\n",
        "candidate_pdf = candidate_pdf.rename(columns={'output_feature_0': 'PREDICTION'})\n",
        "\n",
        "production_pdf['ACTUAL'] = actuals_pdf['WEEKLY_SALES_UNITS']\n",
        "production_pdf['MODEL'] = 'PRODUCTION'\n",
        "production_pdf = production_pdf.rename(columns={'output_feature_0': 'PREDICTION'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "059ffbf1",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_metrics(actual, predicted):\n",
        "    mae = np.mean(np.abs(actual - predicted))\n",
        "    rmse = np.sqrt(np.mean((actual - predicted) ** 2))\n",
        "    mape = np.mean(np.abs((actual - predicted) / np.where(actual == 0, 1, actual))) * 100\n",
        "    return {'MAE': mae, 'RMSE': rmse, 'MAPE': mape}\n",
        "\n",
        "candidate_metrics = calculate_metrics(candidate_pdf['ACTUAL'], candidate_pdf['PREDICTION'])\n",
        "production_metrics = calculate_metrics(production_pdf['ACTUAL'], production_pdf['PREDICTION'])\n",
        "\n",
        "print(\"üìà Performance Comparison\\n\")\n",
        "print(f\"{'Metric':<10} {'PRODUCTION':>15} {'CANDIDATE':>15} {'Difference':>15}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for metric in ['MAE', 'RMSE', 'MAPE']:\n",
        "    prod_val = production_metrics[metric]\n",
        "    candidate_val = candidate_metrics[metric]\n",
        "    diff = candidate_val - prod_val\n",
        "    indicator = \"‚¨áÔ∏è\" if diff < 0 else \"‚¨ÜÔ∏è\" if diff > 0 else \"‚û°Ô∏è\"\n",
        "    unit = \"%\" if metric == \"MAPE\" else \"\"\n",
        "    print(f\"{metric:<10} {prod_val:>14.2f}{unit} {candidate_val:>14.2f}{unit} {diff:>+14.2f} {indicator}\")\n",
        "\n",
        "print(\"\\n‚¨áÔ∏è = CANDIDATE is better (lower error)\")\n",
        "print(\"‚¨ÜÔ∏è = PRODUCTION is better (lower error)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9154e63e",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "print(\"üìã Sample Predictions Comparison\\n\")\n",
        "\n",
        "comparison_df = pd.DataFrame({\n",
        "    'ACTUAL': candidate_pdf['ACTUAL'].head(10),\n",
        "    'PRODUCTION': production_pdf['PREDICTION'].head(10),\n",
        "    'CANDIDATE': candidate_pdf['PREDICTION'].head(10)\n",
        "})\n",
        "comparison_df['PROD_ERROR'] = abs(comparison_df['ACTUAL'] - comparison_df['PRODUCTION'])\n",
        "comparison_df['CANDIDATE_ERROR'] = abs(comparison_df['ACTUAL'] - comparison_df['CANDIDATE'])\n",
        "\n",
        "print(comparison_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95e8f330",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "### 2b. Promote Candidate to Production (Alias Approach)\n",
        "\n",
        "After validating CANDIDATE performs well, promote it to PRODUCTION and demote current PRODUCTION to BACKUP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e79e67da",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "print(\"üîÑ Promoting CANDIDATE ‚Üí PRODUCTION ‚Üí BACKUP\\n\")\n",
        "\n",
        "model_name = \"WEEKLY_SALES_FORECAST_SEGMENT_1\"\n",
        "model = registry.get_model(model_name)\n",
        "\n",
        "candidate_version = model.version('CANDIDATE').version_name\n",
        "production_version = model.version('PRODUCTION').version_name\n",
        "backup_version = model.version('BACKUP').version_name\n",
        "\n",
        "print(f\"Before promotion:\")\n",
        "print(f\"   CANDIDATE:  {candidate_version}\")\n",
        "print(f\"   PRODUCTION: {production_version}\")\n",
        "print(f\"   BACKUP:     {backup_version}\\n\")\n",
        "\n",
        "model.version(candidate_version).unset_alias('CANDIDATE')\n",
        "model.version(production_version).unset_alias('PRODUCTION')\n",
        "model.version(backup_version).unset_alias('BACKUP')\n",
        "\n",
        "model.version(candidate_version).set_alias('PRODUCTION')\n",
        "model.version(production_version).set_alias('BACKUP')\n",
        "\n",
        "model.default = candidate_version\n",
        "\n",
        "print(f\"After promotion:\")\n",
        "print(f\"   PRODUCTION: {candidate_version} (was CANDIDATE)\")\n",
        "print(f\"   BACKUP:     {production_version} (was PRODUCTION)\")\n",
        "print(f\"   DEFAULT:    {candidate_version}\")\n",
        "print(f\"\\n‚ö†Ô∏è  Note: CANDIDATE is now unassigned until next model version is trained\")\n",
        "\n",
        "print(\"üîç Verify Promotion\\n\")\n",
        "\n",
        "model = registry.get_model(model_name)\n",
        "versions = model.show_versions()\n",
        "\n",
        "print(f\"{'Version':<25} {'Aliases'}\")\n",
        "print(\"-\" * 50)\n",
        "for _, v in versions.iterrows():\n",
        "    aliases = v.get('aliases', '[]')\n",
        "    print(f\"{v['name']:<25} {aliases}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "873fd2e5",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "### 2c. Segment Promotion Strategy\n",
        "\n",
        "When managing segmented models, consider two approaches:\n",
        "\n",
        "**Synchronized Promotion (Recommended)**\n",
        "- All segments promoted together as a unit\n",
        "- Best when segments are trained together with shared hyperparameters (as in MMT)\n",
        "- Simpler operational model with easier rollback and auditing\n",
        "- One promotion decision applies to all segments\n",
        "\n",
        "**Independent Promotion**\n",
        "- Each segment promoted on its own schedule\n",
        "- Better when segments have different data volumes, drift rates, or tuning needs\n",
        "- More operational complexity but finer-grained control\n",
        "- Risk of configuration drift between segments\n",
        "\n",
        "Since our MMT approach trains all segments together with the same hyperparameters, synchronized promotion is the natural fit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b71c2bc8",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "def promote_all_segments():\n",
        "    \"\"\"Atomically promote CANDIDATE ‚Üí PRODUCTION ‚Üí BACKUP for all segments.\"\"\"\n",
        "    print(\"üîÑ Synchronized Promotion: All Segments\\n\")\n",
        "    \n",
        "    for segment_id in range(1, 7):\n",
        "        model_name = f\"WEEKLY_SALES_FORECAST_SEGMENT_{segment_id}\"\n",
        "        model = registry.get_model(model_name)\n",
        "        \n",
        "        candidate_ver = model.version('CANDIDATE').version_name\n",
        "        prod_ver = model.version('PRODUCTION').version_name\n",
        "        backup_ver = model.version('BACKUP').version_name\n",
        "        \n",
        "        model.version(candidate_ver).unset_alias('CANDIDATE')\n",
        "        model.version(prod_ver).unset_alias('PRODUCTION')\n",
        "        model.version(backup_ver).unset_alias('BACKUP')\n",
        "        \n",
        "        model.version(candidate_ver).set_alias('PRODUCTION')\n",
        "        model.version(prod_ver).set_alias('BACKUP')\n",
        "        model.default = candidate_ver\n",
        "        \n",
        "        print(f\"‚úÖ {model_name}: {candidate_ver} ‚Üí PRODUCTION\")\n",
        "    \n",
        "    print(\"\\n‚úÖ All segments promoted successfully\")\n",
        "\n",
        "print(\"üì¶ Function defined: promote_all_segments()\")\n",
        "print(\"   Promotes CANDIDATE ‚Üí PRODUCTION and PRODUCTION ‚Üí BACKUP for all 6 segments\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a35728cf",
      "metadata": {},
      "source": [
        "### 2d. Rolling Batch Inference (Canary for Warehouse)\n",
        "\n",
        "For batch/warehouse inference, we can implement canary-style validation by routing a percentage of inputs to the CANDIDATE model while the rest use PRODUCTION. This allows validating the new model on real data before full promotion.\n",
        "\n",
        "```\n",
        "Rolling Batch Strategy:\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ              INPUT DATA (100%)                  ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                      ‚îÇ\n",
        "         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "         ‚îÇ HASH(customer_id) % 5   ‚îÇ\n",
        "         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                      ‚îÇ\n",
        "        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "        ‚ñº                           ‚ñº\n",
        "   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "   ‚îÇ   20%   ‚îÇ                 ‚îÇ   80%   ‚îÇ\n",
        "   ‚îÇCANDIDATE‚îÇ                 ‚îÇPRODUCTION‚îÇ\n",
        "   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "This approach ensures:\n",
        "- **Deterministic routing**: Same customer always goes to same model (consistent experience)\n",
        "- **Representative sample**: Hash-based split distributes evenly across customer segments\n",
        "- **Easy comparison**: Can compare predictions/outcomes between the two groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b394daae",
      "metadata": {},
      "outputs": [],
      "source": [
        "def rolling_batch_inference(\n",
        "    model_name: str,\n",
        "    input_table: str,\n",
        "    output_table: str,\n",
        "    candidate_pct: int = 20,\n",
        "    id_column: str = \"CUSTOMER_ID\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Run batch inference with a percentage of records routed to CANDIDATE model.\n",
        "    Uses deterministic hashing so the same customer always gets the same model.\n",
        "    \n",
        "    Args:\n",
        "        model_name: Model name in registry\n",
        "        input_table: Source table with features\n",
        "        output_table: Destination table for predictions\n",
        "        candidate_pct: Percentage of records for CANDIDATE (default 20%)\n",
        "        id_column: Column to hash for deterministic routing\n",
        "    \"\"\"\n",
        "    model = registry.get_model(model_name)\n",
        "    production_mv = model.version('PRODUCTION')\n",
        "    candidate_mv = model.version('CANDIDATE')\n",
        "    \n",
        "    input_df = session.table(input_table)\n",
        "    \n",
        "    hash_mod = 100 // candidate_pct\n",
        "    \n",
        "    candidate_df = input_df.filter(f\"MOD(HASH({id_column}), {hash_mod}) = 0\")\n",
        "    production_df = input_df.filter(f\"MOD(HASH({id_column}), {hash_mod}) != 0\")\n",
        "    \n",
        "    print(f\"üìä Rolling Batch Inference: {candidate_pct}% CANDIDATE / {100-candidate_pct}% PRODUCTION\")\n",
        "    print(f\"   CANDIDATE records: {candidate_df.count():,}\")\n",
        "    print(f\"   PRODUCTION records: {production_df.count():,}\\n\")\n",
        "    \n",
        "    candidate_preds = candidate_mv.run(candidate_df, function_name=\"predict\")\n",
        "    candidate_preds = candidate_preds.with_column(\"MODEL_VERSION\", lit(candidate_mv.version_name))\n",
        "    \n",
        "    production_preds = production_mv.run(production_df, function_name=\"predict\")\n",
        "    production_preds = production_preds.with_column(\"MODEL_VERSION\", lit(production_mv.version_name))\n",
        "    \n",
        "    all_preds = candidate_preds.union_all(production_preds)\n",
        "    all_preds.write.mode(\"overwrite\").save_as_table(output_table)\n",
        "    \n",
        "    print(f\"‚úÖ Predictions written to {output_table}\")\n",
        "    print(f\"   Total records: {all_preds.count():,}\")\n",
        "    \n",
        "    return {\n",
        "        \"candidate_version\": candidate_mv.version_name,\n",
        "        \"production_version\": production_mv.version_name,\n",
        "        \"candidate_count\": candidate_df.count(),\n",
        "        \"production_count\": production_df.count()\n",
        "    }\n",
        "\n",
        "print(\"üì¶ Function defined: rolling_batch_inference(model_name, input_table, output_table, candidate_pct)\")\n",
        "print(\"   Routes percentage of batch to CANDIDATE model for validation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc53598d",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 3. Gateways as Model Endpoints\n",
        "\n",
        "Snowflake Gateways provide stable HTTP endpoints for model inference, enabling production deployment patterns like **blue-green** and **canary** releases:\n",
        "\n",
        "- **Stable URL**: Permanent hostname that persists when underlying services change\n",
        "- **Traffic Splitting**: Route requests to multiple service endpoints by percentage (canary, A/B testing)\n",
        "- **Automatic Failover**: Redirects traffic from unhealthy to healthy endpoints\n",
        "- **Blue-Green Deployment**: Instant cutover between versions by updating gateway targets (zero downtime)\n",
        "\n",
        "```\n",
        "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                    ‚îÇ     GATEWAY     ‚îÇ\n",
        "                    ‚îÇ  (Stable URL)   ‚îÇ\n",
        "                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                             ‚îÇ\n",
        "                             ‚ñº\n",
        "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                    ‚îÇ    SERVICE      ‚îÇ\n",
        "                    ‚îÇ  (Model v1)     ‚îÇ\n",
        "                    ‚îÇ    100%         ‚îÇ\n",
        "                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "First, we'll deploy a model as an inference service, then create a gateway to provide a stable endpoint."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53c8cd0e",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "### 3a. Deploy Model as Inference Service\n",
        "\n",
        "Deploy a model version from the registry as a managed SPCS service with HTTP endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f3b9380",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "model_name = \"WEEKLY_SALES_FORECAST_SEGMENT_2\"\n",
        "compute_pool = \"MLOPS_COMPUTE_POOL\"\n",
        "\n",
        "model = registry.get_model(model_name)\n",
        "mv_production = model.version(\"PRODUCTION\")\n",
        "\n",
        "production_version = mv_production.version_name\n",
        "service_name_production = f\"SEGMENT_2_SVC_{production_version}\".upper().replace(\".\", \"_\")\n",
        "\n",
        "print(f\"üöÄ Deploying {model_name} (PRODUCTION) as inference service...\\n\")\n",
        "\n",
        "mv_production.create_service(\n",
        "    service_name=service_name_production,\n",
        "    service_compute_pool=compute_pool,\n",
        "    ingress_enabled=True\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Service '{service_name_production}' created\")\n",
        "print(f\"   Compute Pool: {compute_pool}\")\n",
        "print(f\"   Model: {model_name}\")\n",
        "print(f\"   Version: {production_version}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e923b0b4",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "print(\"üìã Service Endpoints\\n\")\n",
        "\n",
        "services = mv_production.list_services()\n",
        "print(services)\n",
        "\n",
        "if len(services) > 0:\n",
        "    service_info = services.iloc[0]\n",
        "    inference_endpoint = service_info.get('inference_endpoint', 'N/A')\n",
        "    internal_endpoint = service_info.get('internal_endpoint', 'N/A')\n",
        "    \n",
        "    print(f\"\\nüîó Public Endpoint:   {inference_endpoint}\")\n",
        "    print(f\"   Internal Endpoint: {internal_endpoint}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f68b13c5",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "### 3b. Create Gateway\n",
        "\n",
        "Create a Snowflake Gateway with a stable URL that routes traffic to the inference service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1d49871",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "gateway_name = \"SEGMENT_2_GATEWAY\"\n",
        "db = \"ARCA_BEVERAGE_DEMO\"\n",
        "schema = \"MODEL_REGISTRY\"\n",
        "service_fqn = f\"{db}.{schema}.{service_name_production}\"\n",
        "\n",
        "gateway_sql = f\"\"\"\n",
        "CREATE OR REPLACE GATEWAY {gateway_name}\n",
        "  FROM SPECIFICATION $$\n",
        "    spec:\n",
        "      type: traffic_split\n",
        "      split_type: custom\n",
        "      targets:\n",
        "        - type: endpoint\n",
        "          value: {service_fqn}!inference\n",
        "          weight: 100\n",
        "  $$\n",
        "\"\"\"\n",
        "\n",
        "print(f\"üîß Creating gateway '{gateway_name}'...\\n\")\n",
        "print(f\"SQL:\\n{gateway_sql}\")\n",
        "\n",
        "session.sql(gateway_sql).collect()\n",
        "print(f\"\\n‚úÖ Gateway '{gateway_name}' created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a671b90f",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "print(f\"üîç Gateway Endpoint Details\\n\")\n",
        "print(f\"Gateway: {gateway_name}\")\n",
        "print(f\"Waiting for endpoint provisioning\", end=\"\", flush=True)\n",
        "\n",
        "max_wait_seconds = 300\n",
        "poll_interval = 10\n",
        "elapsed = 0\n",
        "\n",
        "while elapsed < max_wait_seconds:\n",
        "    gateway_info = session.sql(f\"DESC GATEWAY {gateway_name}\").collect()[0]\n",
        "    gateway_endpoint = gateway_info['ingress_url']\n",
        "    \n",
        "    if \"provisioning\" not in gateway_endpoint.lower():\n",
        "        break\n",
        "    \n",
        "    print(\".\", end=\"\", flush=True)\n",
        "    time.sleep(poll_interval)\n",
        "    elapsed += poll_interval\n",
        "\n",
        "print()\n",
        "\n",
        "if \"provisioning\" in gateway_endpoint.lower():\n",
        "    print(f\"‚ö†Ô∏è  Endpoint still provisioning after {max_wait_seconds}s\")\n",
        "    print(f\"   Status: {gateway_endpoint}\")\n",
        "    print(f\"   Run this cell again in a few minutes\")\n",
        "else:\n",
        "    print(f\"\\n‚úÖ Endpoint ready! ({elapsed}s)\")\n",
        "    print(f\"Stable Endpoint URL: https://{gateway_endpoint}/\")\n",
        "    print(f\"\\nMethod endpoints:\")\n",
        "    print(f\"   Predict: https://{gateway_endpoint}/predict\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "651921f2",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "### 3c. Call Service from Notebook\n",
        "\n",
        "When running inside SPCS, use the service's internal endpoint. Get it via `SHOW ENDPOINTS IN SERVICE`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01dfa79c",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "# Get sample data\n",
        "sample_data = session.table(\"ARCA_BEVERAGE_DEMO.ML_DATA.TRAINING_DATA\").filter(\n",
        "    \"SEGMENT = 'SEGMENT_2'\"\n",
        ").limit(5).to_pandas()\n",
        "\n",
        "feature_cols = [\n",
        "    'CUSTOMER_TOTAL_UNITS_4W', 'WEEKS_WITH_PURCHASE', 'VOLUME_QUARTILE',\n",
        "    'WEEK_OF_YEAR', 'MONTH', 'QUARTER', 'TRANSACTION_COUNT',\n",
        "    'UNIQUE_PRODUCTS_PURCHASED', 'AVG_UNITS_PER_TRANSACTION'\n",
        "]\n",
        "\n",
        "features_df = sample_data[feature_cols]\n",
        "\n",
        "# Get service details\n",
        "svc_info = session.sql(f\"DESC SERVICE {db}.{schema}.{service_name_production}\").collect()[0]\n",
        "internal_dns = svc_info['dns_name']\n",
        "\n",
        "print(f\"üîó Internal DNS: {internal_dns}\\n\")\n",
        "\n",
        "endpoint_url = f\"http://{internal_dns}:5000/predict\"\n",
        "\n",
        "# Submit input data to endpoint\n",
        "split_obj = json.loads(features_df.to_json(orient=\"split\"))\n",
        "payload = {\"dataframe_split\": split_obj}\n",
        "\n",
        "headers = {\"Content-Type\": \"application/json\"}\n",
        "\n",
        "print(f\"üöÄ Calling service endpoint: {endpoint_url}\\n\")\n",
        "\n",
        "response = requests.post(endpoint_url, headers=headers, json=payload, timeout=30)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    result = response.json()\n",
        "    predictions = result.get('predictions', result)['data']\n",
        "    \n",
        "    print(\"‚úÖ Predictions:\\n\")\n",
        "    for i, pred in enumerate(predictions[:5]):\n",
        "        pred_val = pred[1]['output_feature_0']\n",
        "        actual = sample_data['WEEKLY_SALES_UNITS'].iloc[i]\n",
        "        print(f\"   Row {i+1}: Predicted={pred_val:.2f}, Actual={actual:.2f}\")\n",
        "else:\n",
        "    print(f\"‚ùå Request failed: HTTP {response.status_code}\")\n",
        "    print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "298218c1",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "### 3d. Multi-Segment Routing with Partitioned Models\n",
        "\n",
        "The example above deploys a single segment model. For a unified endpoint that routes to all segments automatically, use the **partitioned wrapper model** from notebook `04f`:\n",
        "\n",
        "```python\n",
        "# Deploy the partitioned model (handles all 6 segments internally)\n",
        "partitioned_model = registry.get_model(\"WEEKLY_SALES_FORECAST_PARTITIONED\")\n",
        "mv = partitioned_model.version(\"PRODUCTION\")\n",
        "\n",
        "mv.create_service(\n",
        "    service_name=\"WEEKLY_SALES_FORECAST_SVC\",\n",
        "    service_compute_pool=\"MLOPS_COMPUTE_POOL\",\n",
        "    ingress_enabled=True\n",
        ")\n",
        "```\n",
        "\n",
        "The partitioned model uses `@partitioned_api` to automatically route requests based on the `SEGMENT` column in the input data. A single gateway pointing to this service provides one stable endpoint for all segments."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "673b679d",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 4. Traffic Routing Between Model Versions\n",
        "\n",
        "With a gateway in place, we can route inference requests to different model versions. This enables:\n",
        "\n",
        "- **Canary Deployments**: Send a small percentage of traffic to a new version to validate before full rollout\n",
        "- **A/B Testing**: Compare model performance on live traffic\n",
        "- **Gradual Rollouts**: Incrementally shift traffic from old to new versions\n",
        "- **Instant Rollback**: Quickly revert to previous version by adjusting weights\n",
        "\n",
        "```\n",
        "Gateway Traffic Routing:\n",
        "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                    ‚îÇ    GATEWAY      ‚îÇ\n",
        "                    ‚îÇ  (Stable URL)   ‚îÇ\n",
        "                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                             ‚îÇ\n",
        "              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "              ‚îÇ                             ‚îÇ\n",
        "              ‚ñº                             ‚ñº\n",
        "        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "        ‚îÇ Model V1 ‚îÇ                 ‚îÇ Model V2 ‚îÇ\n",
        "        ‚îÇ   90%    ‚îÇ                 ‚îÇ   10%    ‚îÇ\n",
        "        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "         Production                    Canary\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af9b94bc",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "### 4a. Deploy a Second Model Version as Service\n",
        "\n",
        "To enable traffic splitting, deploy a second version of the model as its own service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd0f01aa",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "mv_candidate = model.version(\"CANDIDATE\")\n",
        "candidate_version = mv_candidate.version_name\n",
        "service_name_candidate = f\"SEGMENT_2_SVC_{candidate_version}\".upper().replace(\".\", \"_\")\n",
        "\n",
        "print(f\"üöÄ Deploying {model_name} (CANDIDATE) as canary service...\\n\")\n",
        "\n",
        "mv_candidate.create_service(\n",
        "    service_name=service_name_candidate,\n",
        "    service_compute_pool=compute_pool,\n",
        "    ingress_enabled=True\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Service '{service_name_candidate}' created\")\n",
        "print(f\"   Version: {candidate_version}\")\n",
        "print(f\"\\nüìã Active Services:\")\n",
        "print(f\"   PRODUCTION: {service_name_production} ({production_version})\")\n",
        "print(f\"   CANDIDATE:  {service_name_candidate} ({candidate_version})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aad7a72f",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "### 4b. Configure Traffic Split\n",
        "\n",
        "Use `ALTER GATEWAY` to route traffic between versions. Start with 90% to production and 10% to the canary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bac7fb9",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "service_production_fqn = f\"{db}.{schema}.{service_name_production}\"\n",
        "service_candidate_fqn = f\"{db}.{schema}.{service_name_candidate}\"\n",
        "\n",
        "alter_gateway_sql = f\"\"\"\n",
        "ALTER GATEWAY {gateway_name}\n",
        "FROM SPECIFICATION $$\n",
        "spec:\n",
        "  type: traffic_split\n",
        "  split_type: custom\n",
        "  targets:\n",
        "    - type: endpoint\n",
        "      value: {service_production_fqn}!inference\n",
        "      weight: 90\n",
        "    - type: endpoint\n",
        "      value: {service_candidate_fqn}!inference\n",
        "      weight: 10\n",
        "$$\n",
        "\"\"\"\n",
        "\n",
        "print(f\"üîÑ Configuring traffic split for gateway '{gateway_name}'...\\n\")\n",
        "print(f\"SQL:\\n{alter_gateway_sql}\")\n",
        "\n",
        "session.sql(alter_gateway_sql).collect()\n",
        "\n",
        "print(f\"\\n‚úÖ Gateway updated:\")\n",
        "print(f\"   {service_name_production} (PRODUCTION): 90%\")\n",
        "print(f\"   {service_name_candidate} (CANDIDATE):   10%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6bb3057",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "### 4c. Gradual Traffic Shift\n",
        "\n",
        "After validating the canary, gradually increase its traffic share. Once confident, complete the cutover."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "200e669a",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "def update_traffic_split(gateway: str, production_weight: int, candidate_weight: int):\n",
        "    \"\"\"Update gateway traffic split between production and candidate services.\"\"\"\n",
        "    alter_sql = f\"\"\"\n",
        "    ALTER GATEWAY {gateway}\n",
        "    FROM SPECIFICATION $$\n",
        "    spec:\n",
        "      type: traffic_split\n",
        "      split_type: custom\n",
        "      targets:\n",
        "        - type: endpoint\n",
        "          value: {service_production_fqn}!inference\n",
        "          weight: {production_weight}\n",
        "        - type: endpoint\n",
        "          value: {service_candidate_fqn}!inference\n",
        "          weight: {candidate_weight}\n",
        "    $$\n",
        "    \"\"\"\n",
        "    session.sql(alter_sql).collect()\n",
        "    print(f\"‚úÖ Traffic split updated: PRODUCTION={production_weight}%, CANDIDATE={candidate_weight}%\")\n",
        "\n",
        "print(\"üìà Gradual Traffic Shift Schedule\\n\")\n",
        "\n",
        "print(\"Step 1: Initial canary (90/10)\")\n",
        "update_traffic_split(gateway_name, 90, 10)\n",
        "\n",
        "print(\"\\nStep 2: Increase canary traffic (60/40)\")\n",
        "update_traffic_split(gateway_name, 60, 40)\n",
        "\n",
        "print(\"\\nStep 3: Equal split for A/B comparison (50/50)\")\n",
        "update_traffic_split(gateway_name, 50, 50)\n",
        "\n",
        "print(\"\\nStep 4: Complete cutover to new version (0/100)\")\n",
        "update_traffic_split(gateway_name, 0, 100)\n",
        "\n",
        "print(f\"\\nüéâ Migration complete - all traffic now routed to {service_name_candidate}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50569c3a",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "### 4d. Shadow Deployment (Request Mirroring)\n",
        "\n",
        "Unlike traffic splitting where each request goes to ONE target, shadow deployment sends requests to BOTH services:\n",
        "- **Production** response is returned to the caller\n",
        "- **Shadow** response is logged for comparison but not returned\n",
        "\n",
        "This pattern allows validating a new model version on real traffic without any risk to production responses.\n",
        "\n",
        "```\n",
        "Shadow Deployment Pattern:\n",
        "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                    ‚îÇ     CLIENT      ‚îÇ\n",
        "                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                             ‚îÇ request\n",
        "                             ‚ñº\n",
        "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                    ‚îÇ  SHADOW PROXY   ‚îÇ\n",
        "                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                             ‚îÇ\n",
        "              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "              ‚îÇ (mirror)                    ‚îÇ (mirror)\n",
        "              ‚ñº                             ‚ñº\n",
        "        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "        ‚îÇ Model V1 ‚îÇ                 ‚îÇ Model V2 ‚îÇ\n",
        "        ‚îÇ   100%   ‚îÇ                 ‚îÇ   100%   ‚îÇ\n",
        "        ‚îÇ RETURNED ‚îÇ                 ‚îÇ  LOGGED  ‚îÇ\n",
        "        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "         Production                    Shadow\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e20711ee",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "import concurrent.futures\n",
        "from datetime import datetime\n",
        "\n",
        "def shadow_predict(payload: dict, primary_endpoint: str, shadow_endpoint: str, log_table: str = None):\n",
        "    \"\"\"\n",
        "    Send prediction request to both primary and shadow endpoints.\n",
        "    Returns primary response; logs shadow response for comparison.\n",
        "    \"\"\"\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    \n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
        "        primary_future = executor.submit(\n",
        "            requests.post, primary_endpoint, headers=headers, json=payload, timeout=30\n",
        "        )\n",
        "        shadow_future = executor.submit(\n",
        "            requests.post, shadow_endpoint, headers=headers, json=payload, timeout=30\n",
        "        )\n",
        "        \n",
        "        primary_response = primary_future.result()\n",
        "        shadow_response = shadow_future.result()\n",
        "    \n",
        "    shadow_log = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"primary_status\": primary_response.status_code,\n",
        "        \"shadow_status\": shadow_response.status_code,\n",
        "        \"primary_predictions\": primary_response.json() if primary_response.ok else None,\n",
        "        \"shadow_predictions\": shadow_response.json() if shadow_response.ok else None,\n",
        "    }\n",
        "    \n",
        "    return primary_response, shadow_log\n",
        "\n",
        "svc_production_info = session.sql(f\"DESC SERVICE {service_production_fqn}\").collect()[0]\n",
        "svc_candidate_info = session.sql(f\"DESC SERVICE {service_candidate_fqn}\").collect()[0]\n",
        "\n",
        "endpoint_production = f\"http://{svc_production_info['dns_name']}:5000/predict\"\n",
        "endpoint_candidate = f\"http://{svc_candidate_info['dns_name']}:5000/predict\"\n",
        "\n",
        "print(f\"üîó Primary (PRODUCTION): {endpoint_production}\")\n",
        "print(f\"üîó Shadow  (CANDIDATE):  {endpoint_candidate}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42be476a",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "print(\"üîÑ Shadow Deployment Test\\n\")\n",
        "\n",
        "split_obj = json.loads(features_df.to_json(orient=\"split\"))\n",
        "payload = {\"dataframe_split\": split_obj}\n",
        "\n",
        "primary_resp, shadow_log = shadow_predict(payload, endpoint_production, endpoint_candidate)\n",
        "\n",
        "print(f\"Primary Status: {shadow_log['primary_status']}\")\n",
        "print(f\"Shadow Status:  {shadow_log['shadow_status']}\\n\")\n",
        "\n",
        "if primary_resp.ok and shadow_log['shadow_predictions']:\n",
        "    primary_preds = shadow_log['primary_predictions']['data']\n",
        "    shadow_preds = shadow_log['shadow_predictions']['data']\n",
        "    \n",
        "    print(\"üìä Prediction Comparison (Production vs Candidate):\\n\")\n",
        "    print(f\"{'Row':<5} {'Production':>12} {'Candidate':>12} {'Diff':>10}\")\n",
        "    print(\"-\" * 42)\n",
        "    \n",
        "    for i, (p, s) in enumerate(zip(primary_preds, shadow_preds)):\n",
        "        p_val = p[1]['output_feature_0']\n",
        "        s_val = s[1]['output_feature_0']\n",
        "        diff = s_val - p_val\n",
        "        print(f\"{i+1:<5} {p_val:>12.2f} {s_val:>12.2f} {diff:>+10.2f}\")\n",
        "    \n",
        "    print(\"\\n‚úÖ Shadow deployment working - both models received 100% of requests\")\n",
        "    print(\"   Production response returned to caller; Candidate logged for analysis\")\n",
        "else:\n",
        "    print(f\"‚ùå Error in shadow deployment test\")\n",
        "    print(f\"   Primary: {primary_resp.text if not primary_resp.ok else 'OK'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b127eb7",
      "metadata": {},
      "source": [
        "### 4e. Promote Candidate to Production (Gateway Approach)\n",
        "\n",
        "Unlike model aliases which provide instant version switching for warehouse inference, gateway-based endpoints require explicit service management. The promotion workflow:\n",
        "\n",
        "1. **Route 100% traffic to CANDIDATE service** (instant, zero downtime)\n",
        "2. **Update model aliases** to match (for consistency across inference methods)\n",
        "3. **Retire old service** (optional cleanup)\n",
        "\n",
        "```\n",
        "Before Promotion:\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ      GATEWAY       ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ SVC_V_20250210 (PRODUCTION) 0%  ‚îÇ\n",
        "‚îÇ  (Stable URL)      ‚îÇ     ‚îÇ SVC_V_20250211 (CANDIDATE) 100% ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "After Promotion:\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ      GATEWAY       ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ SVC_V_20250211 (PRODUCTION) 100%‚îÇ\n",
        "‚îÇ  (Stable URL)      ‚îÇ     ‚îÇ SVC_V_20250210 (BACKUP)     0%  ‚îÇ ‚Üê can be retired\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "183f240c",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üöÄ Promoting CANDIDATE to PRODUCTION (Gateway Approach)\\n\")\n",
        "\n",
        "promote_gateway_sql = f\"\"\"\n",
        "ALTER GATEWAY {gateway_name}\n",
        "FROM SPECIFICATION $$\n",
        "spec:\n",
        "  type: traffic_split\n",
        "  split_type: custom\n",
        "  targets:\n",
        "    - type: endpoint\n",
        "      value: {service_candidate_fqn}!inference\n",
        "      weight: 100\n",
        "$$\n",
        "\"\"\"\n",
        "\n",
        "print(\"Step 1: Route 100% traffic to CANDIDATE service\")\n",
        "session.sql(promote_gateway_sql).collect()\n",
        "print(f\"‚úÖ Gateway now routes to: {service_name_candidate}\\n\")\n",
        "\n",
        "print(\"Step 2: Update model aliases for consistency\")\n",
        "model = registry.get_model(model_name)\n",
        "\n",
        "old_production_ver = model.version('PRODUCTION').version_name\n",
        "old_backup_ver = model.version('BACKUP').version_name\n",
        "\n",
        "model.version(candidate_version).unset_alias('CANDIDATE')\n",
        "model.version(old_production_ver).unset_alias('PRODUCTION')\n",
        "model.version(old_backup_ver).unset_alias('BACKUP')\n",
        "\n",
        "model.version(candidate_version).set_alias('PRODUCTION')\n",
        "model.version(old_production_ver).set_alias('BACKUP')\n",
        "model.default = candidate_version\n",
        "\n",
        "print(f\"‚úÖ Aliases updated:\")\n",
        "print(f\"   PRODUCTION: {candidate_version} (was CANDIDATE)\")\n",
        "print(f\"   BACKUP:     {old_production_ver} (was PRODUCTION)\")\n",
        "print(f\"   CANDIDATE:  unassigned (awaiting next version)\\n\")\n",
        "\n",
        "print(\"üìã Current State:\")\n",
        "print(f\"   Gateway '{gateway_name}' ‚Üí {service_name_candidate} (100%)\")\n",
        "print(f\"   Model '{model_name}' PRODUCTION alias ‚Üí {candidate_version}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25fc9619",
      "metadata": {},
      "source": [
        "### 4f. Service Inventory and Retirement\n",
        "\n",
        "After promotion, old services remain running and incur compute costs. Review active services and retire those no longer needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d990dd49",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üìã Active Services Inventory\\n\")\n",
        "\n",
        "services_df = session.sql(f\"\"\"\n",
        "    SHOW SERVICES LIKE 'SEGMENT_%_SVC_%' IN COMPUTE POOL {compute_pool}\n",
        "\"\"\").collect()\n",
        "\n",
        "print(f\"{'Service Name':<35} {'Status':<10} {'Instances':<12} {'Pool'}\")\n",
        "print(\"-\" * 85)\n",
        "for row in services_df:\n",
        "    if row['is_job'] == 'false':\n",
        "        instances = f\"{row['current_instances']}/{row['target_instances']}\"\n",
        "        print(f\"{row['name']:<35} {row['status']:<10} {instances:<12} {row['compute_pool']}\")\n",
        "\n",
        "gateway_desc = session.sql(f\"DESC GATEWAY {gateway_name}\").collect()[0]\n",
        "gateway_spec = gateway_desc['spec']\n",
        "\n",
        "print(f\"\\nüîó Gateway '{gateway_name}' configuration:\")\n",
        "print(gateway_spec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bc10381",
      "metadata": {},
      "outputs": [],
      "source": [
        "def retire_service(service_fqn: str, force: bool = False):\n",
        "    \"\"\"\n",
        "    Retire a service that is no longer receiving traffic.\n",
        "    Checks that service is not actively targeted by gateway before dropping.\n",
        "    \"\"\"\n",
        "    gateway_desc = session.sql(f\"DESC GATEWAY {gateway_name}\").collect()[0]\n",
        "    targets_str = str(gateway_desc.get('targets', ''))\n",
        "    \n",
        "    service_short = service_fqn.split('.')[-1]\n",
        "    if service_short.lower() in targets_str.lower() and not force:\n",
        "        print(f\"‚ö†Ô∏è  Cannot retire {service_short} - still targeted by gateway\")\n",
        "        print(f\"   Use force=True to override (will cause gateway errors)\")\n",
        "        return False\n",
        "    \n",
        "    print(f\"üóëÔ∏è  Retiring service: {service_fqn}\")\n",
        "    session.sql(f\"DROP SERVICE IF EXISTS {service_fqn}\").collect()\n",
        "    print(f\"‚úÖ Service dropped\")\n",
        "    return True\n",
        "\n",
        "print(\"üì¶ Service Retirement Function Defined\\n\")\n",
        "print(\"Usage:\")\n",
        "print(f\"   retire_service('{service_production_fqn}')  # Retire old production\")\n",
        "print(f\"\\n‚ö†Ô∏è  Only retire services NOT targeted by the gateway\")\n",
        "print(f\"   Old production service: {service_name_production}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35f7d538",
      "metadata": {},
      "source": [
        "### 4g. Considerations for Partitioned Models (MMT)\n",
        "\n",
        "When working with Many Model Training (MMT) partitioned models, the gateway architecture differs:\n",
        "\n",
        "| Aspect | Single Model | Partitioned Model (MMT) |\n",
        "|--------|--------------|-------------------------|\n",
        "| **Model Count** | 1 model, multiple versions | N models (one per partition), each with versions |\n",
        "| **Service Strategy** | One service per version | One service per partition OR single partitioned service |\n",
        "| **Gateway Routing** | Version-based (V1 vs V2) | Segment-based (route by partition key) |\n",
        "| **Promotion** | Promote single service | Coordinate promotion across all partitions |\n",
        "\n",
        "**Partitioned Model Options:**\n",
        "\n",
        "1. **Single Partitioned Service** (Recommended): Deploy all segment models as one partitioned inference service. Gateway routes all traffic; service routes internally by partition key.\n",
        "\n",
        "2. **Per-Segment Gateways**: Each segment gets its own gateway + services. Client determines which gateway to call based on segment. More complex but allows independent segment promotion.\n",
        "\n",
        "3. **Unified Gateway with Segment Routing**: Single gateway with custom routing logic that directs to segment-specific services based on request payload.\n",
        "\n",
        "For the ARCA demo with 6 segments, Option 1 (partitioned service) is most efficient - it handles partition routing automatically based on the segment column in the input data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "874d542a",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üîÑ Promotion Workflow Comparison\\n\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"WAREHOUSE INFERENCE (Aliases)\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "1. Validate CANDIDATE on test data\n",
        "2. model.version(candidate).set_alias('PRODUCTION')\n",
        "3. Done - next call to model.version('PRODUCTION').run() uses new version\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"REAL-TIME INFERENCE (Gateway + Services)\")  \n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "1. Deploy CANDIDATE as new service: mv.create_service(...)\n",
        "2. Add to gateway with low traffic: ALTER GATEWAY ... weight: 10\n",
        "3. Validate via canary/shadow testing\n",
        "4. Shift traffic: ALTER GATEWAY ... weight: 100\n",
        "5. Update aliases for consistency (optional)\n",
        "6. Retire old service: DROP SERVICE ... (cost savings)\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Key Difference: Aliases provide instant switching for warehouse\")\n",
        "print(\"inference. Gateway approach requires service lifecycle management\")\n",
        "print(\"but enables zero-downtime deployments and instant rollback.\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0acc297",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 5. Summary\n",
        "\n",
        "This notebook demonstrated deployment strategies for ML models in Snowflake, from simple alias-based version management to production-grade gateway routing.\n",
        "\n",
        "### Deployment Options Covered\n",
        "\n",
        "| Section | Approach | Use Case | Key Benefit |\n",
        "|---------|----------|----------|-------------|\n",
        "| **2. Model Aliases** | CANDIDATE/PRODUCTION/BACKUP | Warehouse inference, version control | Instant switching, zero config |\n",
        "| **3. Gateways** | Stable HTTP endpoints | Real-time inference APIs | Permanent URL survives service changes |\n",
        "| **4. Traffic Routing** | Weighted splits (90/10 ‚Üí 0/100) | Canary releases, A/B testing | Gradual rollout, instant rollback |\n",
        "| **4. Shadow Deployment** | Request mirroring | Validate new models on live traffic | Zero production risk |\n",
        "| **4. Promotion** | Gateway target swap + alias sync | Production cutover | Zero downtime, consistent state |\n",
        "\n",
        "### Inference Method Comparison\n",
        "\n",
        "| Method | Latency | Scaling | Best For |\n",
        "|--------|---------|---------|----------|\n",
        "| **Warehouse** (`mv.run()`) | Seconds | Auto (warehouse) | Batch jobs, ad-hoc analysis |\n",
        "| **Service** (REST API) | Milliseconds | Auto (SPCS) | Real-time apps, external integrations |\n",
        "\n",
        "### Version Promotion Workflows\n",
        "\n",
        "| Approach | Steps | Downtime | Rollback Speed |\n",
        "|----------|-------|----------|----------------|\n",
        "| **Alias-based** (Warehouse) | `set_alias('PRODUCTION')` | None | Instant |\n",
        "| **Gateway-based** (Service) | Deploy ‚Üí Split ‚Üí Shift ‚Üí Retire | None | Instant |\n",
        "\n",
        "### MMT/Partitioned Model Considerations\n",
        "\n",
        "- Single partitioned service handles segment routing automatically\n",
        "- Coordinate promotions across all segments for consistency\n",
        "- Consider per-segment gateways only if independent release cycles needed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebdf1809",
      "metadata": {},
      "source": [
        "## 6. Automated Rollbacks\n",
        "\n",
        "Production ML systems need automated safeguards to detect model degradation and trigger rollbacks without human intervention. This section covers rollback triggers, thresholds, and implementation patterns.\n",
        "\n",
        "> **Note**: Model monitoring and observability are covered in detail in **Notebook 06**. This section focuses on the rollback mechanisms that respond to monitoring signals.\n",
        "\n",
        "### Rollback Triggers\n",
        "\n",
        "| Trigger Type | Description | Metric | Suggested Threshold |\n",
        "|--------------|-------------|--------|---------------------|\n",
        "| **Data Drift** | Input feature distributions shift from training baseline | PSI (Population Stability Index) | PSI > 0.2 (significant drift) |\n",
        "| **Prediction Drift** | Model output distribution shifts unexpectedly | KL Divergence | KL > 0.1 |\n",
        "| **Performance Degradation** | Model accuracy drops vs baseline (requires ground truth) | RMSE increase | > 25% above baseline |\n",
        "\n",
        "**Threshold Guidelines:**\n",
        "- **Data Drift (PSI)**: < 0.1 = no drift, 0.1-0.2 = moderate drift (monitor), > 0.2 = significant drift (rollback)\n",
        "- **Prediction Drift (KL)**: Measures divergence between current and baseline prediction distributions\n",
        "- **Performance (RMSE)**: Compare against baseline established during canary phase; 25% degradation triggers rollback\n",
        "\n",
        "### Best Practices for Rollback Thresholds\n",
        "\n",
        "1. **Baseline during canary**: Establish performance baselines with 10% traffic before full rollout\n",
        "2. **Statistical significance**: Require minimum sample size before triggering (e.g., 1000 predictions)\n",
        "3. **Cooldown periods**: Prevent rollback thrashing with minimum time between actions (e.g., 15 min)\n",
        "4. **Severity tiers**: Define WARNING (alert) vs CRITICAL (auto-rollback) thresholds\n",
        "5. **Ground truth delay**: Performance metrics require actuals; use drift metrics for immediate detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60a318be",
      "metadata": {},
      "outputs": [],
      "source": [
        "ROLLBACK_CONFIG = {\n",
        "    \"data_drift_psi\": 0.2,\n",
        "    \"prediction_drift_kl\": 0.1,\n",
        "    \"performance_rmse_pct_increase\": 0.25,\n",
        "    \"min_samples\": 1000,\n",
        "    \"cooldown_minutes\": 15,\n",
        "}\n",
        "\n",
        "print(\"‚öôÔ∏è Rollback Configuration\\n\")\n",
        "print(f\"   {'Metric':<30} {'Threshold':<15} {'Description'}\")\n",
        "print(\"   \" + \"-\" * 70)\n",
        "print(f\"   {'data_drift_psi':<30} {ROLLBACK_CONFIG['data_drift_psi']:<15} PSI > 0.2 = significant drift\")\n",
        "print(f\"   {'prediction_drift_kl':<30} {ROLLBACK_CONFIG['prediction_drift_kl']:<15} KL divergence from baseline\")\n",
        "print(f\"   {'performance_rmse_pct_increase':<30} {ROLLBACK_CONFIG['performance_rmse_pct_increase']:<15.0%} RMSE increase vs baseline\")\n",
        "print(f\"   {'min_samples':<30} {ROLLBACK_CONFIG['min_samples']:<15} Minimum predictions before eval\")\n",
        "print(f\"   {'cooldown_minutes':<30} {ROLLBACK_CONFIG['cooldown_minutes']:<15} Minutes between rollbacks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1381da34",
      "metadata": {},
      "source": [
        "### 6a. Rollback Functions\n",
        "\n",
        "Two rollback implementations corresponding to the inference methods covered in this notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1886961b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def rollback_alias(model_name: str, reason: str = \"automated\"):\n",
        "    \"\"\"\n",
        "    Rollback for warehouse inference: swap PRODUCTION alias back to BACKUP version.\n",
        "    \n",
        "    Use when: Batch inference jobs, warehouse-based predictions (mv.run())\n",
        "    Speed: Instant - next prediction call uses previous version\n",
        "    \"\"\"\n",
        "    model = registry.get_model(model_name)\n",
        "    \n",
        "    current_production = model.version('PRODUCTION').version_name\n",
        "    backup_version = model.version('BACKUP').version_name\n",
        "    \n",
        "    model.version(current_production).unset_alias('PRODUCTION')\n",
        "    model.version(backup_version).unset_alias('BACKUP')\n",
        "    \n",
        "    model.version(backup_version).set_alias('PRODUCTION')\n",
        "    model.version(current_production).set_alias('BACKUP')\n",
        "    model.default = backup_version\n",
        "    \n",
        "    rollback_log = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"model\": model_name,\n",
        "        \"action\": \"alias_rollback\",\n",
        "        \"from_version\": current_production,\n",
        "        \"to_version\": backup_version,\n",
        "        \"reason\": reason\n",
        "    }\n",
        "    \n",
        "    print(f\"üîÑ ROLLBACK [{model_name}]: {current_production} ‚Üí {backup_version}\")\n",
        "    print(f\"   Reason: {reason}\")\n",
        "    \n",
        "    return rollback_log\n",
        "\n",
        "print(\"üì¶ Function defined: rollback_alias(model_name, reason)\")\n",
        "print(\"   For warehouse inference (mv.run())\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3a8b8a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "def rollback_gateway(gateway_name: str, stable_service_fqn: str, reason: str = \"automated\"):\n",
        "    \"\"\"\n",
        "    Rollback for real-time inference: route 100% traffic to stable service.\n",
        "    \n",
        "    Use when: REST API endpoints, real-time predictions via gateway\n",
        "    Speed: ~1 minute for DNS propagation\n",
        "    \"\"\"\n",
        "    rollback_sql = f\"\"\"\n",
        "    ALTER GATEWAY {gateway_name}\n",
        "    FROM SPECIFICATION $$\n",
        "    spec:\n",
        "      type: traffic_split\n",
        "      split_type: custom\n",
        "      targets:\n",
        "        - type: endpoint\n",
        "          value: {stable_service_fqn}!inference\n",
        "          weight: 100\n",
        "    $$\n",
        "    \"\"\"\n",
        "    \n",
        "    session.sql(rollback_sql).collect()\n",
        "    \n",
        "    rollback_log = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"gateway\": gateway_name,\n",
        "        \"action\": \"gateway_rollback\",\n",
        "        \"routed_to\": stable_service_fqn,\n",
        "        \"reason\": reason\n",
        "    }\n",
        "    \n",
        "    print(f\"üîÑ ROLLBACK [{gateway_name}]: 100% ‚Üí {stable_service_fqn.split('.')[-1]}\")\n",
        "    print(f\"   Reason: {reason}\")\n",
        "    \n",
        "    return rollback_log\n",
        "\n",
        "print(\"üì¶ Function defined: rollback_gateway(gateway_name, stable_service_fqn, reason)\")\n",
        "print(\"   For real-time inference (REST API)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc84c2da",
      "metadata": {},
      "source": [
        "### 6b. Automated Rollback Check\n",
        "\n",
        "This function demonstrates how a monitoring system would evaluate metrics and trigger rollback. In production, this would be called by a scheduled task or event-driven trigger from the observability system (see Notebook 06)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21ffd667",
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_and_rollback(\n",
        "    model_name: str,\n",
        "    gateway_name: str,\n",
        "    stable_service_fqn: str,\n",
        "    metrics: dict,\n",
        "    config: dict = ROLLBACK_CONFIG\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Evaluate model performance metrics against thresholds and trigger rollback if needed.\n",
        "    \n",
        "    Args:\n",
        "        model_name: Model to rollback (for alias method)\n",
        "        gateway_name: Gateway to rollback (for service method)\n",
        "        stable_service_fqn: Service to route traffic to on rollback\n",
        "        metrics: Current metrics dict with keys: data_drift_psi, prediction_drift_kl,\n",
        "                 performance_rmse_pct_increase, sample_count\n",
        "        config: Threshold configuration\n",
        "    \n",
        "    Returns:\n",
        "        Status dict with action taken and reason\n",
        "    \"\"\"\n",
        "    if metrics.get('sample_count', 0) < config['min_samples']:\n",
        "        return {\"action\": \"skip\", \"reason\": f\"Insufficient samples ({metrics.get('sample_count', 0)})\"}\n",
        "    \n",
        "    triggers = []\n",
        "    \n",
        "    if metrics.get('data_drift_psi', 0) > config['data_drift_psi']:\n",
        "        triggers.append(f\"data_drift_psi={metrics['data_drift_psi']:.2f} > {config['data_drift_psi']}\")\n",
        "    \n",
        "    if metrics.get('prediction_drift_kl', 0) > config['prediction_drift_kl']:\n",
        "        triggers.append(f\"prediction_drift_kl={metrics['prediction_drift_kl']:.3f} > {config['prediction_drift_kl']}\")\n",
        "    \n",
        "    if metrics.get('performance_rmse_pct_increase', 0) > config['performance_rmse_pct_increase']:\n",
        "        triggers.append(f\"rmse_increase={metrics['performance_rmse_pct_increase']:.0%} > {config['performance_rmse_pct_increase']:.0%}\")\n",
        "    \n",
        "    if not triggers:\n",
        "        return {\"action\": \"none\", \"reason\": \"All metrics within thresholds\"}\n",
        "    \n",
        "    reason = \"; \".join(triggers)\n",
        "    \n",
        "    alias_log = rollback_alias(model_name, reason)\n",
        "    gateway_log = rollback_gateway(gateway_name, stable_service_fqn, reason)\n",
        "    \n",
        "    return {\n",
        "        \"action\": \"rollback\",\n",
        "        \"reason\": reason,\n",
        "        \"alias_rollback\": alias_log,\n",
        "        \"gateway_rollback\": gateway_log\n",
        "    }\n",
        "\n",
        "print(\"üì¶ Function defined: check_and_rollback(...)\")\n",
        "print(\"   Evaluates model performance metrics and triggers rollback if thresholds exceeded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b80a570",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üß™ Simulated Rollback Scenarios\\n\")\n",
        "\n",
        "scenarios = [\n",
        "    {\"name\": \"Healthy\", \"data_drift_psi\": 0.05, \"prediction_drift_kl\": 0.03, \"performance_rmse_pct_increase\": 0.05, \"sample_count\": 5000},\n",
        "    {\"name\": \"Data Drift\", \"data_drift_psi\": 0.35, \"prediction_drift_kl\": 0.08, \"performance_rmse_pct_increase\": 0.10, \"sample_count\": 5000},\n",
        "    {\"name\": \"Prediction Drift\", \"data_drift_psi\": 0.10, \"prediction_drift_kl\": 0.18, \"performance_rmse_pct_increase\": 0.12, \"sample_count\": 5000},\n",
        "    {\"name\": \"Performance Drop\", \"data_drift_psi\": 0.12, \"prediction_drift_kl\": 0.05, \"performance_rmse_pct_increase\": 0.40, \"sample_count\": 5000},\n",
        "    {\"name\": \"Insufficient Data\", \"data_drift_psi\": 0.50, \"prediction_drift_kl\": 0.25, \"performance_rmse_pct_increase\": 0.60, \"sample_count\": 500},\n",
        "]\n",
        "\n",
        "print(f\"{'Scenario':<20} {'Data Drift':<12} {'Pred Drift':<12} {'RMSE Œî':<10} {'Action':<10}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for s in scenarios:\n",
        "    action = \"SKIP\" if s['sample_count'] < ROLLBACK_CONFIG['min_samples'] else \\\n",
        "             \"ROLLBACK\" if (s['data_drift_psi'] > ROLLBACK_CONFIG['data_drift_psi'] or \n",
        "                           s['prediction_drift_kl'] > ROLLBACK_CONFIG['prediction_drift_kl'] or\n",
        "                           s['performance_rmse_pct_increase'] > ROLLBACK_CONFIG['performance_rmse_pct_increase']) else \"OK\"\n",
        "    \n",
        "    print(f\"{s['name']:<20} {s['data_drift_psi']:<12.2f} {s['prediction_drift_kl']:<12.3f} {s['performance_rmse_pct_increase']:<10.0%} {action:<10}\")\n",
        "\n",
        "print(f\"\\nThresholds: PSI > {ROLLBACK_CONFIG['data_drift_psi']}, KL > {ROLLBACK_CONFIG['prediction_drift_kl']}, RMSE Œî > {ROLLBACK_CONFIG['performance_rmse_pct_increase']:.0%}\")\n",
        "print(\"\\n‚ö†Ô∏è  Note: Actual rollback calls commented out for demonstration\")\n",
        "print(\"   In production, check_and_rollback() would execute the rollback\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78cdf46b",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Notebook 05: Deployment Options - Complete\n",
        "\n",
        "**Sections covered:**\n",
        "1. Model Registry Setup - Verified 6 segment models with multiple versions\n",
        "2. Model Aliases - CANDIDATE ‚Üí PRODUCTION ‚Üí BACKUP lifecycle\n",
        "3. Gateways - Stable endpoints for real-time inference\n",
        "4. Traffic Routing - Canary, shadow deployment, promotion\n",
        "5. Summary - Deployment patterns comparison\n",
        "6. Automated Rollbacks - Triggers, thresholds, rollback functions\n",
        "\n",
        "**Functions defined:**\n",
        "- `rollback_alias()` - Instant version swap for warehouse inference\n",
        "- `rollback_gateway()` - Traffic rerouting for real-time inference\n",
        "- `check_and_rollback()` - Automated threshold evaluation\n",
        "\n",
        "**Next steps:**\n",
        "- ‚Üí **05b**: Batch inference pipelines\n",
        "- ‚Üí **06**: ML Observability and monitoring (rollback triggers)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
