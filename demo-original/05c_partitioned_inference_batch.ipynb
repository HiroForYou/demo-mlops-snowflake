{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "# ARCA Beverage Demo: Partitioned Inference (Batch)\n\n## Overview\nThis notebook demonstrates **batch partitioned inference** using features pre-materialized from the Feature Store.\n\n## Why not query Feature Store directly?\n> For **batch inference**, features are materialized from the Feature Store into an optimized table.\n> This is more efficient than querying the Feature Store for each individual record.\n>\n> The Feature Store remains the **single source of truth** for feature definitions - we used it in Notebook 02 to generate `TRAINING_DATA`.\n>\n> For **real-time inference** (e.g., a customer opens the app), we would query the Feature Store directly.\n\n## What We'll Do:\n1. Load inference data with pre-materialized features\n2. Execute **single inference call** with PARTITION BY SEGMENT\n3. Compare predictions vs actuals\n4. Log results for ML Observability\n\n## Key Message:\n**Single SQL statement ‚Üí 6 models execute in parallel ‚Üí Unified results**",
      "id": "intro"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "from snowflake.snowpark.context import get_active_session\nfrom snowflake.ml.registry import Registry\nfrom snowflake.snowpark import functions as F\nimport pandas as pd\nimport time\n\nsession = get_active_session()\n\nsession.sql(\"USE WAREHOUSE ARCA_DEMO_WH\").collect()\nsession.sql(\"USE DATABASE ARCA_BEVERAGE_DEMO\").collect()\nsession.sql(\"USE SCHEMA ML_DATA\").collect()\n\nregistry = Registry(\n    session=session,\n    database_name=\"ARCA_BEVERAGE_DEMO\",\n    schema_name=\"MODEL_REGISTRY\"\n)\n\nprint(\"‚úÖ Connected to Snowflake\")\nprint(f\"   Database: {session.get_current_database()}\")\nprint(f\"   Schema: {session.get_current_schema()}\")",
      "id": "setup"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 1. Load Inference Data (Pre-materialized Features)\n\nUsing features already materialized from Feature Store into TRAINING_DATA.\nFiltering for inference period (December 2025).",
      "id": "data_header"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "print(\"\\nüìä Loading inference data with pre-materialized features...\\n\")\n\n# Get inference period data - most recent week per customer\n# This ensures 1:1 mapping between input and predictions\ninference_df = session.sql(\"\"\"\n    SELECT \n        t.CUSTOMER_ID,\n        t.WEEK_START_DATE,\n        t.SEGMENT,\n        t.SEGMENT_DESCRIPTION,\n        t.CUSTOMER_TOTAL_UNITS_4W,\n        t.WEEKS_WITH_PURCHASE,\n        t.VOLUME_QUARTILE,\n        t.WEEK_OF_YEAR,\n        t.MONTH,\n        t.QUARTER,\n        t.TRANSACTION_COUNT,\n        t.UNIQUE_PRODUCTS_PURCHASED,\n        t.AVG_UNITS_PER_TRANSACTION,\n        t.WEEKLY_SALES_UNITS AS ACTUAL_WEEKLY_SALES\n    FROM ARCA_BEVERAGE_DEMO.ML_DATA.TRAINING_DATA t\n    WHERE t.WEEK_START_DATE >= DATE('2025-12-01')\n    QUALIFY ROW_NUMBER() OVER (PARTITION BY t.CUSTOMER_ID ORDER BY t.WEEK_START_DATE DESC) = 1\n    ORDER BY t.SEGMENT, t.CUSTOMER_ID\n\"\"\")\n\nprint(f\"‚úÖ Inference data loaded (1 row per customer - most recent week)\")\nprint(f\"   Total records: {inference_df.count():,}\")\nprint(f\"   Unique customers: {inference_df.select('CUSTOMER_ID').distinct().count():,}\")\n\nprint(\"\\nüìä Records per Segment:\")\ninference_df.group_by('SEGMENT').count().sort('SEGMENT').show()\n\nprint(\"\\nüìã Sample data with features:\")\ninference_df.select(\n    'CUSTOMER_ID', 'SEGMENT', 'CUSTOMER_TOTAL_UNITS_4W', \n    'WEEKS_WITH_PURCHASE', 'VOLUME_QUARTILE', 'ACTUAL_WEEKLY_SALES'\n).show(5)",
      "id": "load_data"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 2. Verify Partitioned Model",
      "id": "model_header"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "print(\"\\nüì¶ Verifying partitioned model...\\n\")\n\nmodel_ref = registry.get_model(\"WEEKLY_SALES_FORECAST_PARTITIONED\")\nmodel_version = model_ref.version(\"PRODUCTION\")\n\nprint(\"‚úÖ Model: WEEKLY_SALES_FORECAST_PARTITIONED\")\nprint(f\"   Version: {model_version.version_name}\")\nprint(f\"   Alias: PRODUCTION\")\n\n# Show model functions\nfunctions = session.sql(\"\"\"\n    SHOW FUNCTIONS IN MODEL ARCA_BEVERAGE_DEMO.MODEL_REGISTRY.WEEKLY_SALES_FORECAST_PARTITIONED\n\"\"\").collect()\n\nprint(f\"\\nüìã Available functions:\")\nfor f in functions:\n    print(f\"   - {f['name']}\")",
      "id": "verify_model"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 3. Execute Partitioned Inference (SQL)\n\n**Key syntax:** `TABLE(model!PREDICT(...) OVER (PARTITION BY SEGMENT))`\n\nSnowflake automatically:\n1. Splits data by SEGMENT\n2. Routes each partition to correct sub-model\n3. Executes in parallel\n4. Returns unified results",
      "id": "inference_header"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üöÄ EXECUTING PARTITIONED INFERENCE\")\nprint(\"=\"*80)\n\nprint(\"\\nüìù Preparing inference data...\")\ninference_df.write.mode('overwrite').save_as_table(\n    'ARCA_BEVERAGE_DEMO.ML_DATA.INFERENCE_INPUT_TEMP'\n)\n\nprint(\"\\nüîÆ Running partitioned inference...\\n\")\nprint(\"   Syntax: TABLE(model!PREDICT(...) OVER (PARTITION BY SEGMENT))\")\nprint(\"   This single call routes to 6 different sub-models automatically!\\n\")\n\nstart_time = time.time()\n\npredictions_sql = \"\"\"\nWITH model_predictions AS (\n    SELECT \n        p.CUSTOMER_ID,\n        p.SEGMENT,\n        p.PREDICTED_WEEKLY_SALES\n    FROM ARCA_BEVERAGE_DEMO.ML_DATA.INFERENCE_INPUT_TEMP i,\n        TABLE(\n            ARCA_BEVERAGE_DEMO.MODEL_REGISTRY.WEEKLY_SALES_FORECAST_PARTITIONED!PREDICT(\n                i.CUSTOMER_ID,\n                i.SEGMENT,\n                i.CUSTOMER_TOTAL_UNITS_4W,\n                i.WEEKS_WITH_PURCHASE,\n                i.VOLUME_QUARTILE,\n                i.WEEK_OF_YEAR,\n                i.MONTH,\n                i.QUARTER,\n                i.TRANSACTION_COUNT,\n                i.UNIQUE_PRODUCTS_PURCHASED,\n                i.AVG_UNITS_PER_TRANSACTION::FLOAT\n            ) OVER (PARTITION BY i.SEGMENT)\n        ) p\n)\nSELECT \n    mp.CUSTOMER_ID,\n    mp.SEGMENT,\n    i.WEEK_START_DATE,\n    i.SEGMENT_DESCRIPTION,\n    ROUND(mp.PREDICTED_WEEKLY_SALES, 2) AS PREDICTED_WEEKLY_SALES,\n    i.ACTUAL_WEEKLY_SALES,\n    ROUND(mp.PREDICTED_WEEKLY_SALES - i.ACTUAL_WEEKLY_SALES, 2) AS PREDICTION_ERROR,\n    ROUND(ABS(mp.PREDICTED_WEEKLY_SALES - i.ACTUAL_WEEKLY_SALES), 2) AS ABSOLUTE_ERROR\nFROM model_predictions mp\nJOIN ARCA_BEVERAGE_DEMO.ML_DATA.INFERENCE_INPUT_TEMP i \n    ON mp.CUSTOMER_ID = i.CUSTOMER_ID AND mp.SEGMENT = i.SEGMENT\nORDER BY mp.SEGMENT, mp.CUSTOMER_ID\n\"\"\"\n\npredictions_df = session.sql(predictions_sql)\nprediction_count = predictions_df.count()\ninference_time = time.time() - start_time\n\nprint(f\"‚úÖ Inference complete!\")\nprint(f\"   ‚è±Ô∏è  Time: {inference_time:.2f} seconds\")\nprint(f\"   üìä Predictions: {prediction_count:,}\")\n\nprint(\"\\nüìä Sample Predictions vs Actuals:\")\npredictions_df.show(10)",
      "id": "inference"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 4. Analyze Prediction Performance by Segment",
      "id": "analysis_header"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "print(\"\\nüìä Performance Analysis by Segment\\n\")\n\nperformance_sql = \"\"\"\nWITH model_predictions AS (\n    SELECT \n        p.CUSTOMER_ID,\n        p.SEGMENT,\n        p.PREDICTED_WEEKLY_SALES\n    FROM ARCA_BEVERAGE_DEMO.ML_DATA.INFERENCE_INPUT_TEMP i,\n        TABLE(\n            ARCA_BEVERAGE_DEMO.MODEL_REGISTRY.WEEKLY_SALES_FORECAST_PARTITIONED!PREDICT(\n                i.CUSTOMER_ID, i.SEGMENT,\n                i.CUSTOMER_TOTAL_UNITS_4W, i.WEEKS_WITH_PURCHASE, i.VOLUME_QUARTILE,\n                i.WEEK_OF_YEAR, i.MONTH, i.QUARTER,\n                i.TRANSACTION_COUNT, i.UNIQUE_PRODUCTS_PURCHASED,\n                i.AVG_UNITS_PER_TRANSACTION::FLOAT\n            ) OVER (PARTITION BY i.SEGMENT)\n        ) p\n),\npredictions AS (\n    SELECT \n        mp.SEGMENT,\n        mp.PREDICTED_WEEKLY_SALES,\n        i.ACTUAL_WEEKLY_SALES,\n        mp.PREDICTED_WEEKLY_SALES - i.ACTUAL_WEEKLY_SALES AS ERROR\n    FROM model_predictions mp\n    JOIN ARCA_BEVERAGE_DEMO.ML_DATA.INFERENCE_INPUT_TEMP i \n        ON mp.CUSTOMER_ID = i.CUSTOMER_ID AND mp.SEGMENT = i.SEGMENT\n)\nSELECT\n    SEGMENT,\n    COUNT(*) AS PREDICTIONS,\n    ROUND(AVG(PREDICTED_WEEKLY_SALES), 1) AS AVG_PREDICTED,\n    ROUND(AVG(ACTUAL_WEEKLY_SALES), 1) AS AVG_ACTUAL,\n    ROUND(AVG(ABS(ERROR)), 2) AS MAE,\n    ROUND(SQRT(AVG(POWER(ERROR, 2))), 2) AS RMSE\nFROM predictions\nGROUP BY SEGMENT\nORDER BY SEGMENT\n\"\"\"\n\nprint(\"By Segment:\")\nsession.sql(performance_sql).show()\n\n# Overall performance\noverall_sql = \"\"\"\nWITH model_predictions AS (\n    SELECT \n        p.CUSTOMER_ID,\n        p.SEGMENT,\n        p.PREDICTED_WEEKLY_SALES\n    FROM ARCA_BEVERAGE_DEMO.ML_DATA.INFERENCE_INPUT_TEMP i,\n        TABLE(\n            ARCA_BEVERAGE_DEMO.MODEL_REGISTRY.WEEKLY_SALES_FORECAST_PARTITIONED!PREDICT(\n                i.CUSTOMER_ID, i.SEGMENT,\n                i.CUSTOMER_TOTAL_UNITS_4W, i.WEEKS_WITH_PURCHASE, i.VOLUME_QUARTILE,\n                i.WEEK_OF_YEAR, i.MONTH, i.QUARTER,\n                i.TRANSACTION_COUNT, i.UNIQUE_PRODUCTS_PURCHASED,\n                i.AVG_UNITS_PER_TRANSACTION::FLOAT\n            ) OVER (PARTITION BY i.SEGMENT)\n        ) p\n),\npredictions AS (\n    SELECT \n        mp.PREDICTED_WEEKLY_SALES,\n        i.ACTUAL_WEEKLY_SALES,\n        mp.PREDICTED_WEEKLY_SALES - i.ACTUAL_WEEKLY_SALES AS ERROR\n    FROM model_predictions mp\n    JOIN ARCA_BEVERAGE_DEMO.ML_DATA.INFERENCE_INPUT_TEMP i \n        ON mp.CUSTOMER_ID = i.CUSTOMER_ID AND mp.SEGMENT = i.SEGMENT\n)\nSELECT\n    COUNT(*) AS TOTAL_PREDICTIONS,\n    ROUND(AVG(ABS(ERROR)), 2) AS OVERALL_MAE,\n    ROUND(SQRT(AVG(POWER(ERROR, 2))), 2) AS OVERALL_RMSE,\n    ROUND(AVG(ABS(ERROR) / NULLIF(ACTUAL_WEEKLY_SALES, 0)) * 100, 1) AS MAPE_PCT\nFROM predictions\n\"\"\"\n\nprint(\"\\nOverall Performance:\")\nsession.sql(overall_sql).show()",
      "id": "analysis"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 5. Save Predictions to Inference Logs",
      "id": "save_header"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "print(\"\\nüíæ Saving predictions to inference logs...\\n\")\n\n# Create inference logs table\nsession.sql(\"\"\"\nCREATE TABLE IF NOT EXISTS ARCA_BEVERAGE_DEMO.ML_DATA.INFERENCE_LOGS (\n    CUSTOMER_ID NUMBER,\n    SEGMENT VARCHAR,\n    WEEK_START_DATE DATE,\n    PREDICTED_WEEKLY_SALES FLOAT,\n    ACTUAL_WEEKLY_SALES FLOAT,\n    PREDICTION_ERROR FLOAT,\n    ABSOLUTE_ERROR FLOAT,\n    INFERENCE_TIMESTAMP TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n    MODEL_VERSION VARCHAR\n)\n\"\"\").collect()\n\n# Clear previous logs (optional - for demo purposes)\nsession.sql(\"DELETE FROM ARCA_BEVERAGE_DEMO.ML_DATA.INFERENCE_LOGS\").collect()\n\n# Insert predictions using CTE + JOIN pattern\nsession.sql(f\"\"\"\nINSERT INTO ARCA_BEVERAGE_DEMO.ML_DATA.INFERENCE_LOGS\n    (CUSTOMER_ID, SEGMENT, WEEK_START_DATE, PREDICTED_WEEKLY_SALES, \n     ACTUAL_WEEKLY_SALES, PREDICTION_ERROR, ABSOLUTE_ERROR, MODEL_VERSION)\nWITH model_predictions AS (\n    SELECT \n        p.CUSTOMER_ID,\n        p.SEGMENT,\n        p.PREDICTED_WEEKLY_SALES\n    FROM ARCA_BEVERAGE_DEMO.ML_DATA.INFERENCE_INPUT_TEMP i,\n        TABLE(\n            ARCA_BEVERAGE_DEMO.MODEL_REGISTRY.WEEKLY_SALES_FORECAST_PARTITIONED!PREDICT(\n                i.CUSTOMER_ID, i.SEGMENT,\n                i.CUSTOMER_TOTAL_UNITS_4W, i.WEEKS_WITH_PURCHASE, i.VOLUME_QUARTILE,\n                i.WEEK_OF_YEAR, i.MONTH, i.QUARTER,\n                i.TRANSACTION_COUNT, i.UNIQUE_PRODUCTS_PURCHASED,\n                i.AVG_UNITS_PER_TRANSACTION::FLOAT\n            ) OVER (PARTITION BY i.SEGMENT)\n        ) p\n)\nSELECT \n    mp.CUSTOMER_ID,\n    mp.SEGMENT,\n    i.WEEK_START_DATE,\n    mp.PREDICTED_WEEKLY_SALES,\n    i.ACTUAL_WEEKLY_SALES,\n    mp.PREDICTED_WEEKLY_SALES - i.ACTUAL_WEEKLY_SALES,\n    ABS(mp.PREDICTED_WEEKLY_SALES - i.ACTUAL_WEEKLY_SALES),\n    '{model_version.version_name}'\nFROM model_predictions mp\nJOIN ARCA_BEVERAGE_DEMO.ML_DATA.INFERENCE_INPUT_TEMP i \n    ON mp.CUSTOMER_ID = i.CUSTOMER_ID AND mp.SEGMENT = i.SEGMENT\n\"\"\").collect()\n\nlog_count = session.sql(\"SELECT COUNT(*) as CNT FROM ARCA_BEVERAGE_DEMO.ML_DATA.INFERENCE_LOGS\").collect()[0]['CNT']\nprint(f\"‚úÖ Saved {log_count:,} predictions to INFERENCE_LOGS\")\n\nprint(\"\\nüìã Sample from logs:\")\nsession.sql(\"\"\"\n    SELECT * FROM ARCA_BEVERAGE_DEMO.ML_DATA.INFERENCE_LOGS \n    ORDER BY SEGMENT, CUSTOMER_ID \n    LIMIT 5\n\"\"\").show()",
      "id": "save"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 6. SQL-Only Demo (Copy-Paste Ready)\n\nThis query can be executed from **any SQL client** - Snowsight, Python, JDBC, etc.",
      "id": "sql_demo_header"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "sql_demo = \"\"\"\n-- ============================================================\n-- PARTITIONED INFERENCE - SINGLE SQL CALL\n-- ============================================================\n-- This query:\n--   1. Takes customer features as input\n--   2. Routes each segment to its specific model\n--   3. Returns predictions for ALL segments in one call\n-- ============================================================\n\nWITH model_predictions AS (\n    SELECT \n        p.CUSTOMER_ID,\n        p.SEGMENT,\n        p.PREDICTED_WEEKLY_SALES\n    FROM ARCA_BEVERAGE_DEMO.ML_DATA.INFERENCE_INPUT_TEMP input,\n        TABLE(\n            ARCA_BEVERAGE_DEMO.MODEL_REGISTRY.WEEKLY_SALES_FORECAST_PARTITIONED!PREDICT(\n                input.CUSTOMER_ID,\n                input.SEGMENT,\n                input.CUSTOMER_TOTAL_UNITS_4W,\n                input.WEEKS_WITH_PURCHASE,\n                input.VOLUME_QUARTILE,\n                input.WEEK_OF_YEAR,\n                input.MONTH,\n                input.QUARTER,\n                input.TRANSACTION_COUNT,\n                input.UNIQUE_PRODUCTS_PURCHASED,\n                input.AVG_UNITS_PER_TRANSACTION::FLOAT\n            ) OVER (PARTITION BY input.SEGMENT)  -- ‚Üê THIS IS THE KEY!\n        ) p\n)\nSELECT \n    mp.CUSTOMER_ID,\n    mp.SEGMENT,\n    i.WEEK_START_DATE,\n    ROUND(mp.PREDICTED_WEEKLY_SALES, 2) AS PREDICTED_WEEKLY_SALES,\n    i.ACTUAL_WEEKLY_SALES\nFROM model_predictions mp\nJOIN ARCA_BEVERAGE_DEMO.ML_DATA.INFERENCE_INPUT_TEMP i \n    ON mp.CUSTOMER_ID = i.CUSTOMER_ID AND mp.SEGMENT = i.SEGMENT\nORDER BY mp.SEGMENT, mp.CUSTOMER_ID\nLIMIT 20;\n\"\"\"\n\nprint(\"üìã SQL Query for Demo (copy-paste ready):\")\nprint(\"=\"*60)\nprint(sql_demo)\nprint(\"=\"*60)\nprint(\"\\nüí° Key points:\")\nprint(\"   1. OVER (PARTITION BY SEGMENT) routes to correct sub-model\")\nprint(\"   2. CTE + JOIN pattern to get original columns back\")",
      "id": "sql_demo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 7. Summary",
      "id": "summary_header"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üéâ PARTITIONED INFERENCE COMPLETE!\")\nprint(\"=\"*80)\n\nprint(f\"\"\"\nüìä Summary:\n   ‚úÖ Predictions generated: {prediction_count:,}\n   ‚úÖ Segments covered: 6\n   ‚úÖ Inference time: {inference_time:.2f} seconds\n   ‚úÖ Logs saved to: INFERENCE_LOGS\n\nüí° Key Advantages of Partitioned Models:\n   ‚úÖ Single model in registry (not 6 separate)\n   ‚úÖ Automatic routing by SEGMENT column\n   ‚úÖ SQL-native inference (no Python required)\n   ‚úÖ Parallel execution handled by Snowflake\n   ‚úÖ Unified results in single query\n\nüéØ Business Impact:\n   ‚Ä¢ One SQL call predicts for ALL customer segments\n   ‚Ä¢ No need to manage 6 separate model endpoints\n   ‚Ä¢ Easy to integrate into any BI tool or pipeline\n   ‚Ä¢ Production-ready pattern for multi-segment forecasting\n\nüöÄ Next Steps:\n   ‚Üí Notebook 06: ML Observability (drift monitoring, alerts)\n\"\"\")\n\nprint(\"=\"*80)",
      "id": "summary"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}