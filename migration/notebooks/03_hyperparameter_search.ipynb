{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "# Migration: Hyperparameter Search (XGBoost + Snowflake ML Tune + MMT) - Per Group\n#\n## Overview\nThis script performs hyperparameter optimization using Snowflake ML's tune.search for XGBoost regression.\n**Uses Many Model Training (MMT) to perform separate hyperparameter search for each of the 16 stats_ntile_group groups in PARALLEL.**\n#\n## What We'll Do:\n1. Load cleaned training data with stats_ntile_group\n2. Get all 16 unique groups\n3. Use Many Model Training (MMT) to process all groups in PARALLEL:\n   - Each group runs its own Random Search using snowflake.ml.modeling.tune.search\n   - Load group-specific data (sampled for efficiency)\n   - Prepare features and target\n   - Save best hyperparameters per group\n4. Generate summary of all hyperparameter results\n",
      "id": "38094ad6-e62a-4195-b938-37da48bea68c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "from snowflake.snowpark.context import get_active_session\nfrom snowflake.ml.feature_store import FeatureStore\nfrom snowflake.ml.modeling.tune import Tuner, TunerConfig, get_tuner_context\nfrom snowflake.ml.modeling.tune.search import RandomSearch, randint, uniform\nfrom snowflake.ml.data.data_connector import DataConnector\nfrom snowflake.ml.experiment import ExperimentTracking\nfrom snowflake.ml.modeling.distributors.many_model import ManyModelTraining\nimport numpy as np\nfrom datetime import datetime\nimport json\nimport time\n\nsession = get_active_session()\n\n# Set context\nsession.sql(\"USE DATABASE BD_AA_DEV\").collect()\nsession.sql(\"USE SCHEMA SC_STORAGE_BMX_PS\").collect()\n\nprint(f\"‚úÖ Connected to Snowflake\")\nprint(f\"   Database: {session.get_current_database()}\")\nprint(f\"   Schema: {session.get_current_schema()}\")\n\n# Configuraci√≥n:\n# - Si no tienes permisos para FeatureView/Dynamic Tables, usa tablas limpias.\n# - Mantengo el flag pero agrego fallback autom√°tico si el modo Feature Store falla.\nUSE_CLEANED_TABLES = False  # True = TRAIN_DATASET_CLEANED, False = intentar Feature Store\n",
      "id": "e27e9ef4-4569-405c-91e3-24b3752848c4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 1. Get All Groups and Load Training Data\n",
      "id": "a85c647d-2fb7-45a1-99ed-30a2a9f4666c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üìä GETTING ALL GROUPS\")\nprint(\"=\" * 80)\n\n# Get all unique groups from cleaned training table\ngroups_df = session.sql(\n    \"\"\"\n    SELECT DISTINCT stats_ntile_group AS GROUP_NAME\n    FROM BD_AA_DEV.SC_STORAGE_BMX_PS.TRAIN_DATASET_CLEANED\n    WHERE stats_ntile_group IS NOT NULL\n    ORDER BY stats_ntile_group\n\"\"\"\n)\n\ngroups_list = [row[\"GROUP_NAME\"] for row in groups_df.collect()]\nprint(f\"\\n‚úÖ Found {len(groups_list)} groups:\")\nfor i, group in enumerate(groups_list, 1):\n    print(f\"   {i:2d}. {group}\")\n\nif len(groups_list) != 16:\n    print(f\"\\n‚ö†Ô∏è  WARNING: Expected 16 groups, found {len(groups_list)}\")\n    print(\"   Continuing with available groups...\")\n",
      "id": "7c2cf3c4-ce6a-4496-aea6-e40fc60ece87",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 2. Load Training Data (Feature Store or Cleaned Tables)\n",
      "id": "6a44f7f0-17d2-4557-b563-c68802dca87f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "if USE_CLEANED_TABLES:\n    print(\"\\n\" + \"=\" * 80)\n    print(\"üìä LOADING DATA FROM CLEANED TABLES (TESTING MODE)\")\n    print(\"=\" * 80)\n    \n    # Load directly from cleaned training table (for testing purposes)\n    print(\"‚è≥ Loading data from TRAIN_DATASET_CLEANED...\")\n    train_df = session.table(\"BD_AA_DEV.SC_STORAGE_BMX_PS.TRAIN_DATASET_CLEANED\")\n    \n    total_rows = train_df.count()\n    print(f\"\\n‚úÖ Training data loaded from cleaned table\")\n    print(f\"   Total rows: {total_rows:,}\")\n    print(f\"   ‚ö†Ô∏è  TESTING MODE: Using cleaned tables directly (not Feature Store)\")\nelse:\n    print(\"\\n\" + \"=\" * 80)\n    print(\"üè™ FEATURE STORE MODE (SIN FEATUREVIEW)\")\n    print(\"=\" * 80)\n\n    # En lugar de FeatureView, soportamos una tabla de features materializada por `02_feature_store_setup.py`\n    # (sin Dynamic Tables). Si no existe o falla, hacemos fallback a tablas limpias.\n    FEATURES_TABLE = \"BD_AA_DEV.SC_FEATURES_BMX.UNI_BOX_FEATURES\"\n\n    try:\n        # Mantener inicializaci√≥n del Feature Store (aunque no usemos FeatureView)\n        _fs = FeatureStore(session=session, database=\"BD_AA_DEV\", name=\"SC_FEATURES_BMX\")\n        print(\"‚úÖ Feature Store inicializado (sin FeatureView)\")\n\n        print(f\"‚è≥ Loading features from table: {FEATURES_TABLE} ...\")\n        features_df = session.table(FEATURES_TABLE)\n\n        print(\"‚è≥ Loading target variable and stats_ntile_group from training table...\")\n        target_df = session.table(\"BD_AA_DEV.SC_STORAGE_BMX_PS.TRAIN_DATASET_CLEANED\").select(\n            \"customer_id\", \"brand_pres_ret\", \"week\", \"uni_box_week\", \"stats_ntile_group\"\n        )\n\n        print(\"‚è≥ Joining features with target...\")\n        train_df = features_df.join(\n            target_df, on=[\"customer_id\", \"brand_pres_ret\", \"week\"], how=\"inner\"\n        )\n\n        total_rows = train_df.count()\n        print(f\"\\n‚úÖ Training data loaded from features table + target\")\n        print(f\"   Total rows: {total_rows:,}\")\n    except Exception as e:\n        print(f\"‚ö†Ô∏è  Could not load/join features table ({FEATURES_TABLE}): {str(e)[:200]}\")\n        print(\"   Falling back to TRAIN_DATASET_CLEANED (USE_CLEANED_TABLES=True behavior)\")\n        train_df = session.table(\"BD_AA_DEV.SC_STORAGE_BMX_PS.TRAIN_DATASET_CLEANED\")\n        total_rows = train_df.count()\n        print(f\"\\n‚úÖ Training data loaded from cleaned table (fallback)\")\n        print(f\"   Total rows: {total_rows:,}\")\n",
      "id": "0d603213-848c-485e-b2e1-8f7e37345757",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 3. Define Hyperparameter Search Space\n",
      "id": "e66b04ab-2c08-4e19-8554-e1ca119669fb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üéØ DEFINING HYPERPARAMETER SEARCH SPACE\")\nprint(\"=\" * 80)\n\n# Define parameter distributions for Random Search using Snowflake ML tune.search\nsearch_space = {\n    \"n_estimators\": randint(50, 300),\n    \"max_depth\": randint(3, 10),\n    \"learning_rate\": uniform(0.01, 0.3),\n    \"subsample\": uniform(0.6, 1.0),\n    \"colsample_bytree\": uniform(0.6, 1.0),\n    \"min_child_weight\": randint(1, 7),\n    \"gamma\": uniform(0, 0.5),\n    \"reg_alpha\": uniform(0, 1),\n    \"reg_lambda\": uniform(0, 1),\n}\n\nprint(\"\\nüìã Hyperparameter Search Space (using snowflake.ml.modeling.tune.search):\")\nfor param, dist in search_space.items():\n    if hasattr(dist, \"low\") and hasattr(dist, \"high\"):\n        if hasattr(dist, \"base\"):  # loguniform\n            print(f\"   {param}: loguniform({dist.low:.2f}, {dist.high:.2f})\")\n        else:  # uniform or randint\n            if isinstance(dist, randint):\n                print(f\"   {param}: randint({dist.low}, {dist.high})\")\n            else:\n                print(f\"   {param}: uniform({dist.low:.2f}, {dist.high:.2f})\")\n\n# Number of trials for Random Search (reduced per group for efficiency)\nnum_trials = 30  # Reduced from 50 since we're doing 16 groups\nprint(f\"\\nüî¢ Random Search trials per group: {num_trials}\")\n\n# Sample rate per group for hyperparameter search\n# Options:\n#   - 1.0 = Use full group (most accurate but slower)\n#   - 0.5 = Use 50% of group (balanced)\n#   - 0.1 = Use 10% of group (faster, less accurate)\n# Note: For large datasets, using full group (1.0) is recommended for better hyperparameter tuning\nSAMPLE_RATE_PER_GROUP = 0.2\nprint(f\"üìä Sample rate per group: {SAMPLE_RATE_PER_GROUP*100:.0f}%\")\nif SAMPLE_RATE_PER_GROUP < 1.0:\n    print(f\"   ‚ö†Ô∏è  Using {SAMPLE_RATE_PER_GROUP*100:.0f}% of data - consider using 1.0 (full group) for better results\")\nelse:\n    print(f\"   ‚úÖ Using full group data for optimal hyperparameter search\")\n",
      "id": "94ba85c3-f326-438d-8ed9-515f48a2f8ab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 4. Perform Hyperparameter Search Per Group\n",
      "id": "63fbedc4-9c0d-423a-9390-93d817240d7d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üîç PERFORMING HYPERPARAMETER SEARCH PER GROUP\")\nprint(\"=\" * 80)\n\n# Initialize ML Experiments for hyperparameter tracking FIRST\nprint(\"\\n\" + \"=\" * 80)\nprint(\"üî¨ INITIALIZING ML EXPERIMENTS\")\nprint(\"=\" * 80)\n\n# Initialize experiment_name in global scope\nexperiment_name = f\"hyperparameter_search_xgboost_{datetime.now().strftime('%Y%m%d')}\"\n\ntry:\n    exp_tracking = ExperimentTracking(session)\n    exp_tracking.set_experiment(experiment_name)\n    print(f\"‚úÖ Experiment created: {experiment_name}\")\n    experiments_available = True\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è  ML Experiments not available: {str(e)[:200]}\")\n    print(\"   Will continue with table-based storage only\")\n    exp_tracking = None\n    experiments_available = False\n\n# Create results table ONLY if ML Experiments is not available\n# If Experiments is available, we don't need this table\nif not experiments_available:\n    print(\"\\nüìã Creating HYPERPARAMETER_RESULTS table (Experiments not available)\")\n    session.sql(\n        \"\"\"\n        CREATE TABLE IF NOT EXISTS BD_AA_DEV.SC_STORAGE_BMX_PS.HYPERPARAMETER_RESULTS (\n            search_id VARCHAR,\n            group_name VARCHAR,\n            algorithm VARCHAR,\n            best_params VARIANT,\n            best_cv_rmse FLOAT,\n            best_cv_mae FLOAT,\n            val_rmse FLOAT,\n            val_mae FLOAT,\n            n_iter INTEGER,\n            sample_size INTEGER,\n            created_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()\n        )\n    \"\"\"\n    ).collect()\n    print(\"   ‚úÖ Table created (will be used as primary storage)\")\nelse:\n    print(\"\\nüìã Skipping table creation (using ML Experiments as primary storage)\")\n\n# Define excluded columns (metadata columns, not features)\n# Note: FEATURE_TIMESTAMP may not exist if using cleaned tables directly\nexcluded_cols = [\n    \"customer_id\",\n    \"brand_pres_ret\",\n    \"week\",\n    \"FEATURE_TIMESTAMP\",  # Feature Store timestamp column (may not exist in cleaned tables)\n    \"stats_ntile_group\",  # Group column - not a feature\n]\n\n# Get feature columns from first group (all groups should have same features)\nsample_group_df = train_df.filter(train_df[\"stats_ntile_group\"] == groups_list[0])\nsample_pandas = sample_group_df.limit(1).to_pandas()\nfeature_cols = [\n    col for col in sample_pandas.columns \n    if col not in excluded_cols + [\"uni_box_week\"]\n]\n\nprint(f\"\\nüìã Features ({len(feature_cols)}):\")\nfor col in sorted(feature_cols):\n    print(f\"   - {col}\")\n\n# Dictionary to store all results\nall_results = {}\n\n\ndef create_train_func_for_tuner(feature_cols):\n    \"\"\"\n    Create a training function for the Tuner.\n    This function will be called for each trial with different hyperparameters.\n    \n    Following Snowflake ML HPO best practices:\n    - Gets all data from dataset_map (not from outer scope)\n    - Uses \"train\" and \"test\" keys from dataset_map\n    - Reports metrics via tuner_context.report()\n    \n    Args:\n        feature_cols: List of feature column names\n    \n    Returns:\n        train_func: Function that can be used by Tuner\n    \"\"\"\n    def train_func():\n        from snowflake.ml.modeling.xgboost import XGBRegressor\n        from sklearn.metrics import mean_squared_error, mean_absolute_error\n        import numpy as np\n        \n        tuner_context = get_tuner_context()\n        params = tuner_context.get_hyper_params()\n        dm = tuner_context.get_dataset_map()\n        \n        # Load data from DataConnector (following HPO documentation pattern)\n        train_pd = dm[\"train\"].to_pandas()\n        test_pd = dm[\"test\"].to_pandas()\n        \n        # Prepare training features and target\n        X_train = train_pd[feature_cols].fillna(0)\n        y_train = train_pd[\"uni_box_week\"].fillna(0)\n        \n        # Prepare validation features and target\n        X_val = test_pd[feature_cols].fillna(0)\n        y_val = test_pd[\"uni_box_week\"].fillna(0)\n        \n        # Build model with hyperparameters from tuner\n        xgb_params = params.copy()\n        xgb_params[\"random_state\"] = 42\n        xgb_params[\"n_jobs\"] = -1\n        xgb_params[\"objective\"] = \"reg:squarederror\"\n        xgb_params[\"eval_metric\"] = \"rmse\"\n        \n        # Train model\n        model = XGBRegressor(**xgb_params)\n        model.fit(X_train, y_train)\n        \n        # Evaluate on validation set (from dataset_map, not outer scope)\n        y_val_pred = model.predict(X_val)\n        val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n        val_mae = mean_absolute_error(y_val, y_val_pred)\n        \n        # Report metrics (following HPO documentation pattern)\n        tuner_context.report(metrics={\"rmse\": val_rmse, \"mae\": val_mae}, model=model)\n    \n    return train_func\n\n\ndef search_hyperparameters_for_group(data_connector, context):\n    \"\"\"\n    Perform hyperparameter search for a specific group using MMT + HPO.\n    \n    ARCHITECTURE: Two-Level Parallelization\n    ========================================\n    Level 1 (MMT - Many Model Training):\n      - MMT partitions data by stats_ntile_group (16 groups)\n      - Each group runs in PARALLEL (16 parallel executions)\n      - This function is called ONCE per group by MMT\n    \n    Level 2 (HPO - Hyperparameter Optimization):\n      - Within EACH group, Tuner runs multiple trials (e.g., 30 trials)\n      - Trials can run in parallel (controlled by max_concurrent_trials)\n      - Each trial tests different hyperparameter combinations\n      - Total parallelization = 16 groups √ó max_concurrent_trials per group\n    \n    This function:\n    1. Receives data for ONE group (via MMT partitioning)\n    2. Performs Random Search using Snowflake ML Tuner (HPO)\n    3. Saves best hyperparameters to Experiments/Table\n    4. Returns a simple object with results\n    \n    Args:\n        data_connector: Snowflake data connector (provided by MMT)\n        context: Contains partition_id (stats_ntile_group name)\n    \n    Returns:\n        Simple object containing best hyperparameters\n    \"\"\"\n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import mean_squared_error, mean_absolute_error\n    import numpy as np\n    \n    group_name = context.partition_id\n    print(f\"\\n{'='*80}\")\n    print(f\"üîç Hyperparameter Search for Group: {group_name}\")\n    print(f\"{'='*80}\")\n    \n    # Define DummyResult class once (reused in multiple early-return scenarios)\n    class DummyResult:\n        def __init__(self):\n            self.group_name = group_name\n            self.skipped = True\n    \n    # Load data\n    df = data_connector.to_pandas()\n    group_count = len(df)\n    print(f\"üìä Group data: {group_count:,} records\")\n    \n    if group_count < 50:\n        print(f\"‚ö†Ô∏è  WARNING: Group has less than 50 records. Skipping hyperparameter search.\")\n        print(f\"   Will use default hyperparameters for this group.\")\n        return DummyResult()\n    \n    # Sample data for this group (or use full group if SAMPLE_RATE_PER_GROUP = 1.0)\n    if SAMPLE_RATE_PER_GROUP < 1.0:\n        sampled_df = df.sample(frac=SAMPLE_RATE_PER_GROUP, random_state=42)\n        sampled_count = len(sampled_df)\n        print(f\"   Sampled: {sampled_count:,} records ({SAMPLE_RATE_PER_GROUP*100:.0f}% of {group_count:,} total)\")\n    else:\n        # Use full group for better hyperparameter search\n        sampled_df = df\n        sampled_count = group_count\n        print(f\"   Using full group: {sampled_count:,} records (100% of group)\")\n    \n    # Define excluded columns (metadata columns, not features)\n    # Note: FEATURE_TIMESTAMP may not exist if using cleaned tables directly\n    excluded_cols = [\n        \"customer_id\",\n        \"brand_pres_ret\",\n        \"week\",\n        \"FEATURE_TIMESTAMP\",  # Feature Store timestamp column (may not exist in cleaned tables)\n        \"stats_ntile_group\",  # Group column - not a feature\n    ]\n    \n    # Get feature columns\n    feature_cols_list = [\n        col for col in sampled_df.columns \n        if col not in excluded_cols + [\"uni_box_week\"]\n    ]\n    \n    # Prepare X and y\n    X = sampled_df[feature_cols_list].fillna(0)\n    y = sampled_df[\"uni_box_week\"].fillna(0)\n    \n    print(f\"   Data shape: X={X.shape}, y={y.shape}\")\n    print(f\"   Target range: [{y.min():.2f}, {y.max():.2f}], mean: {y.mean():.2f}\")\n    \n    # Split into train and validation sets\n    if len(X) < 20:\n        print(f\"‚ö†Ô∏è  WARNING: Not enough data for train/val split. Skipping.\")\n        return DummyResult()\n        \n    X_train, X_val, y_train, y_val = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    \n    print(f\"   Train: {X_train.shape[0]:,} samples, Val: {X_val.shape[0]:,} samples\")\n    \n    # Prepare data for Tuner using DataConnector\n    # Following Snowflake ML HPO documentation pattern: include both \"train\" and \"test\" in dataset_map\n    train_data = X_train.copy()\n    train_data[\"uni_box_week\"] = y_train.values\n    \n    val_data = X_val.copy()\n    val_data[\"uni_box_week\"] = y_val.values\n    \n    # Create DataConnectors for both train and test sets\n    train_dc = DataConnector.from_dataframe(train_data)\n    val_dc = DataConnector.from_dataframe(val_data)\n    \n    # dataset_map must include both \"train\" and \"test\" keys (following HPO documentation)\n    dataset_map = {\n        \"train\": train_dc,\n        \"test\": val_dc\n    }\n    \n    # Create training function for Tuner (no longer needs X_val, y_val - gets from dataset_map)\n    train_func = create_train_func_for_tuner(feature_cols_list)\n    \n    # Configure Tuner\n    # IMPORTANT: Understanding parallelization levels:\n    # - MMT (Many Model Training): Parallelizes at GROUP level (16 groups run in parallel)\n    # - HPO (Hyperparameter Optimization): Parallelizes at TRIAL level within each group\n    #   - max_concurrent_trials controls how many trials run in parallel within THIS group\n    #   - Setting to 1 means trials run sequentially within the group\n    #   - Can increase to use more CPU/GPU cores per group (e.g., max_concurrent_trials=4)\n    #   - Total parallelization = MMT groups √ó HPO concurrent trials per group\n    tuner_config = TunerConfig(\n        metric=\"rmse\",\n        mode=\"min\",  # Minimize RMSE\n        search_alg=RandomSearch(),\n        num_trials=num_trials,\n        max_concurrent_trials=1,  # Trials run sequentially within this group\n        # Note: Can increase max_concurrent_trials if you have more CPU/GPU cores available\n        # per group. For example, if each group has 4 cores, set max_concurrent_trials=4\n        # to run 4 trials in parallel within each group.\n    )\n    \n    # Create and run Tuner\n    print(f\"   ‚è≥ Starting Random Search using snowflake.ml.modeling.tune ({num_trials} trials)...\")\n    start_time = time.time()\n    \n    try:\n        tuner = Tuner(train_func, search_space, tuner_config)\n        results = tuner.run(dataset_map=dataset_map)\n        \n        elapsed_time = time.time() - start_time\n        \n        # Get best results\n        best_result = results.best_result\n        best_params = best_result.hyperparameters\n        best_rmse = best_result.metrics[\"rmse\"]\n        best_mae = best_result.metrics.get(\"mae\", None)\n        best_model = results.best_model\n        \n        # Evaluate best model on validation set again for consistency\n        y_val_pred = best_model.predict(X_val)\n        val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n        val_mae = mean_absolute_error(y_val, y_val_pred)\n        \n        print(f\"   ‚úÖ Completed in {elapsed_time:.1f}s\")\n        print(f\"      Best RMSE: {best_rmse:.4f}\")\n        print(f\"      Val RMSE: {val_rmse:.4f}, Val MAE: {val_mae:.4f}\")\n        \n        # Store results in global dictionary (for summary later)\n        all_results[group_name] = {\n            \"best_params\": best_params,\n            \"best_cv_rmse\": best_rmse,\n            \"val_rmse\": val_rmse,\n            \"val_mae\": val_mae,\n            \"sample_size\": sampled_count,\n        }\n        \n        # Save to ML Experiments\n        search_id = f\"xgb_snowflake_tune_{group_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n        experiments_success = False\n        \n        if experiments_available:\n            try:\n                # Create a run for this group's best hyperparameters\n                run_name = f\"best_{group_name}_{datetime.now().strftime('%H%M%S')}\"\n                with exp_tracking.start_run(run_name):\n                    # Log all hyperparameters\n                    exp_tracking.log_params(best_params)\n                    \n                    # Log metrics\n                    exp_tracking.log_metrics({\n                        \"best_rmse\": float(best_rmse),\n                        \"val_rmse\": float(val_rmse),\n                        \"val_mae\": float(val_mae),\n                        \"sample_size\": int(sampled_count),\n                        \"num_trials\": int(num_trials),\n                    })\n                    \n                    # Log group identifier as a tag/parameter\n                    exp_tracking.log_param(\"group_name\", group_name)\n                    exp_tracking.log_param(\"search_id\", search_id)\n                    exp_tracking.log_param(\"algorithm\", \"XGBoost\")\n                \n                print(f\"   ‚úÖ Results logged to ML Experiments (run: {run_name})\")\n                experiments_success = True\n            except Exception as e:\n                print(f\"   ‚ö†Ô∏è  Error logging to Experiments: {str(e)[:200]}\")\n                experiments_success = False\n        \n        # Save to database ONLY if ML Experiments is not available or failed\n        # If Experiments works, we don't need the table\n        if not experiments_available or not experiments_success:\n            print(f\"   üìã Saving to table (Experiments {'not available' if not experiments_available else 'failed'})\")\n            \n            # Ensure table exists\n            session.sql(\n                \"\"\"\n                CREATE TABLE IF NOT EXISTS BD_AA_DEV.SC_STORAGE_BMX_PS.HYPERPARAMETER_RESULTS (\n                    search_id VARCHAR,\n                    group_name VARCHAR,\n                    algorithm VARCHAR,\n                    best_params VARIANT,\n                    best_cv_rmse FLOAT,\n                    best_cv_mae FLOAT,\n                    val_rmse FLOAT,\n                    val_mae FLOAT,\n                    n_iter INTEGER,\n                    sample_size INTEGER,\n                    created_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()\n                )\n            \"\"\"\n            ).collect()\n            \n            best_params_json = json.dumps(\n                {\n                    k: float(v) if isinstance(v, (np.integer, np.floating)) else v\n                    for k, v in best_params.items()\n                }\n            )\n            \n            best_mae_value = best_mae if best_mae is not None else None\n            best_mae_sql = f\"{best_mae_value:.6f}\" if best_mae_value is not None else \"NULL\"\n            \n            # Guardar resultados con group_name como identificador del grupo\n            insert_sql = f\"\"\"\n                INSERT INTO BD_AA_DEV.SC_STORAGE_BMX_PS.HYPERPARAMETER_RESULTS\n                (search_id, group_name, algorithm, best_params, best_cv_rmse, best_cv_mae, val_rmse, val_mae, n_iter, sample_size)\n                VALUES (\n                    '{search_id}',\n                    '{group_name}',\n                    'XGBoost',\n                    PARSE_JSON('{best_params_json}'),\n                    {best_rmse:.6f},\n                    {best_mae_sql},\n                    {val_rmse:.6f},\n                    {val_mae:.6f},\n                    {num_trials},\n                    {sampled_count}\n                )\n            \"\"\"\n            \n            session.sql(insert_sql).collect()\n            print(f\"   ‚úÖ Results saved to table\")\n        else:\n            print(f\"   ‚úÖ Results stored in ML Experiments only (table not needed)\")\n        \n        # Create result object to return\n        class HyperparameterResult:\n            def __init__(self):\n                self.group_name = group_name\n                self.best_params = best_params\n                self.best_rmse = best_rmse\n                self.val_rmse = val_rmse\n                self.val_mae = val_mae\n                self.skipped = False\n        \n        print(f\"{'='*80}\\n\")\n        return HyperparameterResult()\n        \n    except Exception as e:\n        print(f\"   ‚ùå Error during hyperparameter search: {str(e)[:200]}\")\n        import traceback\n        print(f\"   Traceback: {traceback.format_exc()[:300]}\")\n        print(f\"   Will use default hyperparameters for this group.\")\n        print(f\"{'='*80}\\n\")\n        \n        # Return a dummy object indicating failure\n        return DummyResult()\n\n\n# Setup MMT stage (if needed)\nprint(\"\\nüìã Setting up MMT stage for hyperparameter search...\")\nsession.sql(\"CREATE SCHEMA IF NOT EXISTS BD_AA_DEV.SC_MODELS_BMX\").collect()\nsession.sql(\"CREATE STAGE IF NOT EXISTS BD_AA_DEV.SC_MODELS_BMX.MMT_HYPERPARAMETER_SEARCH\").collect()\nprint(\"   ‚úÖ MMT stage created\")\n\n# Execute Many Model Training (MMT) for Hyperparameter Search\n# ============================================================\n# ARCHITECTURE: Two-Level Parallelization\n# \n# Level 1 - MMT (Many Model Training):\n#   - MMT partitions data by stats_ntile_group (16 groups)\n#   - Each group runs in PARALLEL (16 groups executing simultaneously)\n#   - This is the OUTER level of parallelization\n#\n# Level 2 - HPO (Hyperparameter Optimization):\n#   - Within EACH group, Tuner runs multiple trials (e.g., 30 trials)\n#   - Trials can run in parallel (controlled by max_concurrent_trials in TunerConfig)\n#   - This is the INNER level of parallelization\n#\n# Total Parallelization = MMT groups √ó HPO concurrent trials per group\n# Example: 16 groups √ó 1 trial/group = 16 parallel executions\n#          If max_concurrent_trials=4: 16 groups √ó 4 trials/group = 64 parallel executions\n#\n# IMPORTANTE: La conexi√≥n grupo-hiperpar√°metros se hace mediante el campo \n# 'group_name' que se guarda en la tabla HYPERPARAMETER_RESULTS o ML Experiments. \n# Luego en el script 04, se usa este 'group_name' para cargar los hiperpar√°metros correctos \n# para cada modelo.\nprint(\"\\n\" + \"=\" * 80)\nprint(\"üöÄ STARTING MANY MODEL TRAINING (MMT) FOR HYPERPARAMETER SEARCH\")\nprint(\"=\" * 80)\nprint(\"\\nTwo-Level Parallelization Architecture:\")\nprint(\"  Level 1 (MMT): 16 groups running in PARALLEL\")\nprint(\"  Level 2 (HPO): Multiple trials per group (controlled by max_concurrent_trials)\")\nprint(\"  Each group will run its own Random Search with Tuner\\n\")\n\nstart_time = time.time()\n\n# Create MMT trainer for hyperparameter search\ntrainer = ManyModelTraining(\n    search_hyperparameters_for_group, \n    \"BD_AA_DEV.SC_MODELS_BMX.MMT_HYPERPARAMETER_SEARCH\"\n)\n\n# Execute MMT with partition_by stats_ntile_group\n# This will automatically partition the data by group and run search_hyperparameters_for_group\n# for each partition in parallel\nsearch_run = trainer.run(\n    partition_by=\"stats_ntile_group\",  # ‚Üê KEY: Partition by group\n    snowpark_dataframe=train_df,\n    run_id=f\"hyperparameter_search_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n)\n\nprint(\"\\n‚è≥ Hyperparameter search in progress... Monitoring completion...\\n\")\n\n# Monitor with timeout\nmax_wait = 3600  # 60 minutes max (hyperparameter search can take longer)\ncheck_interval = 10  # Check every 10 seconds\nelapsed = 0\ncompleted = False\n\nwhile elapsed < max_wait:\n    time.sleep(check_interval)\n    elapsed += check_interval\n\n    try:\n        done_count = 0\n        total_count = 0\n        for partition_id in search_run.partition_details:\n            total_count += 1\n            status = search_run.partition_details[partition_id].status\n            if status.name == \"DONE\" or status.name == \"FAILED\":\n                done_count += 1\n\n        print(\n            f\"‚è±Ô∏è  {elapsed}s elapsed - Progress: {done_count}/{total_count} groups completed\",\n            end=\"\\r\",\n        )\n\n        if done_count == total_count:\n            print(\"\\n‚úÖ All hyperparameter searches completed!\" + \" \" * 50)\n            completed = True\n            break\n    except:\n        print(f\"‚è±Ô∏è  {elapsed}s elapsed - Waiting for status update...\", end=\"\\r\")\n\nif not completed:\n    print(\"\\n‚è±Ô∏è  Timeout reached - Verifying completion via stage...\" + \" \" * 30)\n    stage_files = session.sql(\n        f\"LIST @BD_AA_DEV.SC_MODELS_BMX.MMT_HYPERPARAMETER_SEARCH PATTERN='.*{search_run.run_id}.*'\"\n    ).collect()\n    if len(stage_files) > 0:\n        print(\n            f\"‚úÖ Found {len(stage_files)} result files in stage - Search completed successfully!\"\n        )\n        completed = True\n\nend_time = time.time()\nelapsed_minutes = (end_time - start_time) / 60\n\nprint(\"\\n\" + \"=\" * 80)\nprint(f\"‚úÖ HYPERPARAMETER SEARCH COMPLETE! Status: {'COMPLETED' if completed else 'UNKNOWN'}\")\nprint(\"=\" * 80)\nprint(f\"\\n‚è±Ô∏è  Total search time: {elapsed_minutes:.2f} minutes\")\n\n# Review results from MMT run\nprint(\"\\nüìä Hyperparameter Search Results by Group:\\n\")\n\nsuccessful_searches = 0\nfor partition_id in search_run.partition_details:\n    details = search_run.partition_details[partition_id]\n\n    if details.status.name == \"DONE\":\n        try:\n            result = search_run.get_model(partition_id)\n            if hasattr(result, 'skipped') and result.skipped:\n                print(f\"‚ö†Ô∏è  {partition_id}: Skipped (insufficient data or error)\")\n            else:\n                print(f\"‚úÖ {partition_id}:\")\n                print(f\"   Best RMSE: {result.best_rmse:.4f}\")\n                print(f\"   Val RMSE: {result.val_rmse:.4f}, Val MAE: {result.val_mae:.4f}\")\n                successful_searches += 1\n        except Exception as e:\n            print(f\"‚ö†Ô∏è  {partition_id}: Could not load result - {str(e)[:100]}\")\n    else:\n        print(f\"‚ùå {partition_id}: Search failed\")\n        print(f\"   Status: {details.status}\")\n\nprint(f\"\\n‚úÖ Completed hyperparameter search for {successful_searches}/{len(groups_list)} groups\")\n",
      "id": "31807bb3-7a46-4aa3-b92a-c4fa0dbb7b2d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 5. Summary of All Results\n",
      "id": "82f9194b-64d0-4592-a3d6-77d0391d0694"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üìä SUMMARY OF ALL HYPERPARAMETER SEARCHES\")\nprint(\"=\" * 80)\n\n# Summary: Show results from Experiments or table\nif experiments_available:\n    print(\"\\nüìä Results Summary:\")\n    print(f\"   ‚úÖ All results stored in ML Experiments\")\n    print(f\"   ‚úÖ Experiment: {experiment_name}\")\n    print(f\"   ‚úÖ Groups processed: {len(all_results)}\")\n    print(f\"\\nüí° View results in Snowsight: AI & ML ‚Üí Experiments ‚Üí {experiment_name}\")\n    \n    # Try to show summary from Experiments if possible\n    try:\n        # This is a conceptual query - actual API may vary\n        print(\"\\nüìä Sample results from Experiments:\")\n        for group_name, result in list(all_results.items())[:5]:\n            print(f\"   {group_name}: RMSE={result['val_rmse']:.4f}, MAE={result['val_mae']:.4f}\")\n        if len(all_results) > 5:\n            print(f\"   ... and {len(all_results) - 5} more groups\")\n    except:\n        pass\nelse:\n    # Fallback to table summary if Experiments not available\n    print(\"\\nüìä Results from Table:\")\n    summary_df = session.sql(\n        \"\"\"\n        SELECT \n            group_name,\n            best_cv_rmse,\n            val_rmse,\n            val_mae,\n            sample_size,\n            created_at\n        FROM BD_AA_DEV.SC_STORAGE_BMX_PS.HYPERPARAMETER_RESULTS\n        WHERE created_at >= DATEADD(HOUR, -1, CURRENT_TIMESTAMP())\n        ORDER BY group_name\n    \"\"\"\n    )\n    summary_df.show()\n    \n    # Overall statistics\n    overall_stats = session.sql(\n        \"\"\"\n        SELECT \n            COUNT(*) AS TOTAL_SEARCHES,\n            AVG(best_cv_rmse) AS AVG_CV_RMSE,\n            AVG(val_rmse) AS AVG_VAL_RMSE,\n            MIN(val_rmse) AS MIN_VAL_RMSE,\n            MAX(val_rmse) AS MAX_VAL_RMSE\n        FROM BD_AA_DEV.SC_STORAGE_BMX_PS.HYPERPARAMETER_RESULTS\n        WHERE created_at >= DATEADD(HOUR, -1, CURRENT_TIMESTAMP())\n    \"\"\"\n    )\n    print(\"\\nüìä Overall Statistics:\")\n    overall_stats.show()\n",
      "id": "36bb7006-1c6e-423d-97a9-f6f62e4e2b9b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 6. Summary\n",
      "id": "853e1ff8-3974-4f39-9373-1deb7bde33ca"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"‚úÖ HYPERPARAMETER SEARCH COMPLETE!\")\nprint(\"=\" * 80)\n\nprint(\"\\nüìã Summary:\")\nprint(f\"   ‚úÖ Algorithm: XGBoost\")\nprint(f\"   ‚úÖ Search method: Many Model Training (MMT) + Snowflake ML tune.search RandomSearch\")\nprint(f\"   ‚úÖ Execution: PARALLEL (all groups processed simultaneously)\")\nprint(f\"   ‚úÖ Groups processed: {successful_searches}/{len(groups_list)}\")\nprint(f\"   ‚úÖ Trials per group: {num_trials}\")\nprint(f\"   ‚úÖ Sample rate per group: {SAMPLE_RATE_PER_GROUP*100:.0f}%\")\nprint(f\"   ‚è±Ô∏è  Total time: {elapsed_minutes:.2f} minutes\")\n\n# Calculate statistics from all_results if available\nif all_results:\n    avg_val_rmse = np.mean([r[\"val_rmse\"] for r in all_results.values()])\n    min_val_rmse = min([r[\"val_rmse\"] for r in all_results.values()])\n    max_val_rmse = max([r[\"val_rmse\"] for r in all_results.values()])\n    \n    print(f\"   ‚úÖ Average Validation RMSE: {avg_val_rmse:.4f}\")\n    print(f\"   ‚úÖ Best Group RMSE: {min_val_rmse:.4f}\")\n    print(f\"   ‚úÖ Worst Group RMSE: {max_val_rmse:.4f}\")\n\nprint(\"\\nüí° Next Steps:\")\nprint(\"   1. Review hyperparameter results by group\")\nprint(\"   2. Run 04_many_model_training.py to train 16 models (one per group)\")\nprint(\"   3. Each model will use its group-specific hyperparameters\")\n\nprint(\"\\n\" + \"=\" * 80)\n",
      "id": "a1e7772b-81f2-47be-aa71-1f64ecafe8ac",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}