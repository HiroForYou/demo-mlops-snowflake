{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "# Migration: Hyperparameter Search (XGBoost + Random Search)\n#\n## Overview\nThis script performs hyperparameter optimization using Random Search for XGBoost regression.\n#\n## What We'll Do:\n1. Load cleaned training data (sampled for efficiency)\n2. Prepare features and target\n3. Perform Random Search with cross-validation\n4. Save best hyperparameters\n",
      "id": "633c35b4-9d0a-423d-ac15-9dd68f5ae23a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "from snowflake.snowpark.context import get_active_session\nfrom snowflake.ml.feature_store import FeatureStore\nimport numpy as np\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom scipy.stats import randint, uniform\nfrom datetime import datetime\n\nsession = get_active_session()\n\n# Set context\nsession.sql(\"USE DATABASE BD_AA_DEV\").collect()\nsession.sql(\"USE SCHEMA SC_STORAGE_BMX_PS\").collect()\n\nprint(f\"‚úÖ Connected to Snowflake\")\nprint(f\"   Database: {session.get_current_database()}\")\nprint(f\"   Schema: {session.get_current_schema()}\")\n",
      "id": "ed505623-ded5-4c38-a39a-b40738632ce3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 1. Load Features from Feature Store\n",
      "id": "7c6b2f00-9e61-46c4-8777-e523151b7af7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üè™ LOADING FEATURES FROM FEATURE STORE\")\nprint(\"=\" * 80)\n\n# Initialize Feature Store\nfs = FeatureStore(session=session, database=\"BD_AA_DEV\", name=\"FEATURE_STORE\")\n\nprint(\"‚úÖ Feature Store initialized\")\n\n# Get FeatureView\ntry:\n    feature_view = fs.get_feature_view(\"UNI_BOX_FEATURES\", version=\"v1\")\n    print(\"‚úÖ FeatureView 'UNI_BOX_FEATURES' v1 loaded\")\nexcept Exception as e:\n    # Try v2 if v1 doesn't exist\n    try:\n        feature_view = fs.get_feature_view(\"UNI_BOX_FEATURES\", version=\"v2\")\n        print(\"‚úÖ FeatureView 'UNI_BOX_FEATURES' v2 loaded\")\n    except:\n        print(f\"‚ùå Error loading FeatureView: {str(e)}\")\n        print(\"   Please run 02_feature_store_setup.py first\")\n        raise\n\n# Materialize features (get the feature data)\nprint(\"\\n‚è≥ Materializing features from Feature Store...\")\nfeatures_df = feature_view.get_features()\n\n# Get target from cleaned training table\nprint(\"‚è≥ Loading target variable from training table...\")\ntarget_df = session.table(\"BD_AA_DEV.SC_STORAGE_BMX_PS.TRAIN_DATASET_CLEANED\").select(\n    \"customer_id\", \"brand_pres_ret\", \"week\", \"uni_box_week\"\n)\n\n# Join features with target\nprint(\"‚è≥ Joining features with target...\")\ntrain_df = features_df.join(\n    target_df, on=[\"customer_id\", \"brand_pres_ret\", \"week\"], how=\"inner\"\n)\n\ntotal_rows = train_df.count()\nprint(f\"\\n‚úÖ Training data loaded from Feature Store\")\nprint(f\"   Total rows: {total_rows:,}\")\n\n# Sample data for hyperparameter search (5-10% for efficiency)\nsample_rate = 0.05  # 5% sample\nprint(f\"\\nüìä Sampling {sample_rate*100:.0f}% of data for hyperparameter search...\")\n\nsampled_df = train_df.sample(fraction=sample_rate, seed=42)\nsampled_count = sampled_df.count()\nprint(f\"   Sampled rows: {sampled_count:,}\")\n\n# Convert to pandas for sklearn\nprint(\"\\n‚è≥ Converting to pandas (this may take a moment)...\")\ndf = sampled_df.to_pandas()\nprint(f\"‚úÖ Converted to pandas: {df.shape}\")\n",
      "id": "b586db99-5f03-464a-b705-63e9e554b0db",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 2. Prepare Features and Target\n",
      "id": "2cb7d97f-b709-4719-8c2b-3e84d545c726"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üîß PREPARING FEATURES AND TARGET\")\nprint(\"=\" * 80)\n\n# Define excluded columns (metadata columns from Feature Store)\nexcluded_cols = [\n    \"customer_id\",\n    \"brand_pres_ret\",\n    \"week\",\n    \"FEATURE_TIMESTAMP\",  # Feature Store timestamp column\n]\n\n# Get feature columns (all except excluded and target)\nfeature_cols = [\n    col for col in df.columns if col not in excluded_cols + [\"uni_box_week\"]\n]\n\nprint(f\"\\nüìã Features ({len(feature_cols)}):\")\nfor col in sorted(feature_cols):\n    print(f\"   - {col}\")\n\n# Prepare X and y\nX = df[feature_cols].fillna(0)  # Fill NaN with 0\ny = df[\"uni_box_week\"].fillna(0)\n\nprint(f\"\\n‚úÖ Features prepared:\")\nprint(f\"   X shape: {X.shape}\")\nprint(f\"   y shape: {y.shape}\")\nprint(f\"   Target range: [{y.min():.2f}, {y.max():.2f}]\")\nprint(f\"   Target mean: {y.mean():.2f}\")\n\n# Split into train and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(f\"\\nüìä Train/Validation split:\")\nprint(f\"   Training: {X_train.shape[0]:,} samples\")\nprint(f\"   Validation: {X_val.shape[0]:,} samples\")\n",
      "id": "0e583650-022a-4ba9-8d9b-1e39d5f1e094",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 3. Define Hyperparameter Search Space\n",
      "id": "a01bf8eb-db58-4036-a520-e2a7ef108731"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üéØ DEFINING HYPERPARAMETER SEARCH SPACE\")\nprint(\"=\" * 80)\n\n# Define parameter distributions for Random Search\nparam_distributions = {\n    \"n_estimators\": randint(50, 300),\n    \"max_depth\": randint(3, 10),\n    \"learning_rate\": uniform(0.01, 0.3),\n    \"subsample\": uniform(0.6, 1.0),\n    \"colsample_bytree\": uniform(0.6, 1.0),\n    \"min_child_weight\": randint(1, 7),\n    \"gamma\": uniform(0, 0.5),\n    \"reg_alpha\": uniform(0, 1),\n    \"reg_lambda\": uniform(0, 1),\n}\n\nprint(\"\\nüìã Hyperparameter Search Space:\")\nfor param, dist in param_distributions.items():\n    if hasattr(dist, \"a\") and hasattr(dist, \"b\"):\n        print(f\"   {param}: uniform({dist.a:.2f}, {dist.b:.2f})\")\n    elif hasattr(dist, \"low\") and hasattr(dist, \"high\"):\n        print(f\"   {param}: randint({dist.low}, {dist.high})\")\n\n# Number of iterations for Random Search\nn_iter = 50\nprint(f\"\\nüî¢ Random Search iterations: {n_iter}\")\n",
      "id": "0eaffaa5-31e4-4b20-81c0-df5057a74794",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 4. Perform Random Search\n",
      "id": "1cef0cbc-327b-497b-894a-2f4d82d7bb28"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üîç PERFORMING RANDOM SEARCH\")\nprint(\"=\" * 80)\n\n# Create base XGBoost model\nbase_model = XGBRegressor(\n    random_state=42, n_jobs=-1, objective=\"reg:squarederror\", eval_metric=\"rmse\"\n)\n\n# Create Random Search\nrandom_search = RandomizedSearchCV(\n    estimator=base_model,\n    param_distributions=param_distributions,\n    n_iter=n_iter,\n    cv=5,  # 5-fold cross-validation\n    scoring=\"neg_mean_squared_error\",\n    n_jobs=-1,\n    random_state=42,\n    verbose=1,\n)\n\nprint(\"\\n‚è≥ Starting Random Search (this may take several minutes)...\")\nprint(\"   Using 5-fold cross-validation\")\nprint(\"   This will test 50 different hyperparameter combinations\\n\")\n\n# Fit Random Search\nimport time\n\nstart_time = time.time()\n\nrandom_search.fit(X_train, y_train)\n\nelapsed_time = time.time() - start_time\nprint(f\"\\n‚úÖ Random Search completed in {elapsed_time/60:.2f} minutes\")\n",
      "id": "0ad80345-d570-4626-852f-abd8dbee0665",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 5. Evaluate Best Model\n",
      "id": "fc831745-c110-4a3f-aa18-421dd5f75108"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üèÜ BEST HYPERPARAMETERS\")\nprint(\"=\" * 80)\n\nbest_params = random_search.best_params_\nbest_score = random_search.best_score_\nbest_model = random_search.best_estimator_\n\nprint(\"\\nüìä Best Hyperparameters:\")\nfor param, value in sorted(best_params.items()):\n    print(f\"   {param}: {value}\")\n\nprint(f\"\\nüìà Best CV Score (neg MSE): {best_score:.4f}\")\nprint(f\"   Best CV RMSE: {np.sqrt(-best_score):.4f}\")\n\n# Evaluate on validation set\ny_val_pred = best_model.predict(X_val)\nval_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\nval_mae = mean_absolute_error(y_val, y_val_pred)\n\nprint(f\"\\nüìä Validation Set Performance:\")\nprint(f\"   RMSE: {val_rmse:.4f}\")\nprint(f\"   MAE: {val_mae:.4f}\")\n",
      "id": "4df8dca1-3aa3-4ff3-a2d3-72ae5a9c7fb6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 6. Save Hyperparameters\n",
      "id": "30f89090-0bef-42cf-aec0-04b8f00913f8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üíæ SAVING HYPERPARAMETERS\")\nprint(\"=\" * 80)\n\n# Create results table\nsession.sql(\n    \"\"\"\n    CREATE TABLE IF NOT EXISTS BD_AA_DEV.SC_STORAGE_BMX_PS.HYPERPARAMETER_RESULTS (\n        search_id VARCHAR,\n        algorithm VARCHAR,\n        best_params VARIANT,\n        best_cv_rmse FLOAT,\n        best_cv_mae FLOAT,\n        val_rmse FLOAT,\n        val_mae FLOAT,\n        n_iter INTEGER,\n        sample_size INTEGER,\n        created_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()\n    )\n\"\"\"\n).collect()\n\n# Save results\nsearch_id = f\"xgb_random_search_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n\n# Convert best_params to JSON string for VARIANT type\nimport json\n\nbest_params_json = json.dumps(\n    {\n        k: float(v) if isinstance(v, (np.integer, np.floating)) else v\n        for k, v in best_params.items()\n    }\n)\n\ninsert_sql = f\"\"\"\n    INSERT INTO BD_AA_DEV.SC_STORAGE_BMX_PS.HYPERPARAMETER_RESULTS\n    (search_id, algorithm, best_params, best_cv_rmse, best_cv_mae, val_rmse, val_mae, n_iter, sample_size)\n    VALUES (\n        '{search_id}',\n        'XGBoost',\n        PARSE_JSON('{best_params_json}'),\n        {np.sqrt(-best_score):.6f},\n        NULL,\n        {val_rmse:.6f},\n        {val_mae:.6f},\n        {n_iter},\n        {sampled_count}\n    )\n\"\"\"\n\nsession.sql(insert_sql).collect()\n\nprint(f\"‚úÖ Hyperparameters saved to HYPERPARAMETER_RESULTS\")\nprint(f\"   Search ID: {search_id}\")\n\n# Verify save\nsaved_results = session.sql(\n    f\"\"\"\n    SELECT \n        search_id,\n        algorithm,\n        best_cv_rmse,\n        val_rmse,\n        val_mae,\n        created_at\n    FROM BD_AA_DEV.SC_STORAGE_BMX_PS.HYPERPARAMETER_RESULTS\n    WHERE search_id = '{search_id}'\n\"\"\"\n)\n\nprint(\"\\nüìä Saved Results:\")\nsaved_results.show()\n",
      "id": "304b33d1-110f-41cd-ad7d-28c8953838ff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 7. Summary\n",
      "id": "886b97a2-4c0d-43b3-8147-81c51b6d29e3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"‚úÖ HYPERPARAMETER SEARCH COMPLETE!\")\nprint(\"=\" * 80)\n\nprint(\"\\nüìã Summary:\")\nprint(f\"   ‚úÖ Algorithm: XGBoost\")\nprint(f\"   ‚úÖ Search method: Random Search\")\nprint(f\"   ‚úÖ Iterations: {n_iter}\")\nprint(f\"   ‚úÖ Sample size: {sampled_count:,} ({sample_rate*100:.0f}% of total)\")\nprint(f\"   ‚úÖ Best CV RMSE: {np.sqrt(-best_score):.4f}\")\nprint(f\"   ‚úÖ Validation RMSE: {val_rmse:.4f}\")\nprint(f\"   ‚úÖ Search ID: {search_id}\")\n\nprint(\"\\nüí° Next Steps:\")\nprint(\"   1. Review best hyperparameters\")\nprint(\"   2. Run 04_many_model_training.py to train model with best hyperparameters\")\nprint(\"   3. Use full dataset for final training\")\n\nprint(\"\\n\" + \"=\" * 80)\n",
      "id": "d55a770d-51c5-47ef-b4bd-f3b85449605c",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}