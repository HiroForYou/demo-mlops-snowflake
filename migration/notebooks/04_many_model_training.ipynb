{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "# Migration: Many Model Training (MMT) - XGBoost\n\n## Overview\nThis script trains a single XGBoost model using Many Model Training (MMT) framework.\nEven though we have one model, we use MMT for consistency and future scalability.\n\n## What We'll Do:\n1. Load best hyperparameters from hyperparameter search\n2. Define training function for MMT\n3. Execute MMT training with full dataset\n4. Register model in Model Registry\n",
      "id": "e207a462-eef3-4766-8e75-b7a11b4a4222"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "from snowflake.snowpark.context import get_active_session\nfrom snowflake.ml.modeling.distributors.many_model import ManyModelTraining\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml.model import task\nimport time\nfrom datetime import datetime\nimport json\n\nsession = get_active_session()\n\n# Set context\nsession.sql(\"USE WAREHOUSE ARCA_DEMO_WH\").collect()\nsession.sql(\"USE DATABASE BD_AA_DEV\").collect()\nsession.sql(\"USE SCHEMA SC_STORAGE_BMX_PS\").collect()\n\nprint(f\"‚úÖ Connected to Snowflake\")\nprint(f\"   Database: {session.get_current_database()}\")\nprint(f\"   Schema: {session.get_current_schema()}\")\n",
      "id": "c9167908-3414-4c03-b135-714b0ed89b86",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 1. Setup Model Registry & Staging\n",
      "id": "63499c79-70d3-48b7-9236-1ce4bd6a1443"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "session.sql(\"CREATE SCHEMA IF NOT EXISTS BD_AA_DEV.MODEL_REGISTRY\").collect()\nsession.sql(\"CREATE STAGE IF NOT EXISTS BD_AA_DEV.MODEL_REGISTRY.MMT_MODELS\").collect()\n\nregistry = Registry(\n    session=session,\n    database_name=\"BD_AA_DEV\",\n    schema_name=\"MODEL_REGISTRY\"\n)\n\nprint(\"‚úÖ Model Registry initialized\")\nprint(\"‚úÖ Stage for MMT models created\")\n",
      "id": "2b7d9853-a858-4339-bfc1-57a0814b7c60",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 2. Load Best Hyperparameters\n",
      "id": "edff09b5-4a7b-4ac3-890e-fbd8ea474206"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üìä LOADING BEST HYPERPARAMETERS\")\nprint(\"=\"*80)\n\n# Get most recent hyperparameter search results\nhyperparams_df = session.sql(\"\"\"\n    SELECT \n        search_id,\n        algorithm,\n        best_params,\n        best_cv_rmse,\n        val_rmse,\n        val_mae,\n        created_at\n    FROM BD_AA_DEV.SC_STORAGE_BMX_PS.HYPERPARAMETER_RESULTS\n    WHERE algorithm = 'XGBoost'\n    ORDER BY created_at DESC\n    LIMIT 1\n\"\"\")\n\nhyperparams_result = hyperparams_df.collect()\n\nif len(hyperparams_result) == 0:\n    raise ValueError(\"No hyperparameter results found! Please run 03_hyperparameter_search.py first\")\n\nbest_result = hyperparams_result[0]\nbest_params_json = best_result['BEST_PARAMS']\nsearch_id = best_result['SEARCH_ID']\n\nprint(f\"\\n‚úÖ Best hyperparameters loaded\")\nprint(f\"   Search ID: {search_id}\")\nprint(f\"   Best CV RMSE: {best_result['BEST_CV_RMSE']:.4f}\")\nprint(f\"   Validation RMSE: {best_result['VAL_RMSE']:.4f}\")\n\n# Parse hyperparameters\nif isinstance(best_params_json, str):\n    best_params = json.loads(best_params_json)\nelse:\n    best_params = best_params_json\n\nprint(f\"\\nüìã Best Hyperparameters:\")\nfor param, value in sorted(best_params.items()):\n    print(f\"   {param}: {value}\")\n",
      "id": "40a292b8-e19b-4372-969f-bbba81dc2b7a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 3. Prepare Training Data\n",
      "id": "3c160ad0-b42f-4322-9e82-ecf4addca86e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üìä PREPARING TRAINING DATA\")\nprint(\"=\"*80)\n\n# Load cleaned training data\ntraining_df = session.table(\"BD_AA_DEV.SC_STORAGE_BMX_PS.TRAIN_DATASET_CLEANED\")\n\nprint(f\"\\n‚úÖ Training data loaded\")\nprint(f\"   Total records: {training_df.count():,}\")\nprint(f\"   Columns: {len(training_df.columns)}\")\n",
      "id": "084c2a29-30aa-40a5-a9b7-3c2724ca3058",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 4. Define Training Function for MMT\n",
      "id": "bf2acc59-6c74-40d0-8f1b-2906ed8b7c8f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üîß DEFINING TRAINING FUNCTION\")\nprint(\"=\"*80)\n\ndef train_model(data_connector, context):\n    \"\"\"\n    Train XGBoost model for uni_box_week regression.\n    \n    This function:\n    1. Receives data via MMT data connector\n    2. Loads best hyperparameters\n    3. Trains XGBoost model\n    4. Evaluates on test set\n    5. Returns trained model\n    \n    Args:\n        data_connector: Snowflake data connector (provided by MMT)\n        context: Contains partition_id (if partitioned)\n    \n    Returns:\n        Trained XGBoost model object\n    \"\"\"\n    import pandas as pd\n    from xgboost import XGBRegressor\n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import mean_squared_error, mean_absolute_error\n    import numpy as np\n    import json\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"üöÄ Training XGBoost model\")\n    print(f\"{'='*80}\")\n    \n    # Load data\n    df = data_connector.to_pandas()\n    print(f\"üìä Data shape: {df.shape}\")\n    \n    # Define excluded columns\n    excluded_cols = [\n        'customer_id', 'brand_pres_ret', 'week', \n        'group', 'stats_group', 'percentile_group', 'stats_ntile_group'\n    ]\n    \n    # Get feature columns\n    feature_cols = [col for col in df.columns \n                   if col not in excluded_cols + ['uni_box_week']]\n    \n    target_col = 'uni_box_week'\n    \n    X = df[feature_cols].fillna(0)\n    y = df[target_col].fillna(0)\n    \n    print(f\"   Features: {len(feature_cols)}\")\n    print(f\"   Target range: [{y.min():.2f}, {y.max():.2f}]\")\n    \n    # Split train/test\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    \n    print(f\"   Training set: {X_train.shape[0]:,} samples\")\n    print(f\"   Test set: {X_test.shape[0]:,} samples\")\n    \n    # Load best hyperparameters\n    # Get from context or use default\n    try:\n        # Try to get hyperparameters from context\n        if hasattr(context, 'hyperparameters'):\n            params = context.hyperparameters\n        else:\n            # Load from table (this is a workaround - in practice, pass via context)\n            params = best_params\n    except:\n        params = best_params\n    \n    # Convert hyperparameters to proper types\n    xgb_params = {}\n    for k, v in params.items():\n        if isinstance(v, (int, float)):\n            xgb_params[k] = v\n        elif isinstance(v, (np.integer, np.floating)):\n            xgb_params[k] = float(v) if isinstance(v, np.floating) else int(v)\n        else:\n            xgb_params[k] = v\n    \n    # Ensure required parameters\n    xgb_params['random_state'] = 42\n    xgb_params['n_jobs'] = -1\n    xgb_params['objective'] = 'reg:squarederror'\n    xgb_params['eval_metric'] = 'rmse'\n    \n    print(f\"\\n   Training XGBoost with hyperparameters...\")\n    \n    # Train model\n    model = XGBRegressor(**xgb_params)\n    model.fit(X_train, y_train)\n    \n    # Evaluate\n    y_pred = model.predict(X_test)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    mae = mean_absolute_error(y_test, y_pred)\n    \n    print(f\"\\n   ‚úÖ Model trained\")\n    print(f\"      RMSE: {rmse:.2f}\")\n    print(f\"      MAE: {mae:.2f}\")\n    print(f\"{'='*80}\\n\")\n    \n    # Attach metadata to model\n    model.rmse = rmse\n    model.mae = mae\n    model.training_samples = X_train.shape[0]\n    model.test_samples = X_test.shape[0]\n    model.feature_cols = feature_cols\n    model.hyperparameters = xgb_params\n    \n    return model\n\nprint(\"‚úÖ Training function defined\")\n",
      "id": "4486f926-8824-4d55-ba0a-0ccc34cd9d0d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 5. Execute Many Model Training (MMT)\n",
      "id": "0b7021f6-ebd5-41cb-a0cc-9899c7164548"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üöÄ STARTING MANY MODEL TRAINING (MMT)\")\nprint(\"=\"*80)\nprint(\"\\nTraining XGBoost model using MMT framework\")\nprint(\"Using best hyperparameters from Random Search\\n\")\n\nstart_time = time.time()\n\n# Create MMT trainer\ntrainer = ManyModelTraining(\n    train_model,\n    \"BD_AA_DEV.MODEL_REGISTRY.MMT_MODELS\"\n)\n\n# Execute training (without partition_by for single model)\ntraining_run = trainer.run(\n    snowpark_dataframe=training_df,\n    run_id=f\"uni_box_regression_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n)\n\nprint(\"\\n‚è≥ Training in progress... Monitoring completion...\\n\")\n\n# Monitor with timeout\nimport time as time_module\nmax_wait = 1800  # 30 minutes max\ncheck_interval = 10  # Check every 10 seconds\nelapsed = 0\ncompleted = False\n\nwhile elapsed < max_wait:\n    time_module.sleep(check_interval)\n    elapsed += check_interval\n    \n    try:\n        done_count = 0\n        total_count = 0\n        for partition_id in training_run.partition_details:\n            total_count += 1\n            status = training_run.partition_details[partition_id].status\n            if status.name == 'DONE' or status.name == 'FAILED':\n                done_count += 1\n        \n        print(f\"‚è±Ô∏è  {elapsed}s elapsed - Progress: {done_count}/{total_count} models completed\", end='\\r')\n        \n        if done_count == total_count:\n            print(\"\\n‚úÖ All models completed!\" + \" \"*50)\n            completed = True\n            break\n    except:\n        print(f\"‚è±Ô∏è  {elapsed}s elapsed - Waiting for status update...\", end='\\r')\n\nif not completed:\n    print(\"\\n‚è±Ô∏è  Timeout reached - Verifying completion via stage...\" + \" \"*30)\n    stage_files = session.sql(f\"LIST @BD_AA_DEV.MODEL_REGISTRY.MMT_MODELS PATTERN='.*{training_run.run_id}.*'\").collect()\n    if len(stage_files) > 0:\n        print(f\"‚úÖ Found {len(stage_files)} model files in stage - Training completed successfully!\")\n        completed = True\n\nend_time = time.time()\nelapsed_minutes = (end_time - start_time) / 60\n\nprint(\"\\n\" + \"=\"*80)\nprint(f\"‚úÖ TRAINING COMPLETE! Status: {'COMPLETED' if completed else 'UNKNOWN'}\")\nprint(\"=\"*80)\nprint(f\"\\n‚è±Ô∏è  Total training time: {elapsed_minutes:.2f} minutes\")\n",
      "id": "ebf8a20c-f998-4bf3-ad1a-4ffdea706e9f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 6. Review Training Results\n",
      "id": "14ad6608-00a7-481e-a442-b4c7cf7a77bf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\nüìä Training Results:\\n\")\n\nfor partition_id in training_run.partition_details:\n    details = training_run.partition_details[partition_id]\n    \n    if details.status.name == \"DONE\":\n        try:\n            model = training_run.get_model(partition_id)\n            \n            print(f\"\\n‚úÖ {partition_id if partition_id else 'DEFAULT'}:\")\n            print(f\"   RMSE: {model.rmse:.2f}\")\n            print(f\"   MAE: {model.mae:.2f}\")\n            print(f\"   Training samples: {model.training_samples:,}\")\n            print(f\"   Test samples: {model.test_samples:,}\")\n        except Exception as e:\n            print(f\"\\n‚ö†Ô∏è  {partition_id}: Could not load model - {str(e)[:100]}\")\n    else:\n        print(f\"\\n‚ùå {partition_id}: Training failed\")\n        print(f\"   Status: {details.status}\")\n",
      "id": "03c81bf5-c692-420c-a855-6857b3407c56",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 7. Register Model in Model Registry\n",
      "id": "3bccd97b-2628-429b-8dfe-06cbe652e45f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üìù REGISTERING MODEL IN MODEL REGISTRY\")\nprint(\"=\"*80)\n\nversion_date = datetime.now().strftime('%Y%m%d_%H%M')\nregistered_models = {}\n\nfor partition_id in training_run.partition_details:\n    details = training_run.partition_details[partition_id]\n    \n    if details.status.name == \"DONE\":\n        try:\n            model = training_run.get_model(partition_id)\n            \n            model_name = \"uni_box_regression_model\"\n            \n            # Prepare sample input\n            sample_input = training_df.select(model.feature_cols).limit(5)\n            \n            print(f\"\\nRegistering model...\")\n            \n            mv = registry.log_model(\n                model,\n                model_name=model_name,\n                version_name=f\"v_{version_date}\",\n                comment=f\"XGBoost regression model for uni_box_week - Hyperparameters from {search_id}\",\n                metrics={\n                    \"rmse\": float(model.rmse),\n                    \"mae\": float(model.mae),\n                    \"training_samples\": int(model.training_samples),\n                    \"test_samples\": int(model.test_samples),\n                    \"algorithm\": \"XGBoost\",\n                    \"hyperparameter_search_id\": search_id\n                },\n                sample_input_data=sample_input,\n                task=task.Task.TABULAR_REGRESSION\n            )\n            \n            registered_models[partition_id] = {\n                'model_name': model_name,\n                'version': f\"v_{version_date}\",\n                'model_version': mv\n            }\n            \n            print(f\"‚úÖ Model registered: {model_name} v_{version_date}\")\n            print(f\"   RMSE: {model.rmse:.2f}, MAE: {model.mae:.2f}\")\n            \n        except Exception as e:\n            print(f\"‚ùå Error registering model: {str(e)[:200]}\")\n\nprint(f\"\\n‚úÖ {len(registered_models)} model(s) registered successfully!\")\n",
      "id": "17c71289-6376-4efc-a7d2-19a1ddd4111a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 8. Set Production Alias\n",
      "id": "5e93827f-08bc-4fba-a2d5-4006028ecd49"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\nüè∑Ô∏è  Setting PRODUCTION aliases...\\n\")\n\nfor partition_id, model_info in registered_models.items():\n    model_name = model_info['model_name']\n    version = model_info['version']\n    model_version = model_info['model_version']\n    \n    try:\n        # Remove existing PRODUCTION alias\n        try:\n            model_ref = registry.get_model(model_name)\n            model_ref.default.unset_alias(\"PRODUCTION\")\n        except:\n            pass\n        \n        # Set alias on new version\n        model_version.set_alias(\"PRODUCTION\")\n        print(f\"‚úÖ {model_name}: PRODUCTION ‚Üí {version}\")\n    except Exception as e:\n        print(f\"‚ö†Ô∏è  {model_name}: Error setting alias - {str(e)[:100]}\")\n\nprint(\"\\n‚úÖ All production aliases configured!\")\n",
      "id": "92160c08-221e-4746-ba29-081fdc3d8286",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 9. Summary\n",
      "id": "9c72b050-b37a-456c-808f-46570c08e898"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üéâ MANY MODEL TRAINING (MMT) COMPLETE!\")\nprint(\"=\"*80)\n\nprint(\"\\nüìä Summary:\")\nprint(f\"   ‚úÖ Models trained: {len(registered_models)}\")\nprint(f\"   ‚è±Ô∏è  Training time: {elapsed_minutes:.2f} minutes\")\nprint(f\"   üîß Algorithm: XGBoost\")\nprint(f\"   üìà Hyperparameters: From {search_id}\")\n\nif registered_models:\n    for partition_id, info in registered_models.items():\n        model = training_run.get_model(partition_id)\n        print(f\"\\nüèÜ Model Performance:\")\n        print(f\"   RMSE: {model.rmse:.2f}\")\n        print(f\"   MAE: {model.mae:.2f}\")\n        print(f\"   Training samples: {model.training_samples:,}\")\n\nprint(\"\\nüí° Next Steps:\")\nprint(\"   1. Review model performance\")\nprint(\"   2. Run 05_create_partitioned_model.py to create partitioned model\")\nprint(\"   3. Run 06_partitioned_inference_batch.py for batch inference\")\n\nprint(\"\\n\" + \"=\"*80)\n",
      "id": "cb6cf9f0-6f01-4b08-a070-b991f5afdf8e",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}