{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "# Migration: Many Model Training (MMT) - XGBoost\n\n## Overview\nThis script trains a single XGBoost model using Many Model Training (MMT) framework.\nEven though we have one model, we use MMT for consistency and future scalability.\n\n## What We'll Do:\n1. Load best hyperparameters from hyperparameter search\n2. Define training function for MMT\n3. Execute MMT training with full dataset\n4. Register model in Model Registry\n",
      "id": "ba942bf4-d4bb-4d59-80a0-29e531185019"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "from snowflake.snowpark.context import get_active_session\nfrom snowflake.ml.modeling.distributors.many_model import ManyModelTraining\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml.model import task\nimport time\nfrom datetime import datetime\nimport json\n\nsession = get_active_session()\n\n# Set context\nsession.sql(\"USE WAREHOUSE ARCA_DEMO_WH\").collect()\nsession.sql(\"USE DATABASE BD_AA_DEV\").collect()\nsession.sql(\"USE SCHEMA SC_STORAGE_BMX_PS\").collect()\n\nprint(f\"‚úÖ Connected to Snowflake\")\nprint(f\"   Database: {session.get_current_database()}\")\nprint(f\"   Schema: {session.get_current_schema()}\")\n",
      "id": "cf50a940-add7-4439-9c3b-62cc8bca0c96",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 1. Setup Model Registry & Staging\n",
      "id": "9a8f8997-c7e2-4f06-a0ac-92a3f71d434a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "session.sql(\"CREATE SCHEMA IF NOT EXISTS BD_AA_DEV.MODEL_REGISTRY\").collect()\nsession.sql(\"CREATE STAGE IF NOT EXISTS BD_AA_DEV.MODEL_REGISTRY.MMT_MODELS\").collect()\n\nregistry = Registry(\n    session=session,\n    database_name=\"BD_AA_DEV\",\n    schema_name=\"MODEL_REGISTRY\"\n)\n\nprint(\"‚úÖ Model Registry initialized\")\nprint(\"‚úÖ Stage for MMT models created\")\n",
      "id": "f107d012-423c-4c64-8abc-09ba130cbed7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 2. Load Best Hyperparameters\n",
      "id": "3b709f0a-d182-4c35-84b8-2dc8d4744684"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üìä LOADING BEST HYPERPARAMETERS\")\nprint(\"=\"*80)\n\n# Get most recent hyperparameter search results\nhyperparams_df = session.sql(\"\"\"\n    SELECT \n        search_id,\n        algorithm,\n        best_params,\n        best_cv_rmse,\n        val_rmse,\n        val_mae,\n        created_at\n    FROM BD_AA_DEV.SC_STORAGE_BMX_PS.HYPERPARAMETER_RESULTS\n    WHERE algorithm = 'XGBoost'\n    ORDER BY created_at DESC\n    LIMIT 1\n\"\"\")\n\nhyperparams_result = hyperparams_df.collect()\n\nif len(hyperparams_result) == 0:\n    raise ValueError(\"No hyperparameter results found! Please run 03_hyperparameter_search.py first\")\n\nbest_result = hyperparams_result[0]\nbest_params_json = best_result['BEST_PARAMS']\nsearch_id = best_result['SEARCH_ID']\n\nprint(f\"\\n‚úÖ Best hyperparameters loaded\")\nprint(f\"   Search ID: {search_id}\")\nprint(f\"   Best CV RMSE: {best_result['BEST_CV_RMSE']:.4f}\")\nprint(f\"   Validation RMSE: {best_result['VAL_RMSE']:.4f}\")\n\n# Parse hyperparameters\nif isinstance(best_params_json, str):\n    best_params = json.loads(best_params_json)\nelse:\n    best_params = best_params_json\n\nprint(f\"\\nüìã Best Hyperparameters:\")\nfor param, value in sorted(best_params.items()):\n    print(f\"   {param}: {value}\")\n",
      "id": "5acae0d6-43db-407b-a937-c412aa0dc2e1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 3. Prepare Training Data\n",
      "id": "039493b7-e232-45e3-b2c0-e146204bf45d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üìä PREPARING TRAINING DATA\")\nprint(\"=\"*80)\n\n# Load cleaned training data\ntraining_df = session.table(\"BD_AA_DEV.SC_STORAGE_BMX_PS.TRAIN_DATASET_CLEANED\")\n\nprint(f\"\\n‚úÖ Training data loaded\")\nprint(f\"   Total records: {training_df.count():,}\")\nprint(f\"   Columns: {len(training_df.columns)}\")\n",
      "id": "437d4576-fbd5-46bf-a9ab-606dda2d5b4d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 4. Define Training Function for MMT\n",
      "id": "d3317831-010c-47ff-950d-00dbf06cec28"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üîß DEFINING TRAINING FUNCTION\")\nprint(\"=\"*80)\n\ndef train_model(data_connector, context):\n    \"\"\"\n    Train XGBoost model for uni_box_week regression.\n    \n    This function:\n    1. Receives data via MMT data connector\n    2. Loads best hyperparameters\n    3. Trains XGBoost model\n    4. Evaluates on test set\n    5. Returns trained model\n    \n    Args:\n        data_connector: Snowflake data connector (provided by MMT)\n        context: Contains partition_id (if partitioned)\n    \n    Returns:\n        Trained XGBoost model object\n    \"\"\"\n    import pandas as pd\n    from xgboost import XGBRegressor\n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import mean_squared_error, mean_absolute_error\n    import numpy as np\n    import json\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"üöÄ Training XGBoost model\")\n    print(f\"{'='*80}\")\n    \n    # Load data\n    df = data_connector.to_pandas()\n    print(f\"üìä Data shape: {df.shape}\")\n    \n    # Define excluded columns\n    excluded_cols = [\n        'customer_id', 'brand_pres_ret', 'week', \n        'group', 'stats_group', 'percentile_group', 'stats_ntile_group'\n    ]\n    \n    # Get feature columns\n    feature_cols = [col for col in df.columns \n                   if col not in excluded_cols + ['uni_box_week']]\n    \n    target_col = 'uni_box_week'\n    \n    X = df[feature_cols].fillna(0)\n    y = df[target_col].fillna(0)\n    \n    print(f\"   Features: {len(feature_cols)}\")\n    print(f\"   Target range: [{y.min():.2f}, {y.max():.2f}]\")\n    \n    # Split train/test\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    \n    print(f\"   Training set: {X_train.shape[0]:,} samples\")\n    print(f\"   Test set: {X_test.shape[0]:,} samples\")\n    \n    # Load best hyperparameters\n    # Get from context or use default\n    try:\n        # Try to get hyperparameters from context\n        if hasattr(context, 'hyperparameters'):\n            params = context.hyperparameters\n        else:\n            # Load from table (this is a workaround - in practice, pass via context)\n            params = best_params\n    except:\n        params = best_params\n    \n    # Convert hyperparameters to proper types\n    xgb_params = {}\n    for k, v in params.items():\n        if isinstance(v, (int, float)):\n            xgb_params[k] = v\n        elif isinstance(v, (np.integer, np.floating)):\n            xgb_params[k] = float(v) if isinstance(v, np.floating) else int(v)\n        else:\n            xgb_params[k] = v\n    \n    # Ensure required parameters\n    xgb_params['random_state'] = 42\n    xgb_params['n_jobs'] = -1\n    xgb_params['objective'] = 'reg:squarederror'\n    xgb_params['eval_metric'] = 'rmse'\n    \n    print(f\"\\n   Training XGBoost with hyperparameters...\")\n    \n    # Train model\n    model = XGBRegressor(**xgb_params)\n    model.fit(X_train, y_train)\n    \n    # Evaluate\n    y_pred = model.predict(X_test)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    mae = mean_absolute_error(y_test, y_pred)\n    \n    print(f\"\\n   ‚úÖ Model trained\")\n    print(f\"      RMSE: {rmse:.2f}\")\n    print(f\"      MAE: {mae:.2f}\")\n    print(f\"{'='*80}\\n\")\n    \n    # Attach metadata to model\n    model.rmse = rmse\n    model.mae = mae\n    model.training_samples = X_train.shape[0]\n    model.test_samples = X_test.shape[0]\n    model.feature_cols = feature_cols\n    model.hyperparameters = xgb_params\n    \n    return model\n\nprint(\"‚úÖ Training function defined\")\n",
      "id": "97c7d7e6-abdb-4d66-ae42-298595b04e33",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 5. Execute Many Model Training (MMT)\n",
      "id": "ac5dad0d-1884-4e29-bff6-045afe1d5e4f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üöÄ STARTING MANY MODEL TRAINING (MMT)\")\nprint(\"=\"*80)\nprint(\"\\nTraining XGBoost model using MMT framework\")\nprint(\"Using best hyperparameters from Random Search\\n\")\n\nstart_time = time.time()\n\n# Create MMT trainer\ntrainer = ManyModelTraining(\n    train_model,\n    \"BD_AA_DEV.MODEL_REGISTRY.MMT_MODELS\"\n)\n\n# Execute training (without partition_by for single model)\ntraining_run = trainer.run(\n    snowpark_dataframe=training_df,\n    run_id=f\"uni_box_regression_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n)\n\nprint(\"\\n‚è≥ Training in progress... Monitoring completion...\\n\")\n\n# Monitor with timeout\nimport time as time_module\nmax_wait = 1800  # 30 minutes max\ncheck_interval = 10  # Check every 10 seconds\nelapsed = 0\ncompleted = False\n\nwhile elapsed < max_wait:\n    time_module.sleep(check_interval)\n    elapsed += check_interval\n    \n    try:\n        done_count = 0\n        total_count = 0\n        for partition_id in training_run.partition_details:\n            total_count += 1\n            status = training_run.partition_details[partition_id].status\n            if status.name == 'DONE' or status.name == 'FAILED':\n                done_count += 1\n        \n        print(f\"‚è±Ô∏è  {elapsed}s elapsed - Progress: {done_count}/{total_count} models completed\", end='\\r')\n        \n        if done_count == total_count:\n            print(\"\\n‚úÖ All models completed!\" + \" \"*50)\n            completed = True\n            break\n    except:\n        print(f\"‚è±Ô∏è  {elapsed}s elapsed - Waiting for status update...\", end='\\r')\n\nif not completed:\n    print(\"\\n‚è±Ô∏è  Timeout reached - Verifying completion via stage...\" + \" \"*30)\n    stage_files = session.sql(f\"LIST @BD_AA_DEV.MODEL_REGISTRY.MMT_MODELS PATTERN='.*{training_run.run_id}.*'\").collect()\n    if len(stage_files) > 0:\n        print(f\"‚úÖ Found {len(stage_files)} model files in stage - Training completed successfully!\")\n        completed = True\n\nend_time = time.time()\nelapsed_minutes = (end_time - start_time) / 60\n\nprint(\"\\n\" + \"=\"*80)\nprint(f\"‚úÖ TRAINING COMPLETE! Status: {'COMPLETED' if completed else 'UNKNOWN'}\")\nprint(\"=\"*80)\nprint(f\"\\n‚è±Ô∏è  Total training time: {elapsed_minutes:.2f} minutes\")\n",
      "id": "88ee347f-0286-4c41-948c-bcfdf3e7e28b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 6. Review Training Results\n",
      "id": "48e5b2e1-75d0-42a0-abee-ce3b198f55eb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\nüìä Training Results:\\n\")\n\nfor partition_id in training_run.partition_details:\n    details = training_run.partition_details[partition_id]\n    \n    if details.status.name == \"DONE\":\n        try:\n            model = training_run.get_model(partition_id)\n            \n            print(f\"\\n‚úÖ {partition_id if partition_id else 'DEFAULT'}:\")\n            print(f\"   RMSE: {model.rmse:.2f}\")\n            print(f\"   MAE: {model.mae:.2f}\")\n            print(f\"   Training samples: {model.training_samples:,}\")\n            print(f\"   Test samples: {model.test_samples:,}\")\n        except Exception as e:\n            print(f\"\\n‚ö†Ô∏è  {partition_id}: Could not load model - {str(e)[:100]}\")\n    else:\n        print(f\"\\n‚ùå {partition_id}: Training failed\")\n        print(f\"   Status: {details.status}\")\n",
      "id": "f84ceef8-f9b1-4fb3-aa3b-9acc32068cd3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 7. Register Model in Model Registry\n",
      "id": "ce19043d-e999-4b75-823f-2366adeb1461"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üìù REGISTERING MODEL IN MODEL REGISTRY\")\nprint(\"=\"*80)\n\nversion_date = datetime.now().strftime('%Y%m%d_%H%M')\nregistered_models = {}\n\nfor partition_id in training_run.partition_details:\n    details = training_run.partition_details[partition_id]\n    \n    if details.status.name == \"DONE\":\n        try:\n            model = training_run.get_model(partition_id)\n            \n            model_name = \"uni_box_regression_model\"\n            \n            # Prepare sample input\n            sample_input = training_df.select(model.feature_cols).limit(5)\n            \n            print(f\"\\nRegistering model...\")\n            \n            mv = registry.log_model(\n                model,\n                model_name=model_name,\n                version_name=f\"v_{version_date}\",\n                comment=f\"XGBoost regression model for uni_box_week - Hyperparameters from {search_id}\",\n                metrics={\n                    \"rmse\": float(model.rmse),\n                    \"mae\": float(model.mae),\n                    \"training_samples\": int(model.training_samples),\n                    \"test_samples\": int(model.test_samples),\n                    \"algorithm\": \"XGBoost\",\n                    \"hyperparameter_search_id\": search_id\n                },\n                sample_input_data=sample_input,\n                task=task.Task.TABULAR_REGRESSION\n            )\n            \n            registered_models[partition_id] = {\n                'model_name': model_name,\n                'version': f\"v_{version_date}\",\n                'model_version': mv\n            }\n            \n            print(f\"‚úÖ Model registered: {model_name} v_{version_date}\")\n            print(f\"   RMSE: {model.rmse:.2f}, MAE: {model.mae:.2f}\")\n            \n        except Exception as e:\n            print(f\"‚ùå Error registering model: {str(e)[:200]}\")\n\nprint(f\"\\n‚úÖ {len(registered_models)} model(s) registered successfully!\")\n",
      "id": "15d44af6-48c7-46e5-8dbc-43c01f44aa88",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 8. Set Production Alias\n",
      "id": "202eecdd-3180-4a01-8e97-8937ece15da2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\nüè∑Ô∏è  Setting PRODUCTION aliases...\\n\")\n\nfor partition_id, model_info in registered_models.items():\n    model_name = model_info['model_name']\n    version = model_info['version']\n    model_version = model_info['model_version']\n    \n    try:\n        # Remove existing PRODUCTION alias\n        try:\n            model_ref = registry.get_model(model_name)\n            model_ref.default.unset_alias(\"PRODUCTION\")\n        except:\n            pass\n        \n        # Set alias on new version\n        model_version.set_alias(\"PRODUCTION\")\n        print(f\"‚úÖ {model_name}: PRODUCTION ‚Üí {version}\")\n    except Exception as e:\n        print(f\"‚ö†Ô∏è  {model_name}: Error setting alias - {str(e)[:100]}\")\n\nprint(\"\\n‚úÖ All production aliases configured!\")\n",
      "id": "a70541b1-4990-462e-9609-a0306e79a7d8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 9. Summary\n",
      "id": "04e4de0e-8598-4d78-ba1f-2a12d6ac6c3e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üéâ MANY MODEL TRAINING (MMT) COMPLETE!\")\nprint(\"=\"*80)\n\nprint(\"\\nüìä Summary:\")\nprint(f\"   ‚úÖ Models trained: {len(registered_models)}\")\nprint(f\"   ‚è±Ô∏è  Training time: {elapsed_minutes:.2f} minutes\")\nprint(f\"   üîß Algorithm: XGBoost\")\nprint(f\"   üìà Hyperparameters: From {search_id}\")\n\nif registered_models:\n    for partition_id, info in registered_models.items():\n        model = training_run.get_model(partition_id)\n        print(f\"\\nüèÜ Model Performance:\")\n        print(f\"   RMSE: {model.rmse:.2f}\")\n        print(f\"   MAE: {model.mae:.2f}\")\n        print(f\"   Training samples: {model.training_samples:,}\")\n\nprint(\"\\nüí° Next Steps:\")\nprint(\"   1. Review model performance\")\nprint(\"   2. Run 05_create_partitioned_model.py to create partitioned model\")\nprint(\"   3. Run 06_partitioned_inference_batch.py for batch inference\")\n\nprint(\"\\n\" + \"=\"*80)\n",
      "id": "07904aa9-f0a5-4fc3-a055-3faa6f0c1fec",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}