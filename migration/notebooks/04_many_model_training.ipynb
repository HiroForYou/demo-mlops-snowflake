{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "# MMT: 16 Models (LGBM/XGB per stats_ntile_group)\nHyperparameters per group from script 03 ‚Üí train ‚Üí register in Model Registry.\n",
      "id": "79063a71-6b0d-456c-8815-83c253a853d0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "from snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark import functions as F\nfrom snowflake.ml.modeling.distributors.many_model import ManyModelTraining\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml.feature_store import FeatureStore\nfrom snowflake.ml.experiment import ExperimentTracking\nfrom snowflake.ml.model import task\nimport time\nfrom datetime import datetime\nimport json\n\nsession = get_active_session()\n\n# Configuration: Database, schemas, and tables\nDATABASE = \"BD_AA_DEV\"\nSTORAGE_SCHEMA = \"SC_STORAGE_BMX_PS\"\nFEATURES_SCHEMA = \"SC_FEATURES_BMX\"\nMODELS_SCHEMA = \"SC_MODELS_BMX\"\nTRAIN_TABLE_CLEANED = f\"{DATABASE}.{STORAGE_SCHEMA}.TRAIN_DATASET_CLEANED\"\nFEATURES_TABLE = f\"{DATABASE}.{FEATURES_SCHEMA}.UNI_BOX_FEATURES\"\nHYPERPARAMETER_RESULTS_TABLE = f\"{DATABASE}.{MODELS_SCHEMA}.HYPERPARAMETER_RESULTS\"\nMMT_STAGE = f\"{DATABASE}.{MODELS_SCHEMA}.MMT_MODELS\"\nDEFAULT_WAREHOUSE = \"WH_AA_DEV_DS_SQL\"\n\n# Column constants\nTARGET_COLUMN = \"UNI_BOX_WEEK\"\nSTATS_NTILE_GROUP_COL = \"STATS_NTILE_GROUP\"\n\n# Excluded columns (metadata columns, not features) - defined once at the beginning\nEXCLUDED_COLS = [\n    \"CUSTOMER_ID\",\n    \"BRAND_PRES_RET\",\n    \"PROD_KEY\",\n    \"WEEK\",\n    \"FEATURE_TIMESTAMP\",\n    STATS_NTILE_GROUP_COL,\n]\n\n# Cluster scaling configuration\nCLUSTER_SIZE_MMT = 5\nCLUSTER_SIZE_MIN_MMT = 2\nCLUSTER_SIZE_DOWN = 1\n\nsession.sql(f\"USE DATABASE {DATABASE}\").collect()\nsession.sql(f\"USE SCHEMA {STORAGE_SCHEMA}\").collect()\nprint(f\"‚úÖ {session.get_current_database()}.{session.get_current_schema()}\")\n\nUSE_CLEANED_TABLES = False\nMMT_SAMPLE_FRACTION = None  # None = 100%\n\nGROUP_MODEL = {\n    \"group_stat_0_1\": \"LGBMRegressor\",\n    \"group_stat_0_2\": \"LGBMRegressor\",\n    \"group_stat_0_3\": \"LGBMRegressor\",\n    \"group_stat_0_4\": \"LGBMRegressor\",\n    \"group_stat_1_1\": \"LGBMRegressor\",\n    \"group_stat_1_2\": \"LGBMRegressor\",\n    \"group_stat_1_3\": \"XGBRegressor\",\n    \"group_stat_1_4\": \"XGBRegressor\",\n    \"group_stat_2_1\": \"LGBMRegressor\",\n    \"group_stat_2_2\": \"LGBMRegressor\",\n    \"group_stat_2_3\": \"XGBRegressor\",\n    \"group_stat_2_4\": \"XGBRegressor\",\n    \"group_stat_3_1\": \"LGBMRegressor\",\n    \"group_stat_3_2\": \"LGBMRegressor\",\n    \"group_stat_3_3\": \"LGBMRegressor\",\n    \"group_stat_3_4\": \"XGBRegressor\",\n}\n_DEFAULT_MODEL = \"XGBRegressor\"\n",
      "id": "11854f7d-752b-42f5-9c2b-a4875b249914",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 1. Registry and Stage\n",
      "id": "2070733d-1280-46f6-8c7e-32449bf39f75"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "session.sql(f\"CREATE STAGE IF NOT EXISTS {MMT_STAGE}\").collect()\nregistry = Registry(session=session, database_name=DATABASE, schema_name=MODELS_SCHEMA)\nprint(\"‚úÖ Registry + stage ready\")\n",
      "id": "680b2a8b-46aa-4e29-ab15-d2506b52e6a5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 2. Hyperparameters per Group (Experiments or Table)\n",
      "id": "a2be042c-7ad8-4ae2-9ce5-300a3ab660da"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "hyperparams_by_group = {}\nexperiments_loaded = False\nall_groups_from_data = session.sql(\n    f\"\"\"\n    SELECT DISTINCT {STATS_NTILE_GROUP_COL}\n    FROM {TRAIN_TABLE_CLEANED}\n    WHERE {STATS_NTILE_GROUP_COL} IS NOT NULL\n    ORDER BY {STATS_NTILE_GROUP_COL}\n\"\"\"\n).collect()\n\nexpected_groups = [row[STATS_NTILE_GROUP_COL] for row in all_groups_from_data]\n\nprint(\"\\nüî¨ Loading from ML Experiments...\")\ntry:\n    exp_tracking = ExperimentTracking(session)\n    from datetime import datetime, timedelta\n\n    today = datetime.now().strftime(\"%Y%m%d\")\n    experiment_name = f\"hyperparameter_search_regression_{today}\"\n\n    try:\n        exp_tracking.set_experiment(experiment_name)\n        print(f\"‚úÖ Found experiment: {experiment_name}\")\n\n        # Get all runs from this experiment\n        experiments_loaded = True\n        print(\"   ‚úÖ ML Experiments available - loading from experiments\")\n    except:\n        # Try yesterday's experiment as fallback\n        yesterday = (datetime.now() - timedelta(days=1)).strftime(\"%Y%m%d\")\n        experiment_name = f\"hyperparameter_search_regression_{yesterday}\"\n        try:\n            exp_tracking.set_experiment(experiment_name)\n            print(f\"‚úÖ Found experiment: {experiment_name}\")\n            experiments_loaded = True\n        except:\n            print(\"   ‚ö†Ô∏è  No recent experiment found, will use table fallback\")\n            experiments_loaded = False\n\n    if experiments_loaded:\n        try:\n            print(f\"   üìã Runs en experiment: {experiment_name}\")\n\n            runs_query = f\"SHOW RUNS IN EXPERIMENT {experiment_name}\"\n            runs_df = session.sql(runs_query)\n            runs_list = runs_df.collect()\n\n            if len(runs_list) == 0:\n                print(\"   ‚ö†Ô∏è  No runs found in experiment, using table fallback\")\n                experiments_loaded = False\n            else:\n                print(f\"   ‚úÖ Found {len(runs_list)} runs in experiment\")\n\n                runs_by_group = {}\n\n                for run in runs_list:\n                    run_name = run[\"name\"]\n\n                    try:\n                        # Get parameters for this run\n                        params_query = f\"SHOW RUN PARAMETERS IN EXPERIMENT {experiment_name} RUN {run_name}\"\n                        params_df = session.sql(params_query)\n                        params_list = params_df.collect()\n\n                        # Get metrics for this run\n                        metrics_query = f\"SHOW RUN METRICS IN EXPERIMENT {experiment_name} RUN {run_name}\"\n                        metrics_df = session.sql(metrics_query)\n                        metrics_list = metrics_df.collect()\n\n                        # Extract group_name and algorithm from parameters\n                        group_name = None\n                        search_id = None\n                        algorithm = None\n                        best_params = {}\n\n                        for param in params_list:\n                            param_name = param[\"name\"]\n                            param_value = param[\"value\"]\n\n                            if param_name == \"group_name\":\n                                group_name = param_value\n                            elif param_name == \"search_id\":\n                                search_id = param_value\n                            elif param_name == \"algorithm\":\n                                algorithm = param_value\n                            else:\n                                best_params[param_name] = param_value\n\n                        # Extract metrics\n                        val_rmse = None\n                        val_mae = None\n\n                        for metric in metrics_list:\n                            metric_name = metric[\"name\"]\n                            metric_value = metric[\"value\"]\n\n                            if metric_name == \"val_rmse\":\n                                val_rmse = float(metric_value)\n                            elif metric_name == \"val_mae\":\n                                val_mae = float(metric_value)\n\n                        # Only process runs that have a group_name\n                        if group_name and val_rmse is not None:\n                            alg = algorithm or GROUP_MODEL.get(\n                                group_name, _DEFAULT_MODEL\n                            )\n                            if group_name not in runs_by_group:\n                                runs_by_group[group_name] = {\n                                    \"run_name\": run_name,\n                                    \"params\": best_params,\n                                    \"val_rmse\": val_rmse,\n                                    \"val_mae\": val_mae,\n                                    \"search_id\": search_id,\n                                    \"algorithm\": alg,\n                                }\n                            else:\n                                if val_rmse < runs_by_group[group_name][\"val_rmse\"]:\n                                    runs_by_group[group_name] = {\n                                        \"run_name\": run_name,\n                                        \"params\": best_params,\n                                        \"val_rmse\": val_rmse,\n                                        \"val_mae\": val_mae,\n                                        \"search_id\": search_id,\n                                        \"algorithm\": alg,\n                                    }\n\n                    except Exception as run_error:\n                        print(\n                            f\"   ‚ö†Ô∏è  Error processing run {run_name}: {str(run_error)[:100]}\"\n                        )\n                        continue\n\n                # Step 3: Store results in hyperparams_by_group\n                if len(runs_by_group) > 0:\n                    print(f\"   ‚úÖ Loaded {len(runs_by_group)} groups from Experiments\")\n\n                    for group_name, run_info in runs_by_group.items():\n                        hyperparams_by_group[group_name] = {\n                            \"params\": run_info[\"params\"],\n                            \"val_rmse\": run_info[\"val_rmse\"],\n                            \"search_id\": run_info[\"search_id\"] or f\"exp_{group_name}\",\n                            \"algorithm\": run_info.get(\"algorithm\", _DEFAULT_MODEL),\n                        }\n\n                        print(f\"\\n   {group_name}:\")\n                        print(\n                            f\"      Algorithm: {run_info.get('algorithm', _DEFAULT_MODEL)}\"\n                        )\n                        print(f\"      Val RMSE: {run_info['val_rmse']:.4f}\")\n                        if run_info[\"val_mae\"]:\n                            print(f\"      Val MAE: {run_info['val_mae']:.4f}\")\n                        print(f\"      Search ID: {run_info['search_id'] or 'N/A'}\")\n                        print(\n                            f\"      Source: ML Experiments (run: {run_info['run_name']})\"\n                        )\n\n                    experiments_loaded = True\n                else:\n                    print(\n                        \"   ‚ö†Ô∏è  No valid runs with group_name found, using table fallback\"\n                    )\n                    experiments_loaded = False\n\n        except Exception as e:\n            print(f\"   ‚ö†Ô∏è  Error using ExperimentTracking API: {str(e)[:200]}\")\n            print(\"   Will use table fallback\")\n            experiments_loaded = False\n\nexcept Exception as e:\n    print(f\"   ‚ö†Ô∏è  ML Experiments not available: {str(e)[:200]}\")\n    print(\"   Will use table fallback\")\n    experiments_loaded = False\n",
      "id": "caf3ab8b-deb4-45c0-9f56-49bb2dbf314e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "### 2b. Fallback to table\n",
      "id": "e326d636-7543-4349-b808-b916d86b1397"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "if not experiments_loaded or len(hyperparams_by_group) < len(expected_groups):\n    print(\"\\nüìã Fallback: HYPERPARAMETER_RESULTS\")\n\n    table_exists = False\n    try:\n        check_table = session.sql(\n            \"\"\"\n            SELECT COUNT(*) as CNT \n            FROM INFORMATION_SCHEMA.TABLES \n            WHERE TABLE_SCHEMA = 'SC_MODELS_BMX' \n            AND TABLE_NAME = 'HYPERPARAMETER_RESULTS'\n            AND TABLE_CATALOG = 'BD_AA_DEV'\n            \"\"\"\n        ).collect()\n        table_exists = check_table[0][\"CNT\"] > 0\n    except:\n        table_exists = False\n\n    if table_exists:\n        hyperparams_df = session.sql(\n            f\"\"\"\n            WITH latest_searches AS (\n                SELECT \n                    group_name,\n                    search_id,\n                    algorithm,\n                    best_params,\n                    best_cv_rmse,\n                    val_rmse,\n                    val_mae,\n                    created_at,\n                    ROW_NUMBER() OVER (PARTITION BY group_name ORDER BY created_at DESC) AS rn\n                FROM {HYPERPARAMETER_RESULTS_TABLE}\n                WHERE group_name IS NOT NULL\n            )\n            SELECT \n                group_name,\n                search_id,\n                best_params,\n                best_cv_rmse,\n                val_rmse,\n                val_mae\n            FROM latest_searches\n            WHERE rn = 1\n            ORDER BY group_name\n        \"\"\"\n        )\n\n        hyperparams_results = hyperparams_df.collect()\n\n        if len(hyperparams_results) > 0:\n            print(f\"   ‚úÖ Loaded {len(hyperparams_results)} groups from table\")\n\n            for result in hyperparams_results:\n                group_name = result[\"GROUP_NAME\"]\n                best_params_json = result[\"BEST_PARAMS\"]\n\n                if isinstance(best_params_json, str):\n                    best_params = json.loads(best_params_json)\n                else:\n                    best_params = best_params_json\n\n                if group_name not in hyperparams_by_group:\n                    alg = result.get(\"ALGORITHM\") or GROUP_MODEL.get(\n                        group_name, _DEFAULT_MODEL\n                    )\n                    hyperparams_by_group[group_name] = {\n                        \"params\": best_params,\n                        \"val_rmse\": result[\"VAL_RMSE\"],\n                        \"search_id\": result[\"SEARCH_ID\"],\n                        \"algorithm\": alg,\n                    }\n\n                    print(f\"\\n   {group_name}:\")\n                    print(f\"      Algorithm: {alg}\")\n                    print(f\"      Val RMSE: {result['VAL_RMSE']:.4f}\")\n                    print(f\"      Search ID: {result['SEARCH_ID']}\")\n                    print(f\"      Source: Table (fallback)\")\n        else:\n            print(\"   ‚ö†Ô∏è  Table exists but has no results\")\n    else:\n        print(\"   ‚ö†Ô∏è  Table does not exist (this is OK if using ML Experiments)\")\n",
      "id": "43aada28-6190-4bf7-a5f0-2bdd7db54272",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "### 2c. Defaults and validation\n",
      "id": "d20713f5-6dcf-4451-aca1-9177356daae0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "if len(hyperparams_by_group) == 0:\n    raise ValueError(\n        \"No hyperparameter results found in Experiments or table! Please run 03_hyperparameter_search.py first\"\n    )\n\nprint(\n    f\"\\n‚úÖ Total loaded hyperparameters: {len(hyperparams_by_group)}/{len(expected_groups)} groups\"\n)\n\nDEFAULT_PARAMS_BY_MODEL = {\n    \"XGBRegressor\": {\n        \"n_estimators\": 100,\n        \"max_depth\": 6,\n        \"learning_rate\": 0.1,\n        \"subsample\": 0.8,\n        \"colsample_bytree\": 0.8,\n        \"min_child_weight\": 1,\n        \"gamma\": 0,\n        \"reg_alpha\": 0,\n        \"reg_lambda\": 1,\n    },\n    \"LGBMRegressor\": {\n        \"n_estimators\": 100,\n        \"max_depth\": 6,\n        \"learning_rate\": 0.1,\n        \"num_leaves\": 31,\n        \"subsample\": 0.8,\n        \"colsample_bytree\": 0.8,\n        \"reg_alpha\": 0,\n        \"reg_lambda\": 1,\n        \"min_child_samples\": 20,\n    },\n    \"SGDRegressor\": {\n        \"alpha\": 0.0001,\n        \"max_iter\": 2000,\n        \"tol\": 1e-3,\n        \"eta0\": 0.01,\n    },\n}\n\nprint(f\"\\nüìã Defaults per model: {list(DEFAULT_PARAMS_BY_MODEL.keys())}\")\nprint(f\"üîç Validating coverage...\")\ngroups_with_hyperparams = set(hyperparams_by_group.keys())\ngroups_without_hyperparams = set(expected_groups) - groups_with_hyperparams\n\nif groups_without_hyperparams:\n    print(\n        f\"‚ö†Ô∏è  WARNING: {len(groups_without_hyperparams)} groups will use default hyperparameters:\"\n    )\n    for group in sorted(groups_without_hyperparams):\n        print(f\"      - {group}\")\nelse:\n    print(f\"‚úÖ All {len(expected_groups)} groups have optimized hyperparameters!\")\n",
      "id": "48ed9c95-cba4-4c69-8259-26cebd0b2863",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 3. Training Data\n",
      "id": "4f930620-99d0-4127-9bee-2669f8d051e5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\nüè™ Loading training data...\")\n\nif USE_CLEANED_TABLES:\n    print(\"üìä Loading from cleaned table: TRAIN_DATASET_CLEANED\")\n    training_df = session.table(TRAIN_TABLE_CLEANED)\n    print(f\"\\n‚úÖ Training data loaded from cleaned table\")\n    print(f\"   Total records: {training_df.count():,}\")\n    print(f\"   Columns: {len(training_df.columns)}\")\nelse:\n    # Prefer materialized features table (without Dynamic Tables).\n    # If it fails due to permissions/non-existence, fallback to cleaned table.\n    try:\n        # Initialize Feature Store (even though we don't use FeatureView)\n        _fs = FeatureStore(\n            session=session,\n            database=DATABASE,\n            name=FEATURES_SCHEMA,\n            default_warehouse=DEFAULT_WAREHOUSE,\n        )\n        print(\"‚úÖ Feature Store initialized (without FeatureView)\")\n\n        print(f\"üìä Loading features from table: {FEATURES_TABLE}\")\n        features_df = session.table(FEATURES_TABLE)\n\n        print(f\"‚è≥ Loading target variable and {STATS_NTILE_GROUP_COL} from training table...\")\n        target_df = session.table(TRAIN_TABLE_CLEANED).select(\n            \"CUSTOMER_ID\", \"BRAND_PRES_RET\", \"PROD_KEY\", \"WEEK\", TARGET_COLUMN, STATS_NTILE_GROUP_COL\n        )\n\n        print(\"‚è≥ Joining features with target...\")\n        training_df = features_df.join(\n            target_df, on=[\"CUSTOMER_ID\", \"BRAND_PRES_RET\", \"PROD_KEY\", \"WEEK\"], how=\"inner\"\n        )\n\n        print(f\"\\n‚úÖ Training data loaded from features table + target\")\n        print(f\"   Total records: {training_df.count():,}\")\n        print(f\"   Columns: {len(training_df.columns)}\")\n    except Exception as e:\n        print(\n            f\"‚ö†Ô∏è  Could not load/join features table ({FEATURES_TABLE}): {str(e)[:200]}\"\n        )\n        print(\"   Falling back to TRAIN_DATASET_CLEANED\")\n        training_df = session.table(TRAIN_TABLE_CLEANED)\n        print(f\"\\n‚úÖ Training data loaded from cleaned table (fallback)\")\n        print(f\"   Total records: {training_df.count():,}\")\n        print(f\"   Columns: {len(training_df.columns)}\")\n\nPARTITION_COL = next(\n    (c for c in training_df.columns if c.upper() == STATS_NTILE_GROUP_COL),\n    STATS_NTILE_GROUP_COL,\n)\nprint(f\"\\nüìå Partition column: '{PARTITION_COL}'\")\nprint(\"\\nüìä Rows per group:\")\ngroup_counts = (\n    training_df.group_by(PARTITION_COL).count().sort(PARTITION_COL)\n)\ngroup_counts.show(n=20)\n\nif MMT_SAMPLE_FRACTION is not None and 0 < MMT_SAMPLE_FRACTION < 1:\n    n_before = training_df.count()\n    training_df = training_df.sample(frac=MMT_SAMPLE_FRACTION)\n    n_after = training_df.count()\n    print(f\"\\n‚ö†Ô∏è  MMT in TEST mode: using {MMT_SAMPLE_FRACTION*100:.0f}% of data ({n_after:,} of {n_before:,} rows)\")\n",
      "id": "8927efc2-e255-4187-ae64-77b11d2058d3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 4. MMT Training Function\n",
      "id": "5a578c6e-7a15-46fa-82b3-e2dbdc05e947"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "def _get_target_column(df):\n    for c in df.columns:\n        if str(c).upper() == TARGET_COLUMN:\n            return c\n    return TARGET_COLUMN.lower()\n\n\ndef _get_feature_cols_numeric(df, excluded_cols, target_col):\n    \"\"\"Numeric columns only (same as script 03): Snowflake ML requires int/float/bool.\"\"\"\n    # excluded_cols is already in UPPER CASE, target_col may vary\n    excluded_upper = {col.upper() if isinstance(col, str) else str(col).upper() for col in excluded_cols}\n    excluded_upper.add(str(target_col).upper())\n    return [\n        col\n        for col in df.columns\n        if str(col).upper() not in excluded_upper\n        and getattr(df[col].dtype, \"kind\", \"O\") in \"iufb\"\n    ]\n\n\ndef train_segment_model(data_connector, context):\n    import pandas as pd\n    from snowflake.ml.modeling.xgboost import XGBRegressor\n    from snowflake.ml.modeling.lightgbm import LGBMRegressor\n    from snowflake.ml.modeling.linear_model import SGDRegressor\n    from sklearn.metrics import mean_squared_error, mean_absolute_error\n    import numpy as np\n\n    segment_name = context.partition_id\n    print(f\"\\n{'='*80}\")\n    print(f\"üöÄ Training model for {segment_name}\")\n    print(f\"{'='*80}\")\n\n    # NOTE: DataConnector in MMT only provides to_pandas() method, not direct Snowpark DataFrame access\n    # This means we need to convert to pandas, but we can optimize by doing the split efficiently\n    # For very large partitions, consider using MMT_SAMPLE_FRACTION to reduce partition size\n    df = data_connector.to_pandas()\n    print(f\"üìä Data shape: {df.shape}\")\n    \n    target_col = _get_target_column(df)\n    feature_cols = _get_feature_cols_numeric(df, EXCLUDED_COLS, target_col)\n    if len(feature_cols) < 5:\n        excluded_upper = {col for col in EXCLUDED_COLS}\n        excluded_upper.add(str(target_col).upper())\n        feature_cols = [c for c in df.columns if str(c).upper() not in excluded_upper]\n    \n    # Get statistics\n    X = df[feature_cols].copy()\n    for c in feature_cols:\n        X[c] = pd.to_numeric(X[c], errors=\"coerce\").fillna(0)\n    y = pd.to_numeric(df[target_col], errors=\"coerce\").fillna(0)\n\n    print(f\"   Features: {len(feature_cols)}\")\n    print(f\"   Target range: [{y.min():.2f}, {y.max():.2f}]\")\n    print(f\"   Target mean: {y.mean():.2f}\")\n\n    # Split using pandas (original behavior)\n    from sklearn.model_selection import train_test_split\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    print(f\"   Training set: {X_train.shape[0]:,} samples\")\n    print(f\"   Test set: {X_test.shape[0]:,} samples\")\n\n    # Prepare data\n    train_dataset = X_train.copy()\n    for c in feature_cols:\n        train_dataset[c] = np.asarray(train_dataset[c], dtype=np.float64)\n    train_dataset[target_col] = np.asarray(y_train, dtype=np.float64)\n    test_features = X_test.copy()\n    for c in feature_cols:\n        test_features[c] = np.asarray(test_features[c], dtype=np.float64)\n\n    model_type = GROUP_MODEL.get(segment_name, _DEFAULT_MODEL)\n    if segment_name in hyperparams_by_group:\n        algorithm = hyperparams_by_group[segment_name].get(\"algorithm\")\n        if algorithm:\n            model_type = algorithm\n        group_params = hyperparams_by_group[segment_name][\"params\"]\n        search_id = hyperparams_by_group[segment_name][\"search_id\"]\n        val_rmse = hyperparams_by_group[segment_name][\"val_rmse\"]\n        print(f\"\\n   ‚úÖ Using OPTIMIZED hyperparameters from script 03\")\n        print(f\"      Model: {model_type}\")\n        print(f\"      Search ID: {search_id}\")\n        print(f\"      Validation RMSE (from search): {val_rmse:.4f}\")\n    else:\n        group_params = DEFAULT_PARAMS_BY_MODEL.get(\n            model_type, DEFAULT_PARAMS_BY_MODEL[\"XGBRegressor\"]\n        )\n        print(\n            f\"\\n   ‚ö†Ô∏è  Using DEFAULT hyperparameters for {model_type} (no search results for {segment_name})\"\n        )\n\n    def _to_native(v):\n        \"\"\"Same as script 03: numpy -> Python native; numeric string -> float/int.\"\"\"\n        if hasattr(v, \"item\"):\n            return v.item()\n        if isinstance(v, (int, float)):\n            return v\n        if isinstance(v, (np.integer, np.floating)):\n            return int(v) if isinstance(v, np.integer) else float(v)\n        if isinstance(v, str):\n            v = v.strip()\n            try:\n                f = float(v)\n                return int(f) if f == int(f) else f\n            except (ValueError, TypeError):\n                return v\n        return v\n\n    int_params = (\"n_estimators\", \"max_depth\", \"num_leaves\", \"min_child_weight\", \"min_child_samples\", \"max_iter\")\n    float_params = (\"alpha\", \"learning_rate\", \"subsample\", \"colsample_bytree\", \"gamma\", \"reg_alpha\", \"reg_lambda\", \"tol\", \"eta0\")\n    defaults = DEFAULT_PARAMS_BY_MODEL.get(model_type, DEFAULT_PARAMS_BY_MODEL[\"XGBRegressor\"])\n    model_params = {}\n    for k, v in group_params.items():\n        vn = _to_native(v)\n        try:\n            if k in int_params:\n                model_params[k] = int(vn) if isinstance(vn, (int, float, np.integer, np.floating)) else defaults.get(k, vn)\n            elif k in float_params:\n                model_params[k] = float(vn) if isinstance(vn, (int, float, np.integer, np.floating)) else defaults.get(k, vn)\n            else:\n                model_params[k] = vn\n        except (TypeError, ValueError):\n            model_params[k] = defaults.get(k, vn)\n    model_params[\"random_state\"] = 42\n\n    MODEL_CLASSES = {\n        \"XGBRegressor\": XGBRegressor,\n        \"LGBMRegressor\": LGBMRegressor,\n        \"SGDRegressor\": SGDRegressor,\n    }\n    ModelClass = MODEL_CLASSES.get(model_type, XGBRegressor)\n    if model_type == \"XGBRegressor\":\n        model_params[\"n_jobs\"] = -1\n        model_params[\"objective\"] = \"reg:squarederror\"\n        model_params[\"eval_metric\"] = \"rmse\"\n    elif model_type == \"LGBMRegressor\":\n        model_params[\"n_jobs\"] = -1\n        model_params[\"verbosity\"] = -1\n    elif model_type == \"SGDRegressor\":\n        model_params.setdefault(\"penalty\", \"l2\")\n        model_params.setdefault(\"learning_rate\", \"invscaling\")\n\n    print(f\"\\n   Training {model_type} with {len(model_params)} hyperparameters...\")\n    model = ModelClass(\n        input_cols=feature_cols, label_cols=[target_col], **model_params\n    )\n    model.fit(train_dataset)\n\n    pred_result = model.predict(test_features)\n    pred_df = pred_result.to_pandas() if hasattr(pred_result, \"to_pandas\") else pred_result\n    out_col = model.get_output_cols()[0]\n    y_pred = np.asarray(pred_df[out_col])\n\n    # Regression metrics\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    mae = mean_absolute_error(y_test, y_pred)\n\n    # WAPE: sum(|y - y_hat|) / sum(|y|)\n    abs_errors = np.abs(y_test - y_pred)\n    denom_wape = np.sum(np.abs(y_test))\n    wape = float(abs_errors.sum() / denom_wape) if denom_wape > 0 else 0.0\n\n    # MAPE: mean(|y - y_hat| / |y|) * 100, ignoring targets 0\n    non_zero_mask = np.abs(y_test) > 1e-8\n    if non_zero_mask.any():\n        mape = float(\n            (np.abs(y_test[non_zero_mask] - y_pred[non_zero_mask]) / np.abs(y_test[non_zero_mask])).mean()\n            * 100.0\n        )\n    else:\n        mape = 0.0\n\n    print(f\"\\n   ‚úÖ Model trained\")\n    print(f\"      RMSE: {rmse:.2f}\")\n    print(f\"      MAE: {mae:.2f}\")\n    print(f\"      WAPE: {wape:.4f}\")\n    print(f\"      MAPE: {mape:.2f}%\")\n    print(f\"{'='*80}\\n\")\n\n    model.rmse = rmse\n    model.mae = mae\n    model.wape = wape\n    model.mape = mape\n    model.training_samples = X_train.shape[0]\n    model.test_samples = X_test.shape[0]\n    model.feature_cols = feature_cols\n    model.hyperparameters = model_params\n    model.segment = segment_name\n    model.group_name = segment_name\n\n    return model\n\n",
      "id": "b9aabeea-c3e1-41d6-944e-1abec369d431",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 5. Escalar cluster, Ray Dashboard, MMT\n",
      "id": "394c2dad-668b-457e-9942-7814f9a8f9e5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "try:\n    from snowflake.ml.runtime_cluster import scale_cluster\n    scale_cluster(expected_cluster_size=CLUSTER_SIZE_MMT, options={\"block_until_min_cluster_size\": CLUSTER_SIZE_MIN_MMT})\n    print(f\"‚úÖ Cluster scaled to {CLUSTER_SIZE_MMT} nodes\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è scale_cluster: {str(e)[:150]}\")\n\ntry:\n    from snowflake.ml.runtime_cluster import get_ray_dashboard_url\n    print(f\"‚úÖ Ray Dashboard: {get_ray_dashboard_url()}\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Ray Dashboard: {str(e)[:100]}\")\n",
      "id": "ab008533-6058-424b-96f3-3637c3be8b19",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "start_time = time.time()\ntrainer = ManyModelTraining(train_segment_model, MMT_STAGE)\ntraining_run = trainer.run(\n    partition_by=PARTITION_COL,\n    snowpark_dataframe=training_df,\n    run_id=f\"uni_box_regression_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n)\n\nprint(f\"\\n‚úÖ Run ID: {training_run.run_id}\\n\")\n",
      "id": "d8c1d17c-79b4-4d84-af0f-4f5dd6017324",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "### 5d. Wait for MMT (optional; if partition_details fails, exit loop)\n",
      "id": "5adc09b1-9bcc-4667-b4f6-8b1a51d7dced"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "import time as time_module\nMMT_MAX_WAIT = 600\nMMT_CHECK_INTERVAL = 30\n\nelapsed = 0\ncompleted = False\nrun_start = start_time\n\nwhile elapsed < MMT_MAX_WAIT:\n    time_module.sleep(MMT_CHECK_INTERVAL)\n    elapsed += MMT_CHECK_INTERVAL\n\n    try:\n        details = training_run.partition_details\n    except Exception as e:\n        print(f\"\\n‚ö†Ô∏è  partition_details failed: {str(e)[:180]}\")\n        print(\"   Stop waiting. Check Ray Dashboard or run 6/7 later.\")\n        break\n\n    total_count = len(details)\n    done_count = sum(1 for pid in details if details[pid].status.name == \"DONE\")\n    failed_count = sum(1 for pid in details if details[pid].status.name == \"FAILED\")\n    pending_count = total_count - done_count - failed_count\n    print(\n        f\"‚è±Ô∏è  {elapsed}s - OK: {done_count} | FAILED: {failed_count} | pending: {pending_count}\",\n        end=\"\\r\",\n    )\n\n    if done_count + failed_count == total_count:\n        print(\"\\n‚úÖ All models completed!\" + \" \" * 30)\n        completed = True\n        break\n\nif not completed:\n    print(\"\\n‚è±Ô∏è  Timeout. Training may continue in background; check Ray Dashboard or run 6/7 later.\")\n    try:\n        stage_files = session.sql(\n            f\"LIST @{MMT_STAGE} PATTERN='.*{training_run.run_id}.*'\"\n        ).collect()\n        if len(stage_files) >= 16:\n            print(f\"\\n‚úÖ {len(stage_files)} files in stage - training likely completed.\")\n            completed = True\n    except Exception:\n        pass\nelse:\n    print(\"\\n‚úÖ TRAINING COMPLETE\")\nend_time = time.time()\nprint(f\"\\n‚è±Ô∏è  {((end_time - run_start) / 60):.2f} min\")\n\ntry:\n    from snowflake.ml.runtime_cluster import scale_cluster\n    scale_cluster(expected_cluster_size=CLUSTER_SIZE_DOWN)\n    print(f\"‚úÖ Cluster scaled down to {CLUSTER_SIZE_DOWN} node\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è scale down: {str(e)[:120]}\")\n",
      "id": "dbdc6018-cf7d-4554-bc70-1692d5954dc0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 6. Results per Partition\n",
      "id": "5c7e70b9-cd66-406a-9e4e-e9bf35ca9f70"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "try:\n    partition_details = training_run.partition_details\nexcept Exception as e:\n    partition_details = {}\n    print(f\"‚ö†Ô∏è partition_details failed: {str(e)[:200]}. Re-run from ¬ß3, then 5c‚Üí5d‚Üí6.\")\n\ndone_ids = []\nfailed_ids = []\npending_ids = []\nfor partition_id in partition_details:\n    details = partition_details[partition_id]\n    st = details.status.name\n    if st == \"DONE\":\n        done_ids.append(partition_id)\n        try:\n            model = training_run.get_model(partition_id)\n            print(f\"\\n‚úÖ {partition_id}: RMSE={model.rmse:.2f}, MAE={model.mae:.2f}, samples={model.training_samples:,}\")\n        except Exception as e:\n            print(f\"\\n‚ö†Ô∏è  {partition_id}: DONE pero no se pudo cargar - {str(e)[:100]}\")\n    elif st == \"FAILED\":\n        failed_ids.append(partition_id)\n        print(f\"\\n‚ùå {partition_id}: FAILED\")\n        try:\n            logs = getattr(details, \"logs\", None)\n            if logs and \"Error:\" in logs:\n                err_line = next((l for l in logs.split(\"\\n\") if \"Error:\" in l), None)\n                if err_line:\n                    print(f\"   {err_line.strip()[:200]}\")\n        except Exception:\n            pass\n    else:\n        pending_ids.append(partition_id)\n        print(f\"\\n‚è≥ {partition_id}: {st}\")\nprint(f\"\\n--- Resumen: {len(done_ids)} OK, {len(failed_ids)} FAILED, {len(pending_ids)} pendientes ---\")\n",
      "id": "094182f2-9ca4-4585-9dd8-4ce7256f0734",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 7. Register Models in Registry\n",
      "id": "22403fb7-6fe4-447b-ba63-3207dff5f923"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "version_date = datetime.now().strftime(\"%Y%m%d_%H%M\")\nregistered_models = {}\ntry:\n    _reg_partitions = training_run.partition_details\nexcept Exception as e:\n    _reg_partitions = {}\n    print(f\"‚ö†Ô∏è partition_details: {str(e)[:180]}\")\n\nfor partition_id in _reg_partitions:\n    details = _reg_partitions[partition_id]\n\n    if details.status.name == \"DONE\":\n        try:\n            model = training_run.get_model(partition_id)\n\n            model_name = f\"uni_box_regression_{partition_id.lower()}\"\n            group_search_id = None\n            group_hyperparams = None\n            group_algorithm = GROUP_MODEL.get(partition_id, _DEFAULT_MODEL)\n            if partition_id in hyperparams_by_group:\n                group_search_id = hyperparams_by_group[partition_id][\"search_id\"]\n                group_hyperparams = hyperparams_by_group[partition_id][\"params\"]\n                alg = hyperparams_by_group[partition_id].get(\"algorithm\")\n                if alg:\n                    group_algorithm = alg\n\n            print(f\"\\nRegistrando {partition_id}...\")\n            model_metrics = {\n                \"rmse\": float(model.rmse),\n                \"mae\": float(model.mae),\n                \"wape\": float(model.wape),\n                \"mape\": float(model.mape),\n                \"training_samples\": int(model.training_samples),\n                \"test_samples\": int(model.test_samples),\n                \"algorithm\": group_algorithm,\n                \"group\": partition_id,\n                \"hyperparameter_search_id\": group_search_id or \"default\",\n            }\n\n            if group_hyperparams:\n                for key, value in group_hyperparams.items():\n                    if isinstance(value, (int, float)):\n                        model_metrics[f\"hyperparameter_{key}\"] = (\n                            float(value) if isinstance(value, float) else int(value)\n                        )\n                model_metrics[\"hyperparameters\"] = json.dumps(\n                    {\n                        k: float(v) if isinstance(v, (int, float)) else v\n                        for k, v in group_hyperparams.items()\n                    }\n                )\n\n            mv = registry.log_model(\n                model,\n                model_name=model_name,\n                version_name=f\"v_{version_date}\",\n                comment=f\"{group_algorithm} regression model for uni_box_week - Group: {partition_id}\",\n                metrics=model_metrics,\n                task=task.Task.TABULAR_REGRESSION,\n            )\n\n            registered_models[partition_id] = {\n                \"model_name\": model_name,\n                \"version\": f\"v_{version_date}\",\n                \"model_version\": mv,\n            }\n\n            print(f\"‚úÖ {partition_id}: {model_name} v_{version_date}\")\n            print(\n                f\"   RMSE: {model.rmse:.2f}, MAE: {model.mae:.2f}, \"\n                f\"WAPE: {model.wape:.4f}, MAPE: {model.mape:.2f}%\"\n            )\n            \n            # Set PRODUCTION alias to this version (move from previous version if needed)\n            try:\n                model_fqn = f\"{DATABASE}.{MODELS_SCHEMA}.{model_name}\"\n                new_version_name = f\"v_{version_date}\"\n\n                # Try to remove PRODUCTION alias from previous version (if any)\n                try:\n                    session.sql(f\"ALTER MODEL {model_fqn} VERSION PRODUCTION UNSET ALIAS\").collect()\n                except Exception:\n                    # It is fine if there was no previous PRODUCTION alias\n                    pass\n\n                # Assign PRODUCTION alias to the newly logged version\n                session.sql(\n                    f\"ALTER MODEL {model_fqn} VERSION {new_version_name} SET ALIAS=PRODUCTION\"\n                ).collect()\n                print(\"   ‚úÖ PRODUCTION alias set\")\n            except Exception as e:\n                print(f\"   ‚ö†Ô∏è  Error setting PRODUCTION alias: {str(e)[:100]}\")\n\n        except Exception as e:\n            print(f\"‚ùå Error registering model: {str(e)[:200]}\")\n\nprint(f\"\\n‚úÖ {len(registered_models)} model(s) registered successfully!\")\n",
      "id": "8f993f58-1359-4a5a-8637-92d5adb44280",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 8. Verify PRODUCTION Alias\n",
      "id": "23d1fe9e-450c-4df8-84e6-dbcd616ab45d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# PRODUCTION alias is already set during registration (section 7)\n# This section verifies all models have the alias\nprint(\"\\nüìã Verifying PRODUCTION alias for all registered models...\")\nfor partition_id, model_info in registered_models.items():\n    model_name = model_info[\"model_name\"]\n    version = model_info[\"version\"]\n    try:\n        model_ref = registry.get_model(model_name)\n        prod_version = model_ref.version(\"PRODUCTION\")\n        # ModelVersion may expose the version name under different attributes depending on library version\n        version_name = getattr(prod_version, \"name\", getattr(prod_version, \"version_name\", str(prod_version)))\n        print(f\"‚úÖ {model_name}: PRODUCTION ‚Üí {version_name}\")\n    except Exception as e:\n        print(f\"‚ö†Ô∏è  {model_name}: PRODUCTION alias not found - {str(e)[:100]}\")\n",
      "id": "6fbaf2cd-7ed9-409c-8dbe-345045215b30",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 9. Resumen\n",
      "id": "01396452-4b73-4f35-b5f3-7e3e4aa4ac4b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "_elapsed = (time.time() - start_time) / 60\nprint(f\"\\n‚úÖ MMT: {len(registered_models)}/16 models | {_elapsed:.2f} min\")\nif registered_models:\n    for pid in sorted(registered_models.keys()):\n        try:\n            m = training_run.get_model(pid)\n            print(\n                f\"   {pid}: RMSE={m.rmse:.2f}, MAE={m.mae:.2f}, \"\n                f\"WAPE={m.wape:.4f}, MAPE={m.mape:.2f}%\"\n            )\n        except Exception:\n            pass\nprint(\"   Next: 05_create_partitioned_model.py ‚Üí 06_partitioned_inference_batch.py\")\n\n",
      "id": "1f8d9d83-b27c-4d74-9884-46f437ecfc48",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}