{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "# Modelo particionado (16 modelos de 04)\nCarga los modelos por grupo del Registry, crea CustomModel con API particionada y lo registra.\n",
      "id": "1e30a09f-62c4-496f-abc7-66c804e3596d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "from snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark import functions as F\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml.model import custom_model, task\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\n\nsession = get_active_session()\nsession.sql(\"USE DATABASE BD_AA_DEV\").collect()\nsession.sql(\"USE SCHEMA SC_STORAGE_BMX_PS\").collect()\nregistry = Registry(session=session, database_name=\"BD_AA_DEV\", schema_name=\"SC_MODELS_BMX\")\nprint(f\"‚úÖ {session.get_current_database()}.{session.get_current_schema()}\")\n",
      "id": "b56c9b6f-80f4-4cb1-aa2f-348780b55369",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 1. Cargar los 16 modelos (PRODUCTION)\n",
      "id": "5ac8ccb9-ed78-4ace-943a-34f64fda880c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "\ngroups_df = session.sql(\n    \"\"\"\n    SELECT DISTINCT stats_ntile_group AS GROUP_NAME\n    FROM BD_AA_DEV.SC_STORAGE_BMX_PS.TRAIN_DATASET_CLEANED\n    WHERE stats_ntile_group IS NOT NULL\n    ORDER BY stats_ntile_group\n\"\"\"\n)\ngroups_list = [row[\"GROUP_NAME\"] for row in groups_df.collect()]\nprint(f\"\\nüìä Grupos: {len(groups_list)}\")\n\nloaded_models = {}\nfeature_cols = None\n\nfor group_name in groups_list:\n    model_name = f\"uni_box_regression_{group_name.lower()}\"\n    try:\n        model_ref = registry.get_model(model_name)\n        model_version = model_ref.version(\"PRODUCTION\")\n        native_model = model_version.load()\n        if feature_cols is None:\n            feature_cols = getattr(native_model, \"feature_cols\", None)\n            if not feature_cols:\n                raise ValueError(\"Model has no feature_cols; run 04 first.\")\n        loaded_models[group_name] = {\"model\": native_model, \"model_version\": model_version, \"model_name\": model_name}\n        ver_name = getattr(model_version, \"name\", str(model_version))\n        print(f\"‚úÖ {group_name} (versi√≥n: {ver_name})\")\n    except Exception as e:\n        print(f\"‚ùå {group_name}: {str(e)[:100]}\")\n\nif not loaded_models:\n    raise ValueError(\"No models loaded. Run 04_many_model_training.py first.\")\nif len(loaded_models) < len(groups_list):\n    print(f\"‚ö†Ô∏è  {len(loaded_models)}/{len(groups_list)} modelos cargados\")\nversions_loaded = {getattr(m[\"model_version\"], \"name\", None) for m in loaded_models.values()}\nprint(f\"\\n‚úÖ {len(loaded_models)} modelos, {len(feature_cols)} features (alias PRODUCTION ‚Üí {versions_loaded or 'N/A'})\")\n",
      "id": "742c3225-36e7-4325-a344-912dacbbf61d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 2. Define Partitioned Model Class\n",
      "id": "814c551e-0cf2-41b5-bf69-b09526c2ddf2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üîß DEFINING PARTITIONED MODEL CLASS\")\nprint(\"=\" * 80)\n\n\nclass PartitionedUniBoxModel(custom_model.CustomModel):\n    \"\"\"Modelo particionado: enruta predicciones por stats_ntile_group.\"\"\"\n\n    def __init__(self, model_context):\n        super().__init__(model_context)\n        # Usamos las mismas columnas de features detectadas al cargar los modelos base\n        self.feature_cols = feature_cols\n\n    @custom_model.partitioned_api\n    def predict(self, input_df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"Predicci√≥n por grupo; enruta seg√∫n stats_ntile_group.\"\"\"\n        if len(input_df) == 0:\n            return pd.DataFrame(\n                columns=[\n                    \"CUSTOMER_ID\",\n                    \"STATS_NTILE_GROUP\",\n                    \"WEEK\",\n                    \"BRAND_PRES_RET\",\n                    \"predicted_uni_box_week\",\n                ]\n            )\n\n        # Est√°ndar √∫nico: MAY√öSCULAS (evita duplicados case-insensitive en la firma)\n        part_col = \"STATS_NTILE_GROUP\"\n        if part_col not in input_df.columns:\n            raise ValueError(f\"Missing required column '{part_col}' in input_df. Columns: {list(input_df.columns)}\")\n        group_name = input_df[part_col].iloc[0]\n\n        model_key = group_name.lower()\n        try:\n            model = self.context.model_ref(model_key)\n        except Exception:\n            try:\n                model = self.context.model_ref(group_name.lower())\n            except Exception:\n                raise ValueError(f\"Model not found for group: {group_name}. Keys: {list(self.context.models.keys())}\")\n\n        # Seleccionamos √∫nicamente las columnas de features ya conocidas\n        X = input_df[self.feature_cols].fillna(0).astype(np.float64, errors=\"ignore\")\n        pred_out = model.predict(X)\n\n        if isinstance(pred_out, pd.DataFrame):\n            pred_col = next((c for c in pred_out.columns if \"PREDICT\" in c.upper() or \"OUTPUT\" in c.upper()), pred_out.columns[0])\n            predictions = np.asarray(pred_out[pred_col], dtype=np.float64).ravel()\n        elif hasattr(pred_out, \"flatten\"):\n            predictions = np.asarray(pred_out).flatten()\n        else:\n            predictions = np.asarray(pred_out).ravel()\n\n        # Propagar columnas de contexto para evitar JOINs ambiguos en inferencia\n        required_ctx = [\"CUSTOMER_ID\", \"WEEK\", \"BRAND_PRES_RET\"]\n        missing_ctx = [c for c in required_ctx if c not in input_df.columns]\n        if missing_ctx:\n            raise ValueError(f\"Missing required context columns: {missing_ctx}. Columns: {list(input_df.columns)}\")\n\n        cust = input_df[\"CUSTOMER_ID\"].values\n        week_vals = input_df[\"WEEK\"].values\n        brand_vals = input_df[\"BRAND_PRES_RET\"].values\n\n        return pd.DataFrame(\n            {\n                \"CUSTOMER_ID\": cust,\n                \"STATS_NTILE_GROUP\": group_name,\n                \"WEEK\": week_vals,\n                \"BRAND_PRES_RET\": brand_vals,\n                \"predicted_uni_box_week\": predictions,\n            }\n        )\n\n\nprint(\"‚úÖ PartitionedUniBoxModel class defined\")\n",
      "id": "eaff6429-3eb1-48bf-bad5-262e9fd74845",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 3. Create Model Context and Partitioned Model\n",
      "id": "cefd345b-1672-4959-accb-d3c1abc6522e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üì¶ CREATING PARTITIONED MODEL\")\nprint(\"=\" * 80)\n\nmodels_dict = {}\nfor group_name, model_info in loaded_models.items():\n    model_key = group_name.lower()\n    models_dict[model_key] = model_info[\"model\"]\n    print(f\"   Added {group_name} ‚Üí {model_key}\")\nprint(f\"\\n‚úÖ ModelContext created with {len(models_dict)} models\")\n\nmodel_context = custom_model.ModelContext(models=models_dict)\npartitioned_model = PartitionedUniBoxModel(model_context=model_context)\nprint(\"‚úÖ Partitioned model created\")\n",
      "id": "5ebb54f6-89aa-4f7b-9bfe-a3c61f69994f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 4. Sample input (homologado con 06: incluye week y brand_pres_ret como contexto)\n",
      "id": "776c2136-66b7-4089-addd-f8c35a4de8b0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üìã PREPARING SAMPLE INPUT (HOMOLOGADO CON 06)\")\nprint(\"=\" * 80)\n\n# Usar la misma lista de exclusi√≥n que 02/04/06 para asegurar que sample_input tenga la misma firma que inferencia\nexcluded_cols_sample = [\n    \"customer_id\",\n    \"brand_pres_ret\",\n    \"week\",\n    \"group\",\n    \"stats_group\",\n    \"percentile_group\",\n    \"stats_ntile_group\",\n    \"uni_box_week\",  # Target - no es feature\n    \"FEATURE_TIMESTAMP\",\n]\nexcluded_upper_sample = {c.upper() for c in excluded_cols_sample}\n\n# Obtener esquema de training para identificar features num√©ricas (igual que 06 con inference)\ntraining_schema = session.sql(\n    \"DESCRIBE TABLE BD_AA_DEV.SC_STORAGE_BMX_PS.TRAIN_DATASET_CLEANED\"\n).collect()\ncol_type_dict_sample = {row[\"name\"].upper(): str(row[\"type\"]).upper() for row in training_schema}\nall_cols_sample = [row[\"name\"] for row in training_schema]\n\nNUMERIC_PREFIXES_SAMPLE = (\"FLOAT\", \"NUMBER\", \"INTEGER\", \"BIGINT\", \"DOUBLE\")\nfeature_cols_sample = [\n    c for c in all_cols_sample\n    if c.upper() not in excluded_upper_sample\n    and (col_type_dict_sample.get(c.upper()) or \"\").startswith(NUMERIC_PREFIXES_SAMPLE)\n]\n\n# Verificar que feature_cols_sample coincida con feature_cols de los modelos (deber√≠an ser iguales)\nif set(c.upper() for c in feature_cols_sample) != set(c.upper() for c in feature_cols):\n    print(f\"‚ö†Ô∏è  Feature mismatch: sample tiene {len(feature_cols_sample)}, modelos tienen {len(feature_cols)}\")\n    print(f\"   Usando feature_cols de modelos para mantener compatibilidad\")\n    feature_cols_for_sample = feature_cols\nelse:\n    # Ordenar feature_cols_sample seg√∫n el orden de feature_cols para mantener consistencia\n    feature_cols_for_sample = [c for c in feature_cols if c.upper() in {x.upper() for x in feature_cols_sample}]\n    if len(feature_cols_for_sample) != len(feature_cols):\n        print(f\"‚ö†Ô∏è  Algunas features de modelos no est√°n en sample, usando todas las de modelos\")\n        feature_cols_for_sample = feature_cols\n\ntraining_df = session.table(\"BD_AA_DEV.SC_STORAGE_BMX_PS.TRAIN_DATASET_CLEANED\")\n\n# Detectar nombres reales (case-insensitive) para evitar columnas NULL por casing (WEEK vs week)\ncust_col = next((c for c in training_df.columns if c.upper() == \"CUSTOMER_ID\"), \"CUSTOMER_ID\")\npart_col = next((c for c in training_df.columns if c.upper() == \"STATS_NTILE_GROUP\"), \"STATS_NTILE_GROUP\")\nweek_col = next((c for c in training_df.columns if c.upper() == \"WEEK\"), \"WEEK\")\nbrand_col = next((c for c in training_df.columns if c.upper() == \"BRAND_PRES_RET\"), \"BRAND_PRES_RET\")\n\n# Seleccionar y aliasar columnas de contexto con nombres fijos para la firma del modelo\nbase_selected = training_df.select(\n    # Est√°ndar √∫nico: MAY√öSCULAS\n    F.col(cust_col).alias(\"CUSTOMER_ID\"),\n    F.col(part_col).alias(\"STATS_NTILE_GROUP\"),\n    # Usar MAY√öSCULAS para evitar colisiones case-insensitive en la inferencia de firma\n    F.col(week_col).alias(\"WEEK\"),\n    F.col(brand_col).alias(\"BRAND_PRES_RET\"),\n    *[F.col(c) for c in feature_cols_for_sample],\n)\n\nsample_input_sp = (\n    base_selected.filter(F.col(\"STATS_NTILE_GROUP\").isin(list(loaded_models.keys())))\n    .group_by(\"STATS_NTILE_GROUP\")\n    .agg(\n        # Asegurar NO-NULL en columnas de contexto para inferir firma (Snowflake ML requiere al menos un no-null)\n        F.min(F.col(\"CUSTOMER_ID\")).alias(\"CUSTOMER_ID\"),\n        F.coalesce(F.min(F.col(\"WEEK\")), F.lit(\"000000\")).alias(\"WEEK\"),\n        F.coalesce(F.min(F.col(\"BRAND_PRES_RET\")), F.lit(\"UNKNOWN\")).alias(\"BRAND_PRES_RET\"),\n        *[F.min(F.col(c)).alias(c) for c in feature_cols_for_sample],\n    )\n    .select(\"CUSTOMER_ID\", \"STATS_NTILE_GROUP\", \"WEEK\", \"BRAND_PRES_RET\", *feature_cols_for_sample)\n    .limit(min(16, len(loaded_models)))\n)\nsample_input = sample_input_sp.to_pandas()\nprint(f\"‚úÖ Sample input prepared: {len(sample_input)} rows (one per group)\")\nprint(f\"   Columns: CUSTOMER_ID, STATS_NTILE_GROUP, WEEK, BRAND_PRES_RET, {len(feature_cols_for_sample)} features\")\nif len(sample_input) == 0:\n    raise ValueError(\"Sample input is empty. Verifica que TRAIN_DATASET_CLEANED tenga los mismos stats_ntile_group que los modelos cargados.\")\n\n# Blindaje final en pandas (solo MAY√öSCULAS; no se crean columnas extra)\nsample_input[\"WEEK\"] = sample_input[\"WEEK\"].fillna(\"000000\")\nsample_input[\"BRAND_PRES_RET\"] = sample_input[\"BRAND_PRES_RET\"].fillna(\"UNKNOWN\")\n\n# Forzar tipos de contexto a string para que la firma del modelo espere VARCHAR (y calce con inferencia).\n# (En training WEEK suele venir num√©rico; si se infiere NUMBER aqu√≠, luego falla cuando en inferencia llega VARCHAR.)\nsample_input[\"CUSTOMER_ID\"] = sample_input[\"CUSTOMER_ID\"].astype(str)\nsample_input[\"STATS_NTILE_GROUP\"] = sample_input[\"STATS_NTILE_GROUP\"].astype(str)\nsample_input[\"WEEK\"] = sample_input[\"WEEK\"].astype(str)\nsample_input[\"BRAND_PRES_RET\"] = sample_input[\"BRAND_PRES_RET\"].astype(str)\n\n# Debug r√°pido (se ver√° en ejecuci√≥n del notebook/script)\ntry:\n    null_week = int(sample_input[\"WEEK\"].isna().sum())\n    null_brand = int(sample_input[\"BRAND_PRES_RET\"].isna().sum())\n    print(f\"üîé sample_input nulls ‚Äî week: {null_week}, brand_pres_ret: {null_brand}\")\nexcept Exception:\n    pass\n",
      "id": "dc3b6682-7d86-436f-b02b-f0e0533cf029",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 5. Register Partitioned Model\n",
      "id": "baecd6c4-0a32-47ac-bceb-17b89b97cccf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üìù REGISTERING PARTITIONED MODEL\")\nprint(\"=\" * 80)\n\nversion_date = datetime.now().strftime(\"%Y%m%d_%H%M\")\n\nprint(f\"\\nüìù Registering in Model Registry...\")\nprint(f\"   Name: UNI_BOX_REGRESSION_PARTITIONED\")\nprint(f\"   Version: v_{version_date}\")\n\ntry:\n    mv = registry.log_model(\n        partitioned_model,\n        model_name=\"UNI_BOX_REGRESSION_PARTITIONED\",\n        version_name=f\"v_{version_date}\",\n        comment=f\"Partitioned regression model for uni_box_week - Combines {len(loaded_models)} group-specific models (LGBM/XGB/SGD)\",\n        metrics={\n            \"num_groups\": len(loaded_models),\n            \"num_features\": len(feature_cols),\n            \"model_type\": \"mixed\",\n            \"groups\": \",\".join(sorted(loaded_models.keys())),\n        },\n        sample_input_data=sample_input,\n        task=task.Task.TABULAR_REGRESSION,\n        options={\"function_type\": \"TABLE_FUNCTION\"},\n    )\n\n    print(\"\\n‚úÖ Partitioned model registered successfully!\")\n    # Mover alias PRODUCTION de forma \"limpia\":\n    # 1) quitar alias al version previo (si existe)\n    # 2) asignar alias al nuevo version\n    model_fqn = \"BD_AA_DEV.SC_MODELS_BMX.UNI_BOX_REGRESSION_PARTITIONED\"\n    # OJO: el version_name que se loggea arriba es \"v_<timestamp>\" (min√∫scula).\n    # Usamos exactamente ese identificador para evitar ambig√ºedad.\n    new_version_name = f\"v_{version_date}\"\n    try:\n        session.sql(f\"ALTER MODEL {model_fqn} VERSION PRODUCTION UNSET ALIAS\").collect()\n        print(\"üßπ Alias 'PRODUCTION' removido del version anterior\")\n    except Exception as alias_unset_err:\n        print(f\"‚ÑπÔ∏è  No se pudo remover alias previo (puede no existir): {str(alias_unset_err)[:120]}\")\n\n    session.sql(\n        # Alias es un IDENTIFIER; evitar comillas simples para prevenir errores de parsing.\n        f\"ALTER MODEL {model_fqn} VERSION {new_version_name} SET ALIAS=PRODUCTION\"\n    ).collect()\n    print(\"üè∑Ô∏è  Alias 'PRODUCTION' movido al nuevo version\")\n\nexcept Exception as e:\n    print(f\"\\n‚ùå Error registering model: {str(e)}\")\n    raise\n",
      "id": "e0b1b28e-5423-4d88-a30b-a799bbbd520b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 6. Verify Registration\n",
      "id": "9b86a3a0-5e5a-4327-85de-6e166c0e9c9e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üîç VERIFYING REGISTRATION\")\nprint(\"=\" * 80)\n\nresult = session.sql(\n    \"\"\"\n    SHOW MODELS LIKE 'UNI_BOX_REGRESSION_PARTITIONED' \n    IN SCHEMA BD_AA_DEV.SC_MODELS_BMX\n\"\"\"\n).collect()\n\nif result:\n    print(\"‚úÖ Partitioned model found in registry\")\n\n    versions = session.sql(\n        \"\"\"\n        SHOW VERSIONS IN MODEL BD_AA_DEV.SC_MODELS_BMX.UNI_BOX_REGRESSION_PARTITIONED\n    \"\"\"\n    ).collect()\n\n    print(f\"\\nüìä Versions: {len(versions)}\")\n    for v in versions[-3:]:\n        print(f\"   - {v['name']}\")\nelse:\n    print(\"‚ùå Model not found in registry\")\n",
      "id": "c1dc6430-f69b-4d97-84c5-1af058acfce7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 7. Summary\n",
      "id": "ffa0f26e-7d08-402a-a2d8-41207da93a08"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"‚úÖ PARTITIONED MODEL CREATION COMPLETE!\")\nprint(\"=\" * 80)\n\nprint(\"\\nüìã Summary:\")\nprint(f\"   ‚úÖ Source models: {len(loaded_models)} group-specific models\")\nprint(f\"   ‚úÖ Partitioned model: UNI_BOX_REGRESSION_PARTITIONED\")\nprint(f\"   ‚úÖ Version: v_{version_date}\")\nprint(f\"   ‚úÖ Alias: PRODUCTION\")\nprint(f\"   ‚úÖ Features: {len(feature_cols)}\")\nprint(\n    f\"   ‚úÖ Groups: {', '.join(sorted(loaded_models.keys())[:5])}... ({len(loaded_models)} total)\"\n)\n\nprint(\"\\nüí° Next Steps:\")\nprint(\"   1. Review partitioned model registration\")\nprint(\"   2. Run 06_partitioned_inference_batch.py for batch inference\")\nprint(\n    \"   3. Use partitioned inference syntax: TABLE(model!PREDICT(...) OVER (PARTITION BY stats_ntile_group))\"\n)\n\nprint(\"\\nüéØ Key Benefits:\")\nprint(\"   - 16 models combined into one partitioned model\")\nprint(\"   - Automatic routing by stats_ntile_group\")\nprint(\"   - Consistent inference syntax\")\nprint(\"   - Each group uses its optimized hyperparameters\")\n\nprint(\"\\n\" + \"=\" * 80)\n",
      "id": "b0ad70d0-9a28-4460-a9b3-3b1693d0309d",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}