{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "# Modelo particionado (16 modelos de 04)\nCarga los modelos por grupo del Registry, crea CustomModel con API particionada y lo registra.\n",
      "id": "f82654c8-6256-4f63-9d00-91f80d6d4a1d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "from snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark import functions as F\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml.model import custom_model, task\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\n\nsession = get_active_session()\nsession.sql(\"USE DATABASE BD_AA_DEV\").collect()\nsession.sql(\"USE SCHEMA SC_STORAGE_BMX_PS\").collect()\nregistry = Registry(session=session, database_name=\"BD_AA_DEV\", schema_name=\"SC_MODELS_BMX\")\nprint(f\"‚úÖ {session.get_current_database()}.{session.get_current_schema()}\")\n",
      "id": "ec919b6c-dab8-4a51-b0a6-dd551cdee571",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 1. Cargar los 16 modelos (PRODUCTION)\n",
      "id": "c3b4f9dd-6159-4b36-b865-8e55c2125d78"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "\ngroups_df = session.sql(\n    \"\"\"\n    SELECT DISTINCT stats_ntile_group AS GROUP_NAME\n    FROM BD_AA_DEV.SC_STORAGE_BMX_PS.TRAIN_DATASET_CLEANED\n    WHERE stats_ntile_group IS NOT NULL\n    ORDER BY stats_ntile_group\n\"\"\"\n)\ngroups_list = [row[\"GROUP_NAME\"] for row in groups_df.collect()]\nprint(f\"\\nüìä Grupos: {len(groups_list)}\")\n\nloaded_models = {}\nfeature_cols = None\n\nfor group_name in groups_list:\n    model_name = f\"uni_box_regression_{group_name.lower()}\"\n    try:\n        model_ref = registry.get_model(model_name)\n        model_version = model_ref.version(\"PRODUCTION\")\n        native_model = model_version.load()\n        if feature_cols is None:\n            feature_cols = getattr(native_model, \"feature_cols\", None)\n            if not feature_cols:\n                raise ValueError(\"Model has no feature_cols; run 04 first.\")\n        loaded_models[group_name] = {\"model\": native_model, \"model_version\": model_version, \"model_name\": model_name}\n        ver_name = getattr(model_version, \"name\", str(model_version))\n        print(f\"‚úÖ {group_name} (versi√≥n: {ver_name})\")\n    except Exception as e:\n        print(f\"‚ùå {group_name}: {str(e)[:100]}\")\n\nif not loaded_models:\n    raise ValueError(\"No models loaded. Run 04_many_model_training.py first.\")\nif len(loaded_models) < len(groups_list):\n    print(f\"‚ö†Ô∏è  {len(loaded_models)}/{len(groups_list)} modelos cargados\")\nversions_loaded = {getattr(m[\"model_version\"], \"name\", None) for m in loaded_models.values()}\nprint(f\"\\n‚úÖ {len(loaded_models)} modelos, {len(feature_cols)} features (alias PRODUCTION ‚Üí {versions_loaded or 'N/A'})\")\n",
      "id": "1e5e4e14-e731-49be-b8f0-c19986175654",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 2. Define Partitioned Model Class\n",
      "id": "9311845e-2b8a-4525-9e82-0493971a238f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üîß DEFINING PARTITIONED MODEL CLASS\")\nprint(\"=\" * 80)\n\n\nclass PartitionedUniBoxModel(custom_model.CustomModel):\n    \"\"\"Modelo particionado: enruta predicciones por stats_ntile_group.\"\"\"\n\n    def __init__(self, model_context):\n        super().__init__(model_context)\n        # Usamos las mismas columnas de features detectadas al cargar los modelos base\n        self.feature_cols = feature_cols\n\n    @custom_model.partitioned_api\n    def predict(self, input_df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"Predicci√≥n por grupo; enruta seg√∫n stats_ntile_group.\"\"\"\n        if len(input_df) == 0:\n            return pd.DataFrame(\n                columns=[\n                    \"customer_id\",\n                    \"stats_ntile_group\",\n                    \"week\",\n                    \"brand_pres_ret\",\n                    \"predicted_uni_box_week\",\n                ]\n            )\n\n        part_col = \"stats_ntile_group\" if \"stats_ntile_group\" in input_df.columns else \"STATS_NTILE_GROUP\"\n        group_name = input_df[part_col].iloc[0]\n\n        model_key = group_name.lower()\n        try:\n            model = self.context.model_ref(model_key)\n        except Exception:\n            try:\n                model = self.context.model_ref(group_name.lower())\n            except Exception:\n                raise ValueError(f\"Model not found for group: {group_name}. Keys: {list(self.context.models.keys())}\")\n\n        # Seleccionamos √∫nicamente las columnas de features ya conocidas\n        X = input_df[self.feature_cols].fillna(0).astype(np.float64, errors=\"ignore\")\n        pred_out = model.predict(X)\n\n        if isinstance(pred_out, pd.DataFrame):\n            pred_col = next((c for c in pred_out.columns if \"PREDICT\" in c.upper() or \"OUTPUT\" in c.upper()), pred_out.columns[0])\n            predictions = np.asarray(pred_out[pred_col], dtype=np.float64).ravel()\n        elif hasattr(pred_out, \"flatten\"):\n            predictions = np.asarray(pred_out).flatten()\n        else:\n            predictions = np.asarray(pred_out).ravel()\n\n        # Propagar columnas de contexto para evitar JOINs ambiguos en inferencia\n        cust = (\n            input_df[\"customer_id\"].values\n            if \"customer_id\" in input_df.columns\n            else np.arange(len(predictions))\n        )\n        week_vals = (\n            input_df[\"week\"].values if \"week\" in input_df.columns else [None] * len(predictions)\n        )\n        brand_vals = (\n            input_df[\"brand_pres_ret\"].values\n            if \"brand_pres_ret\" in input_df.columns\n            else [None] * len(predictions)\n        )\n\n        return pd.DataFrame(\n            {\n                \"customer_id\": cust,\n                \"stats_ntile_group\": group_name,\n                \"week\": week_vals,\n                \"brand_pres_ret\": brand_vals,\n                \"predicted_uni_box_week\": predictions,\n            }\n        )\n\n\nprint(\"‚úÖ PartitionedUniBoxModel class defined\")\n",
      "id": "83b9992f-c41f-42e1-a01c-6b46412fd32c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 3. Create Model Context and Partitioned Model\n",
      "id": "021d0b3e-b9ad-4db1-99ba-82b0182fbb76"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üì¶ CREATING PARTITIONED MODEL\")\nprint(\"=\" * 80)\n\nmodels_dict = {}\nfor group_name, model_info in loaded_models.items():\n    model_key = group_name.lower()\n    models_dict[model_key] = model_info[\"model\"]\n    print(f\"   Added {group_name} ‚Üí {model_key}\")\nprint(f\"\\n‚úÖ ModelContext created with {len(models_dict)} models\")\n\nmodel_context = custom_model.ModelContext(models=models_dict)\npartitioned_model = PartitionedUniBoxModel(model_context=model_context)\nprint(\"‚úÖ Partitioned model created\")\n",
      "id": "fd2abe5b-351e-4e8f-b49e-895b9b31e867",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 4. Sample input (homologado con 06: incluye week y brand_pres_ret como contexto)\n",
      "id": "fc65ebe8-7f30-48f4-8db9-fdac548c39ad"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üìã PREPARING SAMPLE INPUT (HOMOLOGADO CON 06)\")\nprint(\"=\" * 80)\n\n# Usar la misma lista de exclusi√≥n que 02/04/06 para asegurar que sample_input tenga la misma firma que inferencia\nexcluded_cols_sample = [\n    \"customer_id\",\n    \"brand_pres_ret\",\n    \"week\",\n    \"group\",\n    \"stats_group\",\n    \"percentile_group\",\n    \"stats_ntile_group\",\n    \"uni_box_week\",  # Target - no es feature\n    \"FEATURE_TIMESTAMP\",\n]\nexcluded_upper_sample = {c.upper() for c in excluded_cols_sample}\n\n# Obtener esquema de training para identificar features num√©ricas (igual que 06 con inference)\ntraining_schema = session.sql(\n    \"DESCRIBE TABLE BD_AA_DEV.SC_STORAGE_BMX_PS.TRAIN_DATASET_CLEANED\"\n).collect()\ncol_type_dict_sample = {row[\"name\"].upper(): str(row[\"type\"]).upper() for row in training_schema}\nall_cols_sample = [row[\"name\"] for row in training_schema]\n\nNUMERIC_PREFIXES_SAMPLE = (\"FLOAT\", \"NUMBER\", \"INTEGER\", \"BIGINT\", \"DOUBLE\")\nfeature_cols_sample = [\n    c for c in all_cols_sample\n    if c.upper() not in excluded_upper_sample\n    and (col_type_dict_sample.get(c.upper()) or \"\").startswith(NUMERIC_PREFIXES_SAMPLE)\n]\n\n# Verificar que feature_cols_sample coincida con feature_cols de los modelos (deber√≠an ser iguales)\nif set(c.upper() for c in feature_cols_sample) != set(c.upper() for c in feature_cols):\n    print(f\"‚ö†Ô∏è  Feature mismatch: sample tiene {len(feature_cols_sample)}, modelos tienen {len(feature_cols)}\")\n    print(f\"   Usando feature_cols de modelos para mantener compatibilidad\")\n    feature_cols_for_sample = feature_cols\nelse:\n    # Ordenar feature_cols_sample seg√∫n el orden de feature_cols para mantener consistencia\n    feature_cols_for_sample = [c for c in feature_cols if c.upper() in {x.upper() for x in feature_cols_sample}]\n    if len(feature_cols_for_sample) != len(feature_cols):\n        print(f\"‚ö†Ô∏è  Algunas features de modelos no est√°n en sample, usando todas las de modelos\")\n        feature_cols_for_sample = feature_cols\n\ntraining_df = session.table(\"BD_AA_DEV.SC_STORAGE_BMX_PS.TRAIN_DATASET_CLEANED\")\nsample_input_sp = (\n    training_df.select(\"customer_id\", \"stats_ntile_group\", \"week\", \"brand_pres_ret\", *feature_cols_for_sample)\n    .filter(training_df[\"stats_ntile_group\"].isin(list(loaded_models.keys())))\n    .group_by(\"stats_ntile_group\")\n    .agg(\n        # Asegurar NO-NULL en columnas de contexto para inferir firma (Snowflake ML requiere al menos un no-null)\n        F.min(F.col(\"customer_id\")).alias(\"customer_id\"),\n        F.coalesce(F.min(F.col(\"week\")), F.lit(\"000000\")).alias(\"week\"),\n        F.coalesce(F.min(F.col(\"brand_pres_ret\")), F.lit(\"UNKNOWN\")).alias(\"brand_pres_ret\"),\n        *[F.min(F.col(c)).alias(c) for c in feature_cols_for_sample],\n    )\n    .select(\"customer_id\", \"stats_ntile_group\", \"week\", \"brand_pres_ret\", *feature_cols_for_sample)\n    .limit(min(16, len(loaded_models)))\n)\nsample_input = sample_input_sp.to_pandas()\nprint(f\"‚úÖ Sample input prepared: {len(sample_input)} rows (one per group)\")\nprint(f\"   Columns: customer_id, stats_ntile_group, week, brand_pres_ret, {len(feature_cols_for_sample)} features\")\nif len(sample_input) == 0:\n    raise ValueError(\"Sample input is empty. Verifica que TRAIN_DATASET_CLEANED tenga los mismos stats_ntile_group que los modelos cargados.\")\n",
      "id": "aeadd231-daa2-4ddd-9ecd-a90a8b82bf12",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 5. Register Partitioned Model\n",
      "id": "96510db4-c7e5-448c-b38c-97931df60a95"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üìù REGISTERING PARTITIONED MODEL\")\nprint(\"=\" * 80)\n\nversion_date = datetime.now().strftime(\"%Y%m%d_%H%M\")\n\nprint(f\"\\nüìù Registering in Model Registry...\")\nprint(f\"   Name: UNI_BOX_REGRESSION_PARTITIONED\")\nprint(f\"   Version: v_{version_date}\")\n\ntry:\n    mv = registry.log_model(\n        partitioned_model,\n        model_name=\"UNI_BOX_REGRESSION_PARTITIONED\",\n        version_name=f\"v_{version_date}\",\n        comment=f\"Partitioned regression model for uni_box_week - Combines {len(loaded_models)} group-specific models (LGBM/XGB/SGD)\",\n        metrics={\n            \"num_groups\": len(loaded_models),\n            \"num_features\": len(feature_cols),\n            \"model_type\": \"mixed\",\n            \"groups\": \",\".join(sorted(loaded_models.keys())),\n        },\n        sample_input_data=sample_input,\n        task=task.Task.TABULAR_REGRESSION,\n        options={\"function_type\": \"TABLE_FUNCTION\"},\n    )\n\n    print(\"\\n‚úÖ Partitioned model registered successfully!\")\n    # Mover alias PRODUCTION de forma \"limpia\":\n    # 1) quitar alias al version previo (si existe)\n    # 2) asignar alias al nuevo version\n    model_fqn = \"BD_AA_DEV.SC_MODELS_BMX.UNI_BOX_REGRESSION_PARTITIONED\"\n    new_version_name = f\"V_{version_date}\"\n    try:\n        session.sql(f\"ALTER MODEL {model_fqn} VERSION PRODUCTION UNSET ALIAS\").collect()\n        print(\"üßπ Alias 'PRODUCTION' removido del version anterior\")\n    except Exception as alias_unset_err:\n        print(f\"‚ÑπÔ∏è  No se pudo remover alias previo (puede no existir): {str(alias_unset_err)[:120]}\")\n\n    session.sql(\n        f\"ALTER MODEL {model_fqn} VERSION {new_version_name} SET ALIAS='PRODUCTION'\"\n    ).collect()\n    print(\"üè∑Ô∏è  Alias 'PRODUCTION' movido al nuevo version\")\n\nexcept Exception as e:\n    print(f\"\\n‚ùå Error registering model: {str(e)}\")\n    raise\n",
      "id": "20166744-9e89-4eef-b855-78ebc9e6d19a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 6. Verify Registration\n",
      "id": "d3e8ad5b-5132-4ee1-8001-63253d88df02"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üîç VERIFYING REGISTRATION\")\nprint(\"=\" * 80)\n\nresult = session.sql(\n    \"\"\"\n    SHOW MODELS LIKE 'UNI_BOX_REGRESSION_PARTITIONED' \n    IN SCHEMA BD_AA_DEV.SC_MODELS_BMX\n\"\"\"\n).collect()\n\nif result:\n    print(\"‚úÖ Partitioned model found in registry\")\n\n    versions = session.sql(\n        \"\"\"\n        SHOW VERSIONS IN MODEL BD_AA_DEV.SC_MODELS_BMX.UNI_BOX_REGRESSION_PARTITIONED\n    \"\"\"\n    ).collect()\n\n    print(f\"\\nüìä Versions: {len(versions)}\")\n    for v in versions[-3:]:\n        print(f\"   - {v['name']}\")\nelse:\n    print(\"‚ùå Model not found in registry\")\n",
      "id": "d7b95ac4-d648-4b89-8229-6ea6caac8336",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 7. Summary\n",
      "id": "ed180dc4-9289-4880-8e47-4e9d7c17b4fa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"‚úÖ PARTITIONED MODEL CREATION COMPLETE!\")\nprint(\"=\" * 80)\n\nprint(\"\\nüìã Summary:\")\nprint(f\"   ‚úÖ Source models: {len(loaded_models)} group-specific models\")\nprint(f\"   ‚úÖ Partitioned model: UNI_BOX_REGRESSION_PARTITIONED\")\nprint(f\"   ‚úÖ Version: v_{version_date}\")\nprint(f\"   ‚úÖ Alias: PRODUCTION\")\nprint(f\"   ‚úÖ Features: {len(feature_cols)}\")\nprint(\n    f\"   ‚úÖ Groups: {', '.join(sorted(loaded_models.keys())[:5])}... ({len(loaded_models)} total)\"\n)\n\nprint(\"\\nüí° Next Steps:\")\nprint(\"   1. Review partitioned model registration\")\nprint(\"   2. Run 06_partitioned_inference_batch.py for batch inference\")\nprint(\n    \"   3. Use partitioned inference syntax: TABLE(model!PREDICT(...) OVER (PARTITION BY stats_ntile_group))\"\n)\n\nprint(\"\\nüéØ Key Benefits:\")\nprint(\"   - 16 models combined into one partitioned model\")\nprint(\"   - Automatic routing by stats_ntile_group\")\nprint(\"   - Consistent inference syntax\")\nprint(\"   - Each group uses its optimized hyperparameters\")\n\nprint(\"\\n\" + \"=\" * 80)\n",
      "id": "21e409f2-757a-4609-a5c5-954fb1babaa1",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}