{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "# Modelo particionado (16 modelos de 04)\nCarga los modelos por grupo del Registry, crea CustomModel con API particionada y lo registra.\n",
      "id": "49da5c16-02e9-4a64-bb06-410f171288cd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "from snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark import functions as F\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml.model import custom_model, task\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\n\nsession = get_active_session()\nsession.sql(\"USE DATABASE BD_AA_DEV\").collect()\nsession.sql(\"USE SCHEMA SC_STORAGE_BMX_PS\").collect()\nregistry = Registry(session=session, database_name=\"BD_AA_DEV\", schema_name=\"SC_MODELS_BMX\")\nprint(f\"‚úÖ {session.get_current_database()}.{session.get_current_schema()}\")\n",
      "id": "93bdda0f-2a42-4318-833e-f3840b8080df",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 1. Cargar los 16 modelos (PRODUCTION)\n",
      "id": "67109165-0ae5-4d58-83ec-41f969ae4c45"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "\ngroups_df = session.sql(\n    \"\"\"\n    SELECT DISTINCT stats_ntile_group AS GROUP_NAME\n    FROM BD_AA_DEV.SC_STORAGE_BMX_PS.TRAIN_DATASET_CLEANED\n    WHERE stats_ntile_group IS NOT NULL\n    ORDER BY stats_ntile_group\n\"\"\"\n)\ngroups_list = [row[\"GROUP_NAME\"] for row in groups_df.collect()]\nprint(f\"\\nüìä Grupos: {len(groups_list)}\")\n\nloaded_models = {}\nfeature_cols = None\n\nfor group_name in groups_list:\n    model_name = f\"uni_box_regression_{group_name.lower()}\"\n    try:\n        model_ref = registry.get_model(model_name)\n        model_version = model_ref.version(\"PRODUCTION\")\n        native_model = model_version.load()\n        if feature_cols is None:\n            feature_cols = getattr(native_model, \"feature_cols\", None)\n            if not feature_cols:\n                raise ValueError(\"Model has no feature_cols; run 04 first.\")\n        loaded_models[group_name] = {\"model\": native_model, \"model_version\": model_version, \"model_name\": model_name}\n        ver_name = getattr(model_version, \"name\", str(model_version))\n        print(f\"‚úÖ {group_name} (versi√≥n: {ver_name})\")\n    except Exception as e:\n        print(f\"‚ùå {group_name}: {str(e)[:100]}\")\n\nif not loaded_models:\n    raise ValueError(\"No models loaded. Run 04_many_model_training.py first.\")\nif len(loaded_models) < len(groups_list):\n    print(f\"‚ö†Ô∏è  {len(loaded_models)}/{len(groups_list)} modelos cargados\")\nversions_loaded = {getattr(m[\"model_version\"], \"name\", None) for m in loaded_models.values()}\nprint(f\"\\n‚úÖ {len(loaded_models)} modelos, {len(feature_cols)} features (alias PRODUCTION ‚Üí {versions_loaded or 'N/A'})\")\n",
      "id": "02607405-dde0-459e-82e8-dd4a5188e71a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 2. Define Partitioned Model Class\n",
      "id": "b599bf5e-5965-42db-85ee-f15fa040cb53"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üîß DEFINING PARTITIONED MODEL CLASS\")\nprint(\"=\" * 80)\n\n\nclass PartitionedUniBoxModel(custom_model.CustomModel):\n    \"\"\"Modelo particionado: enruta predicciones por stats_ntile_group.\"\"\"\n\n    def __init__(self, model_context):\n        super().__init__(model_context)\n        # Usamos las mismas columnas de features detectadas al cargar los modelos base\n        self.feature_cols = feature_cols\n\n    @custom_model.partitioned_api\n    def predict(self, input_df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"Predicci√≥n por grupo; enruta seg√∫n stats_ntile_group.\"\"\"\n        if len(input_df) == 0:\n            return pd.DataFrame(columns=[\"customer_id\", \"stats_ntile_group\", \"predicted_uni_box_week\"])\n\n        part_col = \"stats_ntile_group\" if \"stats_ntile_group\" in input_df.columns else \"STATS_NTILE_GROUP\"\n        group_name = input_df[part_col].iloc[0]\n\n        model_key = group_name.lower()\n        try:\n            model = self.context.model_ref(model_key)\n        except Exception:\n            try:\n                model = self.context.model_ref(group_name.lower())\n            except Exception:\n                raise ValueError(f\"Model not found for group: {group_name}. Keys: {list(self.context.models.keys())}\")\n\n        # Seleccionamos √∫nicamente las columnas de features ya conocidas\n        X = input_df[self.feature_cols].fillna(0).astype(np.float64, errors=\"ignore\")\n        pred_out = model.predict(X)\n\n        if isinstance(pred_out, pd.DataFrame):\n            pred_col = next((c for c in pred_out.columns if \"PREDICT\" in c.upper() or \"OUTPUT\" in c.upper()), pred_out.columns[0])\n            predictions = np.asarray(pred_out[pred_col], dtype=np.float64).ravel()\n        elif hasattr(pred_out, \"flatten\"):\n            predictions = np.asarray(pred_out).flatten()\n        else:\n            predictions = np.asarray(pred_out).ravel()\n\n        cust = input_df[\"customer_id\"].values if \"customer_id\" in input_df.columns else np.arange(len(predictions))\n        return pd.DataFrame({\n            \"customer_id\": cust,\n            \"stats_ntile_group\": group_name,\n            \"predicted_uni_box_week\": predictions,\n        })\n\n\nprint(\"‚úÖ PartitionedUniBoxModel class defined\")\n",
      "id": "f9b9b3d0-422c-4526-a5a3-1b124c6f576c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 3. Create Model Context and Partitioned Model\n",
      "id": "8ca3179f-4070-4cb9-8f93-f5ad123e1eb9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üì¶ CREATING PARTITIONED MODEL\")\nprint(\"=\" * 80)\n\nmodels_dict = {}\nfor group_name, model_info in loaded_models.items():\n    model_key = group_name.lower()\n    models_dict[model_key] = model_info[\"model\"]\n    print(f\"   Added {group_name} ‚Üí {model_key}\")\nprint(f\"\\n‚úÖ ModelContext created with {len(models_dict)} models\")\n\nmodel_context = custom_model.ModelContext(models=models_dict)\npartitioned_model = PartitionedUniBoxModel(model_context=model_context)\nprint(\"‚úÖ Partitioned model created\")\n",
      "id": "c246405a-dda7-4cf7-916f-1d7ff1a1578a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 4. Sample input (misma l√≥gica de exclusi√≥n que 02/04/06 para homologar firma de PREDICT)\n",
      "id": "58c6b9a5-7148-4257-8e5e-4ae64e431fb2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üìã PREPARING SAMPLE INPUT (HOMOLOGADO CON 06)\")\nprint(\"=\" * 80)\n\n# Usar la misma lista de exclusi√≥n que 02/04/06 para asegurar que sample_input tenga la misma firma que inferencia\nexcluded_cols_sample = [\n    \"customer_id\",\n    \"brand_pres_ret\",\n    \"week\",\n    \"group\",\n    \"stats_group\",\n    \"percentile_group\",\n    \"stats_ntile_group\",\n    \"uni_box_week\",  # Target - no es feature\n    \"FEATURE_TIMESTAMP\",\n]\nexcluded_upper_sample = {c.upper() for c in excluded_cols_sample}\n\n# Obtener esquema de training para identificar features num√©ricas (igual que 06 con inference)\ntraining_schema = session.sql(\n    \"DESCRIBE TABLE BD_AA_DEV.SC_STORAGE_BMX_PS.TRAIN_DATASET_CLEANED\"\n).collect()\ncol_type_dict_sample = {row[\"name\"].upper(): str(row[\"type\"]).upper() for row in training_schema}\nall_cols_sample = [row[\"name\"] for row in training_schema]\n\nNUMERIC_PREFIXES_SAMPLE = (\"FLOAT\", \"NUMBER\", \"INTEGER\", \"BIGINT\", \"DOUBLE\")\nfeature_cols_sample = [\n    c for c in all_cols_sample\n    if c.upper() not in excluded_upper_sample\n    and (col_type_dict_sample.get(c.upper()) or \"\").startswith(NUMERIC_PREFIXES_SAMPLE)\n]\n\n# Verificar que feature_cols_sample coincida con feature_cols de los modelos (deber√≠an ser iguales)\nif set(c.upper() for c in feature_cols_sample) != set(c.upper() for c in feature_cols):\n    print(f\"‚ö†Ô∏è  Feature mismatch: sample tiene {len(feature_cols_sample)}, modelos tienen {len(feature_cols)}\")\n    print(f\"   Usando feature_cols de modelos para mantener compatibilidad\")\n    feature_cols_for_sample = feature_cols\nelse:\n    # Ordenar feature_cols_sample seg√∫n el orden de feature_cols para mantener consistencia\n    feature_cols_for_sample = [c for c in feature_cols if c.upper() in {x.upper() for x in feature_cols_sample}]\n    if len(feature_cols_for_sample) != len(feature_cols):\n        print(f\"‚ö†Ô∏è  Algunas features de modelos no est√°n en sample, usando todas las de modelos\")\n        feature_cols_for_sample = feature_cols\n\ntraining_df = session.table(\"BD_AA_DEV.SC_STORAGE_BMX_PS.TRAIN_DATASET_CLEANED\")\nsample_input_sp = (\n    training_df.select(\"customer_id\", \"stats_ntile_group\", *feature_cols_for_sample)\n    .filter(training_df[\"stats_ntile_group\"].isin(list(loaded_models.keys())))\n    .group_by(\"stats_ntile_group\")\n    .agg(*[F.min(F.col(c)).alias(c) for c in [\"customer_id\"] + feature_cols_for_sample])\n    .select(\"customer_id\", \"stats_ntile_group\", *feature_cols_for_sample)\n    .limit(min(16, len(loaded_models)))\n)\nsample_input = sample_input_sp.to_pandas()\nprint(f\"‚úÖ Sample input prepared: {len(sample_input)} rows (one per group)\")\nprint(f\"   Columns: customer_id, stats_ntile_group, {len(feature_cols_for_sample)} features\")\n",
      "id": "7d5444a6-f1fa-40d8-80b1-904b223af197",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 5. Register Partitioned Model\n",
      "id": "269d3287-f2df-40c9-ad1d-b1f0aca794b5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üìù REGISTERING PARTITIONED MODEL\")\nprint(\"=\" * 80)\n\nversion_date = datetime.now().strftime(\"%Y%m%d_%H%M\")\n\nprint(f\"\\nüìù Registering in Model Registry...\")\nprint(f\"   Name: UNI_BOX_REGRESSION_PARTITIONED\")\nprint(f\"   Version: v_{version_date}\")\n\ntry:\n    mv = registry.log_model(\n        partitioned_model,\n        model_name=\"UNI_BOX_REGRESSION_PARTITIONED\",\n        version_name=f\"v_{version_date}\",\n        comment=f\"Partitioned regression model for uni_box_week - Combines {len(loaded_models)} group-specific models (LGBM/XGB/SGD)\",\n        metrics={\n            \"num_groups\": len(loaded_models),\n            \"num_features\": len(feature_cols),\n            \"model_type\": \"mixed\",\n            \"groups\": \",\".join(sorted(loaded_models.keys())),\n        },\n        sample_input_data=sample_input,\n        task=task.Task.TABULAR_REGRESSION,\n        options={\"function_type\": \"TABLE_FUNCTION\"},\n    )\n\n    print(\"\\n‚úÖ Partitioned model registered successfully!\")\n    mv.set_alias(\"PRODUCTION\")\n    print(f\"üè∑Ô∏è  Alias 'PRODUCTION' configured\")\n\nexcept Exception as e:\n    print(f\"\\n‚ùå Error registering model: {str(e)}\")\n    raise\n",
      "id": "55fc3582-905b-4300-bdd3-81886b53b6e7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 6. Verify Registration\n",
      "id": "abe6e5b4-11bb-45d5-8ae6-7d8794e2a834"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üîç VERIFYING REGISTRATION\")\nprint(\"=\" * 80)\n\nresult = session.sql(\n    \"\"\"\n    SHOW MODELS LIKE 'UNI_BOX_REGRESSION_PARTITIONED' \n    IN SCHEMA BD_AA_DEV.SC_MODELS_BMX\n\"\"\"\n).collect()\n\nif result:\n    print(\"‚úÖ Partitioned model found in registry\")\n\n    versions = session.sql(\n        \"\"\"\n        SHOW VERSIONS IN MODEL BD_AA_DEV.SC_MODELS_BMX.UNI_BOX_REGRESSION_PARTITIONED\n    \"\"\"\n    ).collect()\n\n    print(f\"\\nüìä Versions: {len(versions)}\")\n    for v in versions[-3:]:\n        print(f\"   - {v['name']}\")\nelse:\n    print(\"‚ùå Model not found in registry\")\n",
      "id": "9531dd56-1f2b-4130-84ef-74bc9e58cad5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 7. Summary\n",
      "id": "b3b45fd5-81de-4028-a1bd-1eb174ea9e33"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"‚úÖ PARTITIONED MODEL CREATION COMPLETE!\")\nprint(\"=\" * 80)\n\nprint(\"\\nüìã Summary:\")\nprint(f\"   ‚úÖ Source models: {len(loaded_models)} group-specific models\")\nprint(f\"   ‚úÖ Partitioned model: UNI_BOX_REGRESSION_PARTITIONED\")\nprint(f\"   ‚úÖ Version: v_{version_date}\")\nprint(f\"   ‚úÖ Alias: PRODUCTION\")\nprint(f\"   ‚úÖ Features: {len(feature_cols)}\")\nprint(\n    f\"   ‚úÖ Groups: {', '.join(sorted(loaded_models.keys())[:5])}... ({len(loaded_models)} total)\"\n)\n\nprint(\"\\nüí° Next Steps:\")\nprint(\"   1. Review partitioned model registration\")\nprint(\"   2. Run 06_partitioned_inference_batch.py for batch inference\")\nprint(\n    \"   3. Use partitioned inference syntax: TABLE(model!PREDICT(...) OVER (PARTITION BY stats_ntile_group))\"\n)\n\nprint(\"\\nüéØ Key Benefits:\")\nprint(\"   - 16 models combined into one partitioned model\")\nprint(\"   - Automatic routing by stats_ntile_group\")\nprint(\"   - Consistent inference syntax\")\nprint(\"   - Each group uses its optimized hyperparameters\")\n\nprint(\"\\n\" + \"=\" * 80)\n",
      "id": "7da08aaa-2686-4240-ba45-67de48bc0b25",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}