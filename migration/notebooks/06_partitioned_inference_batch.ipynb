{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "# Partitioned Inference ‚Äî UNI_BOX_REGRESSION_PARTITIONED\n#\nInference using **PRODUCTION** alias directly, with optional SAMPLE.\n",
      "id": "53d7666e-181d-4152-af2a-1813995c1249"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "from snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark import functions as F\nfrom snowflake.ml.registry import Registry\nimport time\nimport math\n",
      "id": "6ab47fea-42ff-43d9-9ebb-2492d112653a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Configuration\nINFERENCE_SAMPLE_FRACTION = 0.01\n\n# Number of rows per batch. Leave as None to disable batching.\nBATCH_SIZE = 1_000_000\n\nDATABASE = \"BD_AA_DEV\"\nSTORAGE_SCHEMA = \"SC_STORAGE_BMX_PS\"\nMODEL_SCHEMA = \"SC_MODELS_BMX\"\nPARTITIONED_MODEL_NAME = \"UNI_BOX_REGRESSION_PARTITIONED\"\nPREDICTIONS_TABLE = f\"{DATABASE}.{STORAGE_SCHEMA}.INFERENCE_PREDICTIONS\"\n\nSOURCE_TABLE = f\"{DATABASE}.{STORAGE_SCHEMA}.INFERENCE_DATASET_CLEANED\"\nMODEL_FQN = f\"{DATABASE}.{MODEL_SCHEMA}.{PARTITIONED_MODEL_NAME}\"\n",
      "id": "7e128a96-a6ed-4491-a672-0217b0c7f64e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "session = get_active_session()\nsession.sql(f\"USE DATABASE {DATABASE}\").collect()\nsession.sql(f\"USE SCHEMA {STORAGE_SCHEMA}\").collect()\n\nprint(\"‚úÖ Connected to Snowflake\")\nprint(f\"   Model: {PARTITIONED_MODEL_NAME} (PRODUCTION alias)\")\n",
      "id": "7c746e2c-5ad4-4f9d-afb6-1ef42eeedaee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## Input sampling\n",
      "id": "e991b71f-53d0-419a-9170-2ebbf8bd6b32"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "input_df = session.table(SOURCE_TABLE)\n\nif INFERENCE_SAMPLE_FRACTION is not None and 0 < INFERENCE_SAMPLE_FRACTION < 1:\n    input_df = input_df.sample(frac=INFERENCE_SAMPLE_FRACTION)\n    print(f\"‚ö†Ô∏è  Using SAMPLE (Snowpark): {INFERENCE_SAMPLE_FRACTION*100:.2f}%\")\nelse:\n    print(\"‚úÖ Using FULL dataset (Snowpark)\")\n",
      "id": "60686cb9-afdf-482e-9a39-4c6d15081eaf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Create temporary view of input\ninput_df.create_or_replace_temp_view(\"INFERENCE_INPUT\")\n",
      "id": "84719a6c-943c-4f35-9c8e-5796e8df487f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## Partitioned Inference and Save to Table (single-pass, explicit PRODUCTION alias)\n",
      "id": "1f0b50a0-81f6-441b-bc4a-a91dd3e6b826"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Get model version information (used to tag predictions)\ntry:\n    registry = Registry(\n        session=session,\n        database_name=DATABASE,\n        schema_name=MODEL_SCHEMA,\n    )\n    model_ref = registry.get_model(PARTITIONED_MODEL_NAME)\n    model_version = model_ref.version(\"PRODUCTION\")\n    # ModelVersion may expose the version name under different attributes depending on library version\n    model_version_name = getattr(model_version, \"version\", getattr(model_version, \"version_name\", str(model_version)))\n    print(f\"‚úÖ Using model version: {model_version_name}\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è  Could not get model version: {str(e)[:200]}\")\n    model_version_name = \"UNKNOWN\"\n\n# Create predictions table with SQL (including auto-incremental primary key)\ncreate_predictions_table_sql = f\"\"\"\nCREATE TABLE IF NOT EXISTS {PREDICTIONS_TABLE} (\n    PREDICTION_ID NUMBER(38,0) AUTOINCREMENT PRIMARY KEY,\n    CUSTOMER_ID VARCHAR,\n    STATS_NTILE_GROUP VARCHAR,\n    WEEK VARCHAR,\n    BRAND_PRES_RET VARCHAR,\n    PROD_KEY VARCHAR,\n    PREDICTED_UNI_BOX_WEEK FLOAT,\n    MODEL_VERSION VARCHAR,\n    PREDICTION_TIMESTAMP TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()\n)\n\"\"\"\n\nsession.sql(create_predictions_table_sql).collect()\nprint(f\"‚úÖ Predictions table ready: {PREDICTIONS_TABLE} (with auto-incremental PRIMARY KEY)\")\n",
      "id": "6e1082ba-133f-42dd-842c-6f16ffa9bc4f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Truncate predictions table before running inference\nsession.sql(f\"TRUNCATE TABLE {PREDICTIONS_TABLE}\").collect()\nprint(f\"üßπ Predictions table truncated: {PREDICTIONS_TABLE}\")\n",
      "id": "c114b4b8-5410-4c98-8f62-2fa6bdb74f0c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Run partitioned inference and insert predictions into table, optionally in batches\nprint(\"üöÄ RUNNING PARTITIONED INFERENCE AND SAVING TO TABLE (MODEL(..., PRODUCTION))\")\nstart_time = time.time()\n\ntotal_rows = input_df.count()\nprint(f\"üìä Input rows (after sampling if applied): {total_rows:,}\")\n\nif BATCH_SIZE is None:\n    # Inference without batching (single pass)\n    insert_predictions_sql = f\"\"\"\n    INSERT INTO {PREDICTIONS_TABLE}\n    (CUSTOMER_ID, STATS_NTILE_GROUP, WEEK, BRAND_PRES_RET, PROD_KEY, PREDICTED_UNI_BOX_WEEK, MODEL_VERSION)\n    SELECT\n        p.CUSTOMER_ID,\n        p.STATS_NTILE_GROUP,\n        p.WEEK,\n        p.BRAND_PRES_RET,\n        p.PROD_KEY,\n        p.predicted_uni_box_week,\n        '{model_version_name}' AS MODEL_VERSION\n    FROM INFERENCE_INPUT t,\n    TABLE(\n      MODEL({MODEL_FQN}, PRODUCTION)!PREDICT(\n        t.CUSTOMER_ID,\n        t.STATS_NTILE_GROUP,\n        t.WEEK,\n        t.BRAND_PRES_RET,\n        t.PROD_KEY,\n        t.SUM_PAST_12_WEEKS,\n        t.AVG_PAST_12_WEEKS,\n        t.MAX_PAST_24_WEEKS,\n        t.SUM_PAST_24_WEEKS,\n        t.WEEK_OF_YEAR,\n        t.AVG_AVG_DAILY_ALL_HOURS,\n        t.SUM_P4W,\n        t.AVG_PAST_24_WEEKS,\n        t.PHARM_SUPER_CONV,\n        t.WINES_LIQUOR,\n        t.GROCERIES,\n        t.MAX_PREV2,\n        t.AVG_PREV2,\n        t.MAX_PREV3,\n        t.AVG_PREV3,\n        t.W_M1_TOTAL,\n        t.W_M2_TOTAL,\n        t.W_M3_TOTAL,\n        t.W_M4_TOTAL,\n        t.SPEC_FOODS,\n        t.NUM_COOLERS,\n        t.NUM_DOORS,\n        t.MAX_PAST_4_WEEKS,\n        t.SUM_PAST_4_WEEKS,\n        t.AVG_PAST_4_WEEKS,\n        t.MAX_PAST_12_WEEKS\n      ) OVER (PARTITION BY t.STATS_NTILE_GROUP)\n    ) p\n    \"\"\"\n\n    session.sql(insert_predictions_sql).collect()\nelse:\n    # Inference in batches of BATCH_SIZE rows using ROW_NUMBER over the input view\n    num_batches = math.ceil(total_rows / BATCH_SIZE) if total_rows > 0 else 0\n    print(f\"üì¶ Running in batches of {BATCH_SIZE:,} rows ({num_batches} batch(es))\")\n\n    for batch_idx in range(num_batches):\n        batch_start = batch_idx * BATCH_SIZE + 1\n        batch_end = min((batch_idx + 1) * BATCH_SIZE, total_rows)\n        print(f\"   ‚ûú Batch {batch_idx + 1}/{num_batches}: rows {batch_start:,} - {batch_end:,}\")\n\n        insert_predictions_sql_batch = f\"\"\"\n        INSERT INTO {PREDICTIONS_TABLE}\n        (CUSTOMER_ID, STATS_NTILE_GROUP, WEEK, BRAND_PRES_RET, PROD_KEY, PREDICTED_UNI_BOX_WEEK, MODEL_VERSION)\n        WITH INPUT_BATCH AS (\n            SELECT\n                *,\n                ROW_NUMBER() OVER (ORDER BY CUSTOMER_ID, WEEK, BRAND_PRES_RET, PROD_KEY) AS RN\n            FROM INFERENCE_INPUT\n        )\n        SELECT\n            p.CUSTOMER_ID,\n            p.STATS_NTILE_GROUP,\n            p.WEEK,\n            p.BRAND_PRES_RET,\n            p.PROD_KEY,\n            p.predicted_uni_box_week,\n            '{model_version_name}' AS MODEL_VERSION\n        FROM INPUT_BATCH t,\n        TABLE(\n          MODEL({MODEL_FQN}, PRODUCTION)!PREDICT(\n            t.CUSTOMER_ID,\n            t.STATS_NTILE_GROUP,\n            t.WEEK,\n            t.BRAND_PRES_RET,\n            t.PROD_KEY,\n            t.SUM_PAST_12_WEEKS,\n            t.AVG_PAST_12_WEEKS,\n            t.MAX_PAST_24_WEEKS,\n            t.SUM_PAST_24_WEEKS,\n            t.WEEK_OF_YEAR,\n            t.AVG_AVG_DAILY_ALL_HOURS,\n            t.SUM_P4W,\n            t.AVG_PAST_24_WEEKS,\n            t.PHARM_SUPER_CONV,\n            t.WINES_LIQUOR,\n            t.GROCERIES,\n            t.MAX_PREV2,\n            t.AVG_PREV2,\n            t.MAX_PREV3,\n            t.AVG_PREV3,\n            t.W_M1_TOTAL,\n            t.W_M2_TOTAL,\n            t.W_M3_TOTAL,\n            t.W_M4_TOTAL,\n            t.SPEC_FOODS,\n            t.NUM_COOLERS,\n            t.NUM_DOORS,\n            t.MAX_PAST_4_WEEKS,\n            t.SUM_PAST_4_WEEKS,\n            t.AVG_PAST_4_WEEKS,\n            t.MAX_PAST_12_WEEKS\n          ) OVER (PARTITION BY t.STATS_NTILE_GROUP)\n        ) p\n        WHERE t.RN BETWEEN {batch_start} AND {batch_end}\n        \"\"\"\n\n        session.sql(insert_predictions_sql_batch).collect()\n\nelapsed = time.time() - start_time\n\npredictions_df = session.table(PREDICTIONS_TABLE).filter(\n    F.col(\"MODEL_VERSION\") == model_version_name\n)\npredictions_count = predictions_df.count()\nprint(f\"‚úÖ {predictions_count:,} predictions saved to {PREDICTIONS_TABLE} in {elapsed:.2f}s (MODEL(..., PRODUCTION))\")\nprint(f\"   Model version: {model_version_name}\")\npredictions_df.order_by(\"PREDICTION_ID\").show(10)\n",
      "id": "4c6a5d0d-23bc-450c-a215-8c90500a3210",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## (Optional) Sample Inference via Registry + PRODUCTION (Python/pandas)\n#\nUseful for debugging, quick validation or inspecting model output\ndirectly in Python, using the same version labeled as PRODUCTION.\n",
      "id": "dffcd1c9-1324-4df7-b37d-0b3620e970ed"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\nüîç OPTIONAL: SAMPLE PREDICTION VIA REGISTRY (PRODUCTION)\")\n\ntry:\n    # Create Registry pointing to the same database/schema of models\n    registry = Registry(\n        session=session,\n        database_name=DATABASE,\n        schema_name=MODEL_SCHEMA,\n    )\n\n    # Get the model and select the PRODUCTION version\n    model_ref = registry.get_model(PARTITIONED_MODEL_NAME)\n    model_version = model_ref.version(\"PRODUCTION\")\n    # Use force=True to skip package version validation if local environment differs\n    local_model = model_version.load(force=True)\n\n    # Take a small sample of input to avoid loading everything into memory\n    sample_sp = input_df.limit(100)\n    sample_pdf = sample_sp.to_pandas()\n\n    # Execute local prediction using CustomModel (PartitionedUniBoxModel)\n    sample_pred_pdf = local_model.predict(sample_pdf)\n\n    print(\"‚úÖ Sample prediction via Registry (PRODUCTION) completed\")\n    print(sample_pred_pdf.head())\nexcept Exception as e:\n    print(f\"‚ÑπÔ∏è  Skipping optional local prediction via Registry: {e}\")\n    print(\"   Note: This requires local installation of model dependencies (lightgbm, xgboost, etc.)\")\n    print(\"   The main SQL-based inference above works without these local dependencies.\")\n",
      "id": "39aa2d82-3b10-4297-8561-decdb12fc5dd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}