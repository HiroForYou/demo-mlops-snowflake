{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "# Partitioned Inference Batch\nLoad inference data, run TABLE(model!PREDICT(...) OVER (PARTITION BY stats_ntile_group)), save to INFERENCE_LOGS.\n",
      "id": "a10cae66-4fc7-4fd6-bf07-58e196c40880"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "from snowflake.snowpark.context import get_active_session\nfrom snowflake.ml.registry import Registry\nimport time\n\nsession = get_active_session()\nsession.sql(\"USE DATABASE BD_AA_DEV\").collect()\nsession.sql(\"USE SCHEMA SC_STORAGE_BMX_PS\").collect()\n\nregistry = Registry(\n    session=session,\n    database_name=\"BD_AA_DEV\",\n    schema_name=\"SC_MODELS_BMX\"\n)\n\nINFERENCE_SAMPLE_FRACTION = 0.01\n\nprint(\"‚úÖ Connected to Snowflake\")\nprint(f\"   Database: {session.get_current_database()}\")\nprint(f\"   Schema: {session.get_current_schema()}\")\nif INFERENCE_SAMPLE_FRACTION:\n    print(f\"   ‚ö†Ô∏è  Sampling: {INFERENCE_SAMPLE_FRACTION*100:.1f}% del dataset de inferencia\")\n",
      "id": "0aeeb03b-1029-4135-b5e3-ec9060cc29df",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 1. Verify model\n",
      "id": "0a8e7554-3d7b-4bca-bfa3-cbd89d15817e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üîç VERIFYING PARTITIONED MODEL\")\nprint(\"=\"*80)\n\nmodel_ref = registry.get_model(\"UNI_BOX_REGRESSION_PARTITIONED\")\nmodel_version = model_ref.version(\"PRODUCTION\")\nprint(f\"‚úÖ UNI_BOX_REGRESSION_PARTITIONED @ {model_version.version_name} (PRODUCTION)\")\n",
      "id": "852dc7cd-1d99-4d84-a401-29472c3c1910",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 2. Load inference data (directamente desde INFERENCE_DATASET_CLEANED)\nNo se usa Feature Store: inferencia consume la tabla cleaned con las mismas columnas que valid√≥ 01 (compatibles con training).\n",
      "id": "c7c3da3f-7211-4569-9c9b-acc03276f5ce"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üìã LOADING INFERENCE DATA (INFERENCE_DATASET_CLEANED)\")\nprint(\"=\"*80)\n\ninference_df = session.table(\"BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_DATASET_CLEANED\")\n\npartition_col = next((c for c in inference_df.columns if c.upper() == \"STATS_NTILE_GROUP\"), None)\nif partition_col is None:\n    raise ValueError(\"stats_ntile_group not found in inference dataset.\")\n\nif INFERENCE_SAMPLE_FRACTION and 0 < INFERENCE_SAMPLE_FRACTION < 1:\n    inference_df = inference_df.sample(frac=INFERENCE_SAMPLE_FRACTION)\n\nn_records = inference_df.count()\nprint(f\"   Inference records: {n_records:,}\")\ninference_df.group_by(partition_col).count().sort(partition_col).show()\n\nprint(f\"‚úÖ Loaded {n_records:,} records from INFERENCE_DATASET_CLEANED (sin Feature Store)\")\ninference_df.select(\"customer_id\", \"week\", \"brand_pres_ret\", partition_col, \"sum_past_12_weeks\", \"week_of_year\").show(5)\n",
      "id": "5df8cadc-9047-4445-b8af-47ca992b70d2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 3. Prepare inference input (misma exclusi√≥n que 02/04: solo features num√©ricas, sin metadata)\n",
      "id": "64ea1441-a4cb-447c-a190-321f99a6d1d8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üîß PREPARING INFERENCE INPUT\")\nprint(\"=\"*80)\n\n# Misma lista de exclusi√≥n que script 02 (Feature Store) y 04: no son features para el modelo\nexcluded_cols = [\n    \"customer_id\",\n    \"brand_pres_ret\",\n    \"week\",\n    \"group\",\n    \"stats_group\",\n    \"percentile_group\",\n    \"stats_ntile_group\",\n    \"FEATURE_TIMESTAMP\",\n]\nexcluded_upper = {c.upper() for c in excluded_cols}\n\n# Obtener esquema de la tabla de inferencia para identificar solo columnas de features (num√©ricas, no excluidas)\ninference_schema = session.sql(\n    \"DESCRIBE TABLE BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_DATASET_CLEANED\"\n).collect()\ncol_type_dict = {row[\"name\"].upper(): str(row[\"type\"]).upper() for row in inference_schema}\nall_cols = [row[\"name\"] for row in inference_schema]\n\nNUMERIC_PREFIXES = (\"FLOAT\", \"NUMBER\", \"INTEGER\", \"BIGINT\", \"DOUBLE\")\nfeature_cols_actual = [\n    c for c in all_cols\n    if c.upper() not in excluded_upper\n    and (col_type_dict.get(c.upper()) or \"\").startswith(NUMERIC_PREFIXES)\n]\n\n# Crear INFERENCE_INPUT_TEMP solo con columnas necesarias: claves + partition + features (lo que espera PREDICT)\n# Excluir group, stats_group, percentile_group y cualquier no-feature (VARCHAR como PROD_KEY) para que PREDICT reciba la firma correcta\nkeys_and_partition_upper = {\"CUSTOMER_ID\", \"BRAND_PRES_RET\", \"WEEK\", partition_col.upper()}\nfeature_names_upper = {c.upper() for c in feature_cols_actual}\n# Solo incluir columnas que sean: (1) claves/partici√≥n, o (2) features num√©ricas (verificar tipo tambi√©n)\ncols_to_keep = []\nfor c in inference_df.columns:\n    c_upper = c.upper()\n    if c_upper in keys_and_partition_upper:\n        cols_to_keep.append(c)\n    elif c_upper in feature_names_upper:\n        # Verificar que realmente sea num√©rica (doble verificaci√≥n)\n        col_type = col_type_dict.get(c_upper, \"\")\n        if col_type.startswith(NUMERIC_PREFIXES):\n            cols_to_keep.append(c)\n\ninference_input_df = inference_df.select(cols_to_keep)\ninference_input_df.write.mode(\"overwrite\").save_as_table(\"BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP\")\n\ntemp_table = session.table(\"BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP\")\nactual_cols = temp_table.columns\ncustomer_id_col = next((c for c in actual_cols if c.upper() == \"CUSTOMER_ID\"), \"CUSTOMER_ID\")\nbrand_col = next((c for c in actual_cols if c.upper() == \"BRAND_PRES_RET\"), \"BRAND_PRES_RET\")\nweek_col = next((c for c in actual_cols if c.upper() == \"WEEK\"), \"WEEK\")\npartition_col_actual = next((c for c in actual_cols if c.upper() == partition_col.upper()), partition_col)\n\n# Recalcular feature_cols_actual desde la temp table (asegurar que solo tenga num√©ricas, sin VARCHAR como PROD_KEY)\ntemp_schema = session.sql(\"DESCRIBE TABLE BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP\").collect()\ntemp_col_type_dict = {row[\"name\"].upper(): str(row[\"type\"]).upper() for row in temp_schema}\nfeature_cols_actual = [\n    c for c in actual_cols\n    if c.upper() not in excluded_upper\n    and (temp_col_type_dict.get(c.upper()) or \"\").startswith(NUMERIC_PREFIXES)\n]\n\n# Verificar que no haya VARCHARs en features (debug)\nnon_numeric_in_features = [\n    c for c in feature_cols_actual\n    if not (temp_col_type_dict.get(c.upper()) or \"\").startswith(NUMERIC_PREFIXES)\n]\nif non_numeric_in_features:\n    print(f\"‚ö†Ô∏è  ADVERTENCIA: Columnas no num√©ricas en features: {non_numeric_in_features}\")\n    feature_cols_actual = [c for c in feature_cols_actual if c not in non_numeric_in_features]\n\nprint(f\"‚úÖ Excluidas (no features): {list(excluded_cols)}\")\nprint(f\"‚úÖ {len(feature_cols_actual)} features num√©ricas para PREDICT, partition: {partition_col_actual}\")\nif len(feature_cols_actual) > 0:\n    print(f\"   Primeras 5 features: {feature_cols_actual[:5]}\")\n",
      "id": "41cf3f4c-4546-4c8d-84fd-c698257d9df4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 4. Execute partitioned inference\n",
      "id": "4af19d44-10bb-4738-8538-431fde3d090c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üöÄ EXECUTING PARTITIONED INFERENCE\")\nprint(\"=\"*80)\n\nstart_time = time.time()\n# Pass columns as-is; model was registered with sample_input from training (same types).\nfeature_list = \", \".join(f\"i.{col}\" for col in feature_cols_actual)\n\npredictions_sql = f\"\"\"\nWITH model_predictions AS (\n    SELECT \n        p.customer_id,\n        p.{partition_col_actual},\n        p.predicted_uni_box_week\n    FROM BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP i,\n        TABLE(\n            BD_AA_DEV.SC_MODELS_BMX.UNI_BOX_REGRESSION_PARTITIONED!PREDICT(\n                i.{customer_id_col},\n                i.{partition_col_actual},\n                {feature_list}\n            ) OVER (PARTITION BY i.{partition_col_actual})\n        ) p\n)\nSELECT \n    mp.customer_id,\n    mp.{partition_col_actual},\n    i.{week_col},\n    i.{brand_col},\n    ROUND(mp.predicted_uni_box_week, 2) AS predicted_uni_box_week\nFROM model_predictions mp\nJOIN BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP i \n    ON mp.customer_id = i.{customer_id_col}\n    AND mp.{partition_col_actual} = i.{partition_col_actual}\nORDER BY mp.{partition_col_actual}, mp.customer_id\n\"\"\"\n\npredictions_df = session.sql(predictions_sql)\nprediction_count = predictions_df.count()\ninference_time = time.time() - start_time\n\nprint(f\"‚úÖ Done in {inference_time:.2f}s ‚Äî {prediction_count:,} predictions\")\npredictions_df.show(10)\n",
      "id": "e0d1e42e-5575-4b24-a481-702606e81cae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 5. Statistics\n",
      "id": "8a708448-9f84-4cf3-a9a7-071813f5304f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "stats_sql = f\"\"\"\nWITH model_predictions AS (\n    SELECT \n        p.customer_id,\n        p.predicted_uni_box_week\n    FROM BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP i,\n        TABLE(\n            BD_AA_DEV.SC_MODELS_BMX.UNI_BOX_REGRESSION_PARTITIONED!PREDICT(\n                i.{customer_id_col},\n                i.{partition_col_actual},\n                {feature_list}\n            ) OVER (PARTITION BY i.{partition_col_actual})\n        ) p\n)\nSELECT\n    COUNT(*) AS TOTAL_PREDICTIONS,\n    COUNT(DISTINCT customer_id) AS UNIQUE_CUSTOMERS,\n    ROUND(MIN(predicted_uni_box_week), 2) AS MIN_PREDICTION,\n    ROUND(MAX(predicted_uni_box_week), 2) AS MAX_PREDICTION,\n    ROUND(AVG(predicted_uni_box_week), 2) AS AVG_PREDICTION,\n    ROUND(STDDEV(predicted_uni_box_week), 2) AS STDDEV_PREDICTION,\n    ROUND(PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY predicted_uni_box_week), 2) AS Q1,\n    ROUND(PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY predicted_uni_box_week), 2) AS MEDIAN,\n    ROUND(PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY predicted_uni_box_week), 2) AS Q3\nFROM model_predictions\n\"\"\"\n\nsession.sql(stats_sql).show()\n",
      "id": "e7d6813d-381d-49ae-8e52-85c76700a8c8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 6. Save to INFERENCE_LOGS\n",
      "id": "09a2b287-9a1e-45d4-b767-49e8e1832639"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "session.sql(\"\"\"\n    CREATE TABLE IF NOT EXISTS BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_LOGS (\n        customer_id VARCHAR,\n        week VARCHAR,\n        brand_pres_ret VARCHAR,\n        stats_ntile_group VARCHAR,\n        predicted_uni_box_week FLOAT,\n        inference_timestamp TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n        model_version VARCHAR\n    )\n\"\"\").collect()\ninsert_sql = f\"\"\"\nINSERT INTO BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_LOGS\n    (customer_id, week, brand_pres_ret, stats_ntile_group, predicted_uni_box_week, model_version)\nWITH model_predictions AS (\n    SELECT \n        p.customer_id,\n        p.{partition_col_actual},\n        p.predicted_uni_box_week\n    FROM BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP i,\n        TABLE(\n            BD_AA_DEV.SC_MODELS_BMX.UNI_BOX_REGRESSION_PARTITIONED!PREDICT(\n                i.{customer_id_col},\n                i.{partition_col_actual},\n                {feature_list}\n            ) OVER (PARTITION BY i.{partition_col_actual})\n        ) p\n)\nSELECT \n    mp.customer_id,\n    i.{week_col},\n    i.{brand_col},\n    mp.{partition_col_actual},\n    mp.predicted_uni_box_week,\n    '{model_version.version_name}'\nFROM model_predictions mp\nJOIN BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP i \n    ON mp.customer_id = i.{customer_id_col}\n    AND mp.{partition_col_actual} = i.{partition_col_actual}\n\"\"\"\n\nsession.sql(insert_sql).collect()\nlog_count = session.sql(\"SELECT COUNT(*) as CNT FROM BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_LOGS\").collect()[0]['CNT']\nprint(f\"‚úÖ Saved {log_count:,} to INFERENCE_LOGS\")\nsession.sql(\"SELECT * FROM BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_LOGS ORDER BY inference_timestamp DESC LIMIT 5\").show()\n",
      "id": "7382c4e8-8c54-4f58-b52c-44180b640068",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 7. Summary\n",
      "id": "ea8dbd08-5416-472c-8058-b4e1cc6c1f78"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(f\"\\nüéâ Done ‚Äî {prediction_count:,} predictions, {inference_time:.2f}s, model {model_version.version_name}\")\n",
      "id": "d8dee744-4c3f-4109-bf15-170f664de85b",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}