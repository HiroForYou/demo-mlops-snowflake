{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "# Migration: Partitioned Inference Batch\n\n## Overview\nThis script executes batch inference using the partitioned model with partitioned inference syntax.\n\n## What We'll Do:\n1. Load inference data from cleaned table\n2. Prepare features for inference\n3. Execute partitioned inference using TABLE(...) OVER (PARTITION BY ...) syntax\n4. Save predictions to inference logs\n5. Generate statistics\n",
      "id": "13d177d3-8578-47ab-9df2-677126ff1d65"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "from snowflake.snowpark.context import get_active_session\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml.feature_store import FeatureStore\nfrom snowflake.snowpark import functions as F\nimport pandas as pd\nimport time\n\nsession = get_active_session()\n\n# Set context\nsession.sql(\"USE DATABASE BD_AA_DEV\").collect()\nsession.sql(\"USE SCHEMA SC_STORAGE_BMX_PS\").collect()\n\nregistry = Registry(\n    session=session,\n    database_name=\"BD_AA_DEV\",\n    schema_name=\"SC_MODELS_BMX\"\n)\n\nprint(\"‚úÖ Connected to Snowflake\")\nprint(f\"   Database: {session.get_current_database()}\")\nprint(f\"   Schema: {session.get_current_schema()}\")\n",
      "id": "a215aae9-81bd-47ca-aa6d-0a55a60f3202",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 1. Verify Partitioned Model\n",
      "id": "1f713c69-daa0-4e6d-87fe-88e32f1749ae"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üîç VERIFYING PARTITIONED MODEL\")\nprint(\"=\"*80)\n\nmodel_ref = registry.get_model(\"UNI_BOX_REGRESSION_PARTITIONED\")\nmodel_version = model_ref.version(\"PRODUCTION\")\n\nprint(\"‚úÖ Model: UNI_BOX_REGRESSION_PARTITIONED\")\nprint(f\"   Version: {model_version.version_name}\")\nprint(f\"   Alias: PRODUCTION\")\n\n# Show model functions\nfunctions = session.sql(\"\"\"\n    SHOW FUNCTIONS IN MODEL BD_AA_DEV.SC_MODELS_BMX.UNI_BOX_REGRESSION_PARTITIONED\n\"\"\").collect()\n\nprint(f\"\\nüìã Available functions:\")\nfor f in functions:\n    print(f\"   - {f['name']}\")\n",
      "id": "7183d96a-0a36-4326-a0e4-fa42b891e33a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 2. Load Inference Data from Feature Store\n",
      "id": "ccecb2e8-0e28-4acd-85b6-912df45e4134"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üè™ LOADING FEATURES FROM FEATURE STORE\")\nprint(\"=\"*80)\n\n# Initialize Feature Store\nfs = FeatureStore(\n    session=session,\n    database=\"BD_AA_DEV\",\n    name=\"SC_FEATURES_BMX\"\n)\n\nprint(\"‚úÖ Feature Store initialized\")\n\n# Get FeatureView\ntry:\n    feature_view = fs.get_feature_view(\"UNI_BOX_FEATURES\", version=\"v1\")\n    print(\"‚úÖ FeatureView 'UNI_BOX_FEATURES' v1 loaded\")\nexcept Exception as e:\n    # Try v2 if v1 doesn't exist\n    try:\n        feature_view = fs.get_feature_view(\"UNI_BOX_FEATURES\", version=\"v2\")\n        print(\"‚úÖ FeatureView 'UNI_BOX_FEATURES' v2 loaded\")\n    except:\n        print(f\"‚ùå Error loading FeatureView: {str(e)}\")\n        print(\"   Please run 02_feature_store_setup.py first\")\n        raise\n\n# Get inference entity keys (customer_id, brand_pres_ret, week) and stats_ntile_group from inference table\n# This will be our \"spine\" - the entities we want features for\nprint(\"\\n‚è≥ Loading inference entity keys (spine) with stats_ntile_group...\")\ninference_spine = session.table(\"BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_DATASET_CLEANED\").select(\n    \"customer_id\", \"brand_pres_ret\", \"week\", \"stats_ntile_group\"\n).distinct()\n\nprint(f\"   Unique inference keys: {inference_spine.count():,}\")\n\n# Verify stats_ntile_group exists\nif \"stats_ntile_group\" not in inference_spine.columns:\n    raise ValueError(\"stats_ntile_group column not found in inference dataset! This is required for partitioned inference.\")\n\n# Check group distribution\nprint(\"\\nüìä Inference records per group:\")\ngroup_dist = inference_spine.group_by(\"stats_ntile_group\").count().sort(\"stats_ntile_group\")\ngroup_dist.show()\n\n# Materialize all features from FeatureView\nprint(\"‚è≥ Materializing features from Feature Store...\")\nall_features_df = feature_view.get_features()\n\n# Join spine with features to get only features for inference entities\nprint(\"‚è≥ Joining spine with features...\")\ninference_df = inference_spine.join(\n    all_features_df,\n    on=[\"customer_id\", \"brand_pres_ret\", \"week\"],\n    how=\"inner\"\n)\n\nprint(f\"\\n‚úÖ Inference features loaded from Feature Store\")\nprint(f\"   Total records: {inference_df.count():,}\")\nprint(f\"   Unique customers: {inference_df.select('customer_id').distinct().count():,}\")\n\n# Show sample\nprint(\"\\nüìã Sample inference features:\")\ninference_df.select(\n    'customer_id', 'week', 'brand_pres_ret', 'stats_ntile_group',\n    'sum_past_12_weeks', 'week_of_year'\n).show(5)\n",
      "id": "8c49751a-4757-4172-9943-f52545fb60d7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 3. Prepare Inference Input\n",
      "id": "03041bf8-5719-4450-a85a-0294221b81e0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üîß PREPARING INFERENCE INPUT\")\nprint(\"=\"*80)\n\n# Define excluded columns (metadata columns from Feature Store)\nexcluded_cols = [\n    'customer_id', 'brand_pres_ret', 'week', \n    'FEATURE_TIMESTAMP'  # Feature Store timestamp column\n]\n\n# Get feature columns (same as training)\ninference_columns = inference_df.columns\nfeature_cols = [col for col in inference_columns \n                if col not in excluded_cols]\n\nprint(f\"\\nüìã Features for inference ({len(feature_cols)}):\")\nfor col in sorted(feature_cols):\n    print(f\"   - {col}\")\n\n# Use stats_ntile_group as partition column (no dummy needed!)\n# Save to temporary table for inference\ninference_input = inference_df\n\ninference_input.write.mode('overwrite').save_as_table(\n    'BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP'\n)\n\nprint(f\"\\n‚úÖ Inference input prepared and saved to temporary table\")\nprint(f\"   Records: {inference_input.count():,}\")\nprint(f\"   Partition column: stats_ntile_group\")\n",
      "id": "9d2ca956-37fe-4f7f-910b-761124130f7e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 4. Execute Partitioned Inference\n",
      "id": "adfd43f8-1f2c-4fd8-a327-5acaffa880a2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üöÄ EXECUTING PARTITIONED INFERENCE\")\nprint(\"=\"*80)\n\nprint(\"\\nüìù Running partitioned inference...\")\nprint(\"   Syntax: TABLE(model!PREDICT(...) OVER (PARTITION BY stats_ntile_group))\")\nprint(\"   This routes each group to its specific trained model automatically\\n\")\n\nstart_time = time.time()\n\n# Build feature list for PREDICT function\n# We need to pass features in the same order as training\nfeature_list = \", \".join([f\"i.{col}\" for col in feature_cols])\n\npredictions_sql = f\"\"\"\nWITH model_predictions AS (\n    SELECT \n        p.customer_id,\n        p.stats_ntile_group,\n        p.predicted_uni_box_week\n    FROM BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP i,\n        TABLE(\n            BD_AA_DEV.SC_MODELS_BMX.UNI_BOX_REGRESSION_PARTITIONED!PREDICT(\n                i.customer_id,\n                {feature_list}\n            ) OVER (PARTITION BY i.stats_ntile_group)\n        ) p\n)\nSELECT \n    mp.customer_id,\n    mp.stats_ntile_group,\n    i.week,\n    i.brand_pres_ret,\n    ROUND(mp.predicted_uni_box_week, 2) AS predicted_uni_box_week\nFROM model_predictions mp\nJOIN BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP i \n    ON mp.customer_id = i.customer_id \n    AND mp.stats_ntile_group = i.stats_ntile_group\nORDER BY mp.stats_ntile_group, mp.customer_id\n\"\"\"\n\npredictions_df = session.sql(predictions_sql)\nprediction_count = predictions_df.count()\ninference_time = time.time() - start_time\n\nprint(f\"‚úÖ Inference complete!\")\nprint(f\"   ‚è±Ô∏è  Time: {inference_time:.2f} seconds\")\nprint(f\"   üìä Predictions: {prediction_count:,}\")\n\nprint(\"\\nüìä Sample Predictions:\")\npredictions_df.show(10)\n",
      "id": "0a70a05b-5096-40ac-b894-e35887325735",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 5. Analyze Prediction Statistics\n",
      "id": "d47f100e-b810-4ec4-b5bf-b20f9f7403d9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üìà PREDICTION STATISTICS\")\nprint(\"=\"*80)\n\nstats_sql = \"\"\"\nWITH model_predictions AS (\n    SELECT \n        p.customer_id,\n        p.predicted_uni_box_week\n    FROM BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP i,\n        TABLE(\n            BD_AA_DEV.SC_MODELS_BMX.UNI_BOX_REGRESSION_PARTITIONED!PREDICT(\n                i.customer_id,\n                i.sum_past_12_weeks,\n                i.avg_past_12_weeks,\n                i.max_past_24_weeks,\n                i.sum_past_24_weeks,\n                i.week_of_year,\n                i.avg_avg_daily_all_hours,\n                i.sum_p4w,\n                i.avg_past_24_weeks,\n                i.pharm_super_conv,\n                i.wines_liquor,\n                i.groceries,\n                i.max_prev2,\n                i.avg_prev2,\n                i.max_prev3,\n                i.avg_prev3,\n                i.w_m1_total,\n                i.w_m2_total,\n                i.w_m3_total,\n                i.w_m4_total,\n                i.spec_foods,\n                i.prod_key,\n                i.num_coolers,\n                i.num_doors,\n                i.max_past_4_weeks,\n                i.sum_past_4_weeks,\n                i.avg_past_4_weeks,\n                i.max_past_12_weeks\n            ) OVER (PARTITION BY i.stats_ntile_group)\n        ) p\n)\nSELECT\n    COUNT(*) AS TOTAL_PREDICTIONS,\n    COUNT(DISTINCT customer_id) AS UNIQUE_CUSTOMERS,\n    ROUND(MIN(predicted_uni_box_week), 2) AS MIN_PREDICTION,\n    ROUND(MAX(predicted_uni_box_week), 2) AS MAX_PREDICTION,\n    ROUND(AVG(predicted_uni_box_week), 2) AS AVG_PREDICTION,\n    ROUND(STDDEV(predicted_uni_box_week), 2) AS STDDEV_PREDICTION,\n    ROUND(PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY predicted_uni_box_week), 2) AS Q1,\n    ROUND(PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY predicted_uni_box_week), 2) AS MEDIAN,\n    ROUND(PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY predicted_uni_box_week), 2) AS Q3\nFROM model_predictions\n\"\"\"\n\nprint(\"\\nüìä Overall Statistics:\")\nsession.sql(stats_sql).show()\n",
      "id": "18832a81-3ff6-4528-91a2-7163eb308ed5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 6. Save Predictions to Inference Logs\n",
      "id": "013c8705-5dd5-435e-940b-d69b277025f5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üíæ SAVING PREDICTIONS TO INFERENCE LOGS\")\nprint(\"=\"*80)\n\n# Create inference logs table\nsession.sql(\"\"\"\n    CREATE TABLE IF NOT EXISTS BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_LOGS (\n        customer_id VARCHAR,\n        week VARCHAR,\n        brand_pres_ret VARCHAR,\n        stats_ntile_group VARCHAR,\n        predicted_uni_box_week FLOAT,\n        inference_timestamp TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n        model_version VARCHAR\n    )\n\"\"\").collect()\n\n# Clear previous logs (optional - for demo purposes)\n# session.sql(\"DELETE FROM BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_LOGS\").collect()\n\n# Insert predictions\ninsert_sql = f\"\"\"\nINSERT INTO BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_LOGS\n    (customer_id, week, brand_pres_ret, stats_ntile_group, predicted_uni_box_week, model_version)\nWITH model_predictions AS (\n    SELECT \n        p.customer_id,\n        p.stats_ntile_group,\n        p.predicted_uni_box_week\n    FROM BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP i,\n        TABLE(\n            BD_AA_DEV.SC_MODELS_BMX.UNI_BOX_REGRESSION_PARTITIONED!PREDICT(\n                i.customer_id,\n                {feature_list}\n            ) OVER (PARTITION BY i.stats_ntile_group)\n        ) p\n)\nSELECT \n    mp.customer_id,\n    i.week,\n    i.brand_pres_ret,\n    mp.stats_ntile_group,\n    mp.predicted_uni_box_week,\n    '{model_version.version_name}'\nFROM model_predictions mp\nJOIN BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP i \n    ON mp.customer_id = i.customer_id \n    AND mp.stats_ntile_group = i.stats_ntile_group\n\"\"\"\n\nsession.sql(insert_sql).collect()\n\nlog_count = session.sql(\"SELECT COUNT(*) as CNT FROM BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_LOGS\").collect()[0]['CNT']\nprint(f\"‚úÖ Saved {log_count:,} predictions to INFERENCE_LOGS\")\n\nprint(\"\\nüìã Sample from logs:\")\nsession.sql(\"\"\"\n    SELECT * FROM BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_LOGS \n    ORDER BY inference_timestamp DESC\n    LIMIT 5\n\"\"\").show()\n",
      "id": "46506d33-572f-4806-aad4-b621029c3d47",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 7. Summary\n",
      "id": "4908350b-4ddd-40d3-ac25-5ae2697e83a9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üéâ PARTITIONED INFERENCE BATCH COMPLETE!\")\nprint(\"=\"*80)\n\nprint(f\"\"\"\nüìä Summary:\n   ‚úÖ Predictions generated: {prediction_count:,}\n   ‚úÖ Inference time: {inference_time:.2f} seconds\n   ‚úÖ Logs saved to: INFERENCE_LOGS\n   ‚úÖ Model version: {model_version.version_name}\n\nüí° Key Advantages of Partitioned Model:\n   ‚úÖ 16 group-specific models combined into one\n   ‚úÖ Automatic routing by stats_ntile_group\n   ‚úÖ Each group uses optimized hyperparameters\n   ‚úÖ SQL-native inference (no Python required)\n   ‚úÖ Parallel execution handled by Snowflake\n\nüéØ Business Impact:\n   ‚Ä¢ Batch predictions for all inference records\n   ‚Ä¢ Predictions stored for monitoring and analysis\n   ‚Ä¢ Ready for production deployment\n   ‚Ä¢ Scalable to multiple models if needed\n\nüöÄ Next Steps:\n   ‚Üí Review predictions in INFERENCE_LOGS table\n   ‚Üí Set up monitoring and observability\n   ‚Üí Schedule regular batch inference runs\n\"\"\")\n\nprint(\"=\"*80)\n",
      "id": "a35dbb7a-a3ab-453b-81f1-ced4bce98aea",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}