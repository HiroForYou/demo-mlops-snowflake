{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "# Migration: Partitioned Inference Batch\n\n## Overview\nThis script executes batch inference using the partitioned model with partitioned inference syntax.\n\n## What We'll Do:\n1. Load inference data from cleaned table\n2. Prepare features for inference\n3. Execute partitioned inference using TABLE(...) OVER (PARTITION BY ...) syntax\n4. Save predictions to inference logs\n5. Generate statistics\n",
      "id": "5ed1f2e8-6267-4b47-9a2d-aba37b82eff1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "from snowflake.snowpark.context import get_active_session\nfrom snowflake.ml.registry import Registry\nfrom snowflake.snowpark import functions as F\nimport pandas as pd\nimport time\n\nsession = get_active_session()\n\n# Set context\nsession.sql(\"USE DATABASE BD_AA_DEV\").collect()\nsession.sql(\"USE SCHEMA SC_STORAGE_BMX_PS\").collect()\n\nregistry = Registry(\n    session=session,\n    database_name=\"BD_AA_DEV\",\n    schema_name=\"MODEL_REGISTRY\"\n)\n\nprint(\"‚úÖ Connected to Snowflake\")\nprint(f\"   Database: {session.get_current_database()}\")\nprint(f\"   Schema: {session.get_current_schema()}\")\n",
      "id": "395fcf2d-45c6-4e23-801d-436afa9f03dc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 1. Verify Partitioned Model\n",
      "id": "f881226c-5866-4f02-946a-07962c5cd931"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üîç VERIFYING PARTITIONED MODEL\")\nprint(\"=\"*80)\n\nmodel_ref = registry.get_model(\"UNI_BOX_REGRESSION_PARTITIONED\")\nmodel_version = model_ref.version(\"PRODUCTION\")\n\nprint(\"‚úÖ Model: UNI_BOX_REGRESSION_PARTITIONED\")\nprint(f\"   Version: {model_version.version_name}\")\nprint(f\"   Alias: PRODUCTION\")\n\n# Show model functions\nfunctions = session.sql(\"\"\"\n    SHOW FUNCTIONS IN MODEL BD_AA_DEV.MODEL_REGISTRY.UNI_BOX_REGRESSION_PARTITIONED\n\"\"\").collect()\n\nprint(f\"\\nüìã Available functions:\")\nfor f in functions:\n    print(f\"   - {f['name']}\")\n",
      "id": "8f32f587-3365-46a9-bd02-38dd12ca209b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 2. Load Inference Data\n",
      "id": "9d00cecd-8409-4c69-a572-eea09144393c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üìä LOADING INFERENCE DATA\")\nprint(\"=\"*80)\n\n# Load cleaned inference data\ninference_df = session.table(\"BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_DATASET_CLEANED\")\n\nprint(f\"\\n‚úÖ Inference data loaded\")\nprint(f\"   Total records: {inference_df.count():,}\")\nprint(f\"   Unique customers: {inference_df.select('customer_id').distinct().count():,}\")\n\n# Show sample\nprint(\"\\nüìã Sample inference data:\")\ninference_df.select(\n    'customer_id', 'week', 'brand_pres_ret', \n    'sum_past_12_weeks', 'week_of_year'\n).show(5)\n",
      "id": "e7c66bb5-5cee-4e16-b765-bddf00bf0d8f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 3. Prepare Inference Input\n",
      "id": "a25bbd18-6430-4664-a2b3-0812abfa8686"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üîß PREPARING INFERENCE INPUT\")\nprint(\"=\"*80)\n\n# Define excluded columns\nexcluded_cols = [\n    'customer_id', 'brand_pres_ret', 'week', \n    'group', 'stats_group', 'percentile_group', 'stats_ntile_group'\n]\n\n# Get feature columns (same as training)\ninference_columns = inference_df.columns\nfeature_cols = [col for col in inference_columns \n                if col not in excluded_cols]\n\nprint(f\"\\nüìã Features for inference ({len(feature_cols)}):\")\nfor col in sorted(feature_cols):\n    print(f\"   - {col}\")\n\n# Create a dummy partition column for partitioned inference\n# Since we have a single model, we can use a constant partition\ninference_input = inference_df.with_column(\"dummy_partition\", F.lit(\"ALL\"))\n\n# Save to temporary table for inference\ninference_input.write.mode('overwrite').save_as_table(\n    'BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP'\n)\n\nprint(f\"\\n‚úÖ Inference input prepared and saved to temporary table\")\nprint(f\"   Records: {inference_input.count():,}\")\n",
      "id": "aa94a8a6-f020-4994-951f-7b19f830c14b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 4. Execute Partitioned Inference\n",
      "id": "659b2fa4-b7ea-4de2-a02d-0407c07081b1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üöÄ EXECUTING PARTITIONED INFERENCE\")\nprint(\"=\"*80)\n\nprint(\"\\nüìù Running partitioned inference...\")\nprint(\"   Syntax: TABLE(model!PREDICT(...) OVER (PARTITION BY dummy_partition))\")\nprint(\"   This enables partitioned inference even with a single model\\n\")\n\nstart_time = time.time()\n\n# Build feature list for PREDICT function\n# We need to pass features in the same order as training\nfeature_list = \", \".join([f\"i.{col}\" for col in feature_cols])\n\npredictions_sql = f\"\"\"\nWITH model_predictions AS (\n    SELECT \n        p.customer_id,\n        p.predicted_uni_box_week\n    FROM BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP i,\n        TABLE(\n            BD_AA_DEV.MODEL_REGISTRY.UNI_BOX_REGRESSION_PARTITIONED!PREDICT(\n                i.customer_id,\n                {feature_list}\n            ) OVER (PARTITION BY i.dummy_partition)\n        ) p\n)\nSELECT \n    mp.customer_id,\n    i.week,\n    i.brand_pres_ret,\n    ROUND(mp.predicted_uni_box_week, 2) AS predicted_uni_box_week\nFROM model_predictions mp\nJOIN BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP i \n    ON mp.customer_id = i.customer_id\nORDER BY mp.customer_id\n\"\"\"\n\npredictions_df = session.sql(predictions_sql)\nprediction_count = predictions_df.count()\ninference_time = time.time() - start_time\n\nprint(f\"‚úÖ Inference complete!\")\nprint(f\"   ‚è±Ô∏è  Time: {inference_time:.2f} seconds\")\nprint(f\"   üìä Predictions: {prediction_count:,}\")\n\nprint(\"\\nüìä Sample Predictions:\")\npredictions_df.show(10)\n",
      "id": "b6a9b571-2e47-469f-a7c2-e1bca1d49c89",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 5. Analyze Prediction Statistics\n",
      "id": "0e27911f-2ab4-409d-8b35-1021bdc9839b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üìà PREDICTION STATISTICS\")\nprint(\"=\"*80)\n\nstats_sql = \"\"\"\nWITH model_predictions AS (\n    SELECT \n        p.customer_id,\n        p.predicted_uni_box_week\n    FROM BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP i,\n        TABLE(\n            BD_AA_DEV.MODEL_REGISTRY.UNI_BOX_REGRESSION_PARTITIONED!PREDICT(\n                i.customer_id,\n                i.sum_past_12_weeks,\n                i.avg_past_12_weeks,\n                i.max_past_24_weeks,\n                i.sum_past_24_weeks,\n                i.week_of_year,\n                i.avg_avg_daily_all_hours,\n                i.sum_p4w,\n                i.avg_past_24_weeks,\n                i.pharm_super_conv,\n                i.wines_liquor,\n                i.groceries,\n                i.max_prev2,\n                i.avg_prev2,\n                i.max_prev3,\n                i.avg_prev3,\n                i.w_m1_total,\n                i.w_m2_total,\n                i.w_m3_total,\n                i.w_m4_total,\n                i.spec_foods,\n                i.prod_key,\n                i.num_coolers,\n                i.num_doors,\n                i.max_past_4_weeks,\n                i.sum_past_4_weeks,\n                i.avg_past_4_weeks,\n                i.max_past_12_weeks\n            ) OVER (PARTITION BY i.dummy_partition)\n        ) p\n)\nSELECT\n    COUNT(*) AS TOTAL_PREDICTIONS,\n    COUNT(DISTINCT customer_id) AS UNIQUE_CUSTOMERS,\n    ROUND(MIN(predicted_uni_box_week), 2) AS MIN_PREDICTION,\n    ROUND(MAX(predicted_uni_box_week), 2) AS MAX_PREDICTION,\n    ROUND(AVG(predicted_uni_box_week), 2) AS AVG_PREDICTION,\n    ROUND(STDDEV(predicted_uni_box_week), 2) AS STDDEV_PREDICTION,\n    ROUND(PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY predicted_uni_box_week), 2) AS Q1,\n    ROUND(PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY predicted_uni_box_week), 2) AS MEDIAN,\n    ROUND(PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY predicted_uni_box_week), 2) AS Q3\nFROM model_predictions\n\"\"\"\n\nprint(\"\\nüìä Overall Statistics:\")\nsession.sql(stats_sql).show()\n",
      "id": "1136fb66-c93f-4589-b622-3cea697fdd6e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 6. Save Predictions to Inference Logs\n",
      "id": "8ec89786-1ae6-4af3-b979-07203e3eaf12"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üíæ SAVING PREDICTIONS TO INFERENCE LOGS\")\nprint(\"=\"*80)\n\n# Create inference logs table\nsession.sql(\"\"\"\n    CREATE TABLE IF NOT EXISTS BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_LOGS (\n        customer_id VARCHAR,\n        week VARCHAR,\n        brand_pres_ret VARCHAR,\n        predicted_uni_box_week FLOAT,\n        inference_timestamp TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n        model_version VARCHAR\n    )\n\"\"\").collect()\n\n# Clear previous logs (optional - for demo purposes)\n# session.sql(\"DELETE FROM BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_LOGS\").collect()\n\n# Insert predictions\ninsert_sql = f\"\"\"\nINSERT INTO BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_LOGS\n    (customer_id, week, brand_pres_ret, predicted_uni_box_week, model_version)\nWITH model_predictions AS (\n    SELECT \n        p.customer_id,\n        p.predicted_uni_box_week\n    FROM BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP i,\n        TABLE(\n            BD_AA_DEV.MODEL_REGISTRY.UNI_BOX_REGRESSION_PARTITIONED!PREDICT(\n                i.customer_id,\n                {feature_list}\n            ) OVER (PARTITION BY i.dummy_partition)\n        ) p\n)\nSELECT \n    mp.customer_id,\n    i.week,\n    i.brand_pres_ret,\n    mp.predicted_uni_box_week,\n    '{model_version.version_name}'\nFROM model_predictions mp\nJOIN BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP i \n    ON mp.customer_id = i.customer_id\n\"\"\"\n\nsession.sql(insert_sql).collect()\n\nlog_count = session.sql(\"SELECT COUNT(*) as CNT FROM BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_LOGS\").collect()[0]['CNT']\nprint(f\"‚úÖ Saved {log_count:,} predictions to INFERENCE_LOGS\")\n\nprint(\"\\nüìã Sample from logs:\")\nsession.sql(\"\"\"\n    SELECT * FROM BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_LOGS \n    ORDER BY inference_timestamp DESC\n    LIMIT 5\n\"\"\").show()\n",
      "id": "ffae25a3-816e-442e-a749-2d47be862089",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 7. Summary\n",
      "id": "b8ac2914-836e-4ae3-b0f8-da06ab36e6a0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üéâ PARTITIONED INFERENCE BATCH COMPLETE!\")\nprint(\"=\"*80)\n\nprint(f\"\"\"\nüìä Summary:\n   ‚úÖ Predictions generated: {prediction_count:,}\n   ‚úÖ Inference time: {inference_time:.2f} seconds\n   ‚úÖ Logs saved to: INFERENCE_LOGS\n   ‚úÖ Model version: {model_version.version_name}\n\nüí° Key Advantages of Partitioned Model:\n   ‚úÖ Single model with partitioned API\n   ‚úÖ Consistent inference syntax\n   ‚úÖ Ready for future multi-model scenarios\n   ‚úÖ SQL-native inference (no Python required)\n   ‚úÖ Parallel execution handled by Snowflake\n\nüéØ Business Impact:\n   ‚Ä¢ Batch predictions for all inference records\n   ‚Ä¢ Predictions stored for monitoring and analysis\n   ‚Ä¢ Ready for production deployment\n   ‚Ä¢ Scalable to multiple models if needed\n\nüöÄ Next Steps:\n   ‚Üí Review predictions in INFERENCE_LOGS table\n   ‚Üí Set up monitoring and observability\n   ‚Üí Schedule regular batch inference runs\n\"\"\")\n\nprint(\"=\"*80)\n",
      "id": "3555324c-afe4-4dec-9308-fa4aaabf8dae",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}