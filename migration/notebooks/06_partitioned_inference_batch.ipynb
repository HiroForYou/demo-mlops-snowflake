{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "# Partitioned Inference Batch\nLoad inference data, run TABLE(model!PREDICT(...) OVER (PARTITION BY stats_ntile_group)), save to INFERENCE_LOGS.\n",
      "id": "3c0a7d92-ead0-452c-affd-45a3db61ec23"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "from snowflake.snowpark.context import get_active_session\nfrom snowflake.ml.registry import Registry\nimport time\n\nsession = get_active_session()\nsession.sql(\"USE DATABASE BD_AA_DEV\").collect()\nsession.sql(\"USE SCHEMA SC_STORAGE_BMX_PS\").collect()\n\nregistry = Registry(\n    session=session,\n    database_name=\"BD_AA_DEV\",\n    schema_name=\"SC_MODELS_BMX\"\n)\n\nINFERENCE_SAMPLE_FRACTION = 0.01\n\nprint(\"‚úÖ Connected to Snowflake\")\nprint(f\"   Database: {session.get_current_database()}\")\nprint(f\"   Schema: {session.get_current_schema()}\")\nif INFERENCE_SAMPLE_FRACTION:\n    print(f\"   ‚ö†Ô∏è  Sampling: {INFERENCE_SAMPLE_FRACTION*100:.1f}% del dataset de inferencia\")\n",
      "id": "2652cfdb-aaf3-45b6-b76c-4391d56341b2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 1. Verify model\n",
      "id": "a8ef6837-3111-468c-af1a-054e8f02cac8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üîç VERIFYING PARTITIONED MODEL\")\nprint(\"=\"*80)\n\nmodel_ref = registry.get_model(\"UNI_BOX_REGRESSION_PARTITIONED\")\nmodel_version = model_ref.version(\"PRODUCTION\")\nprint(f\"‚úÖ UNI_BOX_REGRESSION_PARTITIONED @ {model_version.version_name} (PRODUCTION)\")\n",
      "id": "804dc0c3-ce01-491c-956d-7e04e29b0622",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 2. Load inference data (directamente desde INFERENCE_DATASET_CLEANED)\nNo se usa Feature Store: inferencia consume la tabla cleaned con las mismas columnas que valid√≥ 01 (compatibles con training).\n",
      "id": "a8fb4287-5b56-4433-bb73-fee2741dc66c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üìã LOADING INFERENCE DATA (INFERENCE_DATASET_CLEANED)\")\nprint(\"=\"*80)\n\ninference_df = session.table(\"BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_DATASET_CLEANED\")\n\npartition_col = next((c for c in inference_df.columns if c.upper() == \"STATS_NTILE_GROUP\"), None)\nif partition_col is None:\n    raise ValueError(\"stats_ntile_group not found in inference dataset.\")\n\nif INFERENCE_SAMPLE_FRACTION and 0 < INFERENCE_SAMPLE_FRACTION < 1:\n    inference_df = inference_df.sample(frac=INFERENCE_SAMPLE_FRACTION)\n\nn_records = inference_df.count()\nprint(f\"   Inference records: {n_records:,}\")\ninference_df.group_by(partition_col).count().sort(partition_col).show()\n\nprint(f\"‚úÖ Loaded {n_records:,} records from INFERENCE_DATASET_CLEANED (sin Feature Store)\")\ninference_df.select(\"customer_id\", \"week\", \"brand_pres_ret\", partition_col, \"sum_past_12_weeks\", \"week_of_year\").show(5)\n",
      "id": "efcfabca-dc33-449b-b868-35336362d921",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 3. Prepare inference input (misma exclusi√≥n que 02/04: solo features num√©ricas, sin metadata)\n",
      "id": "8184c831-a5a4-4152-b999-3ce8b0f88459"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üîß PREPARING INFERENCE INPUT\")\nprint(\"=\"*80)\n\n# Misma lista de exclusi√≥n que script 02 (Feature Store) y 04: no son features para el modelo\nexcluded_cols = [\n    \"customer_id\",\n    \"brand_pres_ret\",\n    \"week\",\n    \"group\",\n    \"stats_group\",\n    \"percentile_group\",\n    \"stats_ntile_group\",\n    \"FEATURE_TIMESTAMP\",\n]\nexcluded_upper = {c.upper() for c in excluded_cols}\n\n# Obtener esquema de la tabla de inferencia para identificar solo columnas de features (num√©ricas, no excluidas)\ninference_schema = session.sql(\n    \"DESCRIBE TABLE BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_DATASET_CLEANED\"\n).collect()\ncol_type_dict = {row[\"name\"].upper(): str(row[\"type\"]).upper() for row in inference_schema}\nall_cols = [row[\"name\"] for row in inference_schema]\n\nNUMERIC_PREFIXES = (\"FLOAT\", \"NUMBER\", \"INTEGER\", \"BIGINT\", \"DOUBLE\")\nfeature_cols_actual = [\n    c for c in all_cols\n    if c.upper() not in excluded_upper\n    and (col_type_dict.get(c.upper()) or \"\").startswith(NUMERIC_PREFIXES)\n]\n\n# Crear INFERENCE_INPUT_TEMP solo con columnas necesarias: claves + partition + features (lo que espera PREDICT)\n# Excluir group, stats_group, percentile_group y cualquier no-feature (VARCHAR como PROD_KEY) para que PREDICT reciba la firma correcta\nkeys_and_partition_upper = {\"CUSTOMER_ID\", \"BRAND_PRES_RET\", \"WEEK\", partition_col.upper()}\nfeature_names_upper = {c.upper() for c in feature_cols_actual}\n# Solo incluir columnas que sean: (1) claves/partici√≥n, o (2) features num√©ricas (verificar tipo tambi√©n)\ncols_to_keep = []\nfor c in inference_df.columns:\n    c_upper = c.upper()\n    if c_upper in keys_and_partition_upper:\n        cols_to_keep.append(c)\n    elif c_upper in feature_names_upper:\n        # Verificar que realmente sea num√©rica (doble verificaci√≥n)\n        col_type = col_type_dict.get(c_upper, \"\")\n        if col_type.startswith(NUMERIC_PREFIXES):\n            cols_to_keep.append(c)\n\nINFERENCE_INPUT_TEMP = \"BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP\"\n\n# Materializar temp con casts expl√≠citos en columnas de contexto para calzar con la firma del modelo (VARCHAR).\n# (Si WEEK llega como VARCHAR en inferencia pero el modelo espera NUMBER, PREDICT falla por tipos.)\ncols_upper = {c.upper(): c for c in cols_to_keep}\ncust_c = cols_upper.get(\"CUSTOMER_ID\", \"CUSTOMER_ID\")\nweek_c = cols_upper.get(\"WEEK\", \"WEEK\")\nbrand_c = cols_upper.get(\"BRAND_PRES_RET\", \"BRAND_PRES_RET\")\npart_c = cols_upper.get(partition_col.upper(), partition_col)\n\ndef _q(ident: str) -> str:\n    # Quote simple para identifiers (mantener compatibilidad con may√∫sculas/min√∫sculas y caracteres especiales)\n    return f'\"{ident}\"'\n\nselect_exprs = [\n    f\"CAST({_q(cust_c)} AS VARCHAR) AS CUSTOMER_ID\",\n    f\"CAST({_q(part_c)} AS VARCHAR) AS {partition_col.upper()}\",\n    f\"CAST({_q(week_c)} AS VARCHAR) AS WEEK\",\n    f\"CAST({_q(brand_c)} AS VARCHAR) AS BRAND_PRES_RET\",\n]\n\n# Features num√©ricas (sin casts; deben permanecer num√©ricas)\nfor c in feature_cols_actual:\n    # usar el nombre real seg√∫n cols_to_keep (si aplica)\n    real_c = next((x for x in cols_to_keep if x.upper() == c.upper()), c)\n    select_exprs.append(f\"{_q(real_c)} AS {_q(real_c)}\")\n\nsession.sql(\n    f\"CREATE OR REPLACE TABLE {INFERENCE_INPUT_TEMP} AS SELECT\\n  \"\n    + \",\\n  \".join(select_exprs)\n    + \"\\nFROM BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_DATASET_CLEANED\"\n).collect()\n\ntemp_table = session.table(\"BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP\")\nactual_cols = temp_table.columns\ncustomer_id_col = next((c for c in actual_cols if c.upper() == \"CUSTOMER_ID\"), \"CUSTOMER_ID\")\nbrand_col = next((c for c in actual_cols if c.upper() == \"BRAND_PRES_RET\"), \"BRAND_PRES_RET\")\nweek_col = next((c for c in actual_cols if c.upper() == \"WEEK\"), \"WEEK\")\npartition_col_actual = next((c for c in actual_cols if c.upper() == partition_col.upper()), partition_col)\n\n# Recalcular feature_cols_actual desde la temp table (asegurar que solo tenga num√©ricas, sin VARCHAR como PROD_KEY)\ntemp_schema = session.sql(\"DESCRIBE TABLE BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP\").collect()\ntemp_col_type_dict = {row[\"name\"].upper(): str(row[\"type\"]).upper() for row in temp_schema}\nfeature_cols_actual = [\n    c for c in actual_cols\n    if c.upper() not in excluded_upper\n    and (temp_col_type_dict.get(c.upper()) or \"\").startswith(NUMERIC_PREFIXES)\n]\n\n# Verificar que no haya VARCHARs en features (debug)\nnon_numeric_in_features = [\n    c for c in feature_cols_actual\n    if not (temp_col_type_dict.get(c.upper()) or \"\").startswith(NUMERIC_PREFIXES)\n]\nif non_numeric_in_features:\n    print(f\"‚ö†Ô∏è  ADVERTENCIA: Columnas no num√©ricas en features: {non_numeric_in_features}\")\n    feature_cols_actual = [c for c in feature_cols_actual if c not in non_numeric_in_features]\n\nprint(f\"‚úÖ Excluidas (no features): {list(excluded_cols)}\")\nprint(f\"‚úÖ {len(feature_cols_actual)} features num√©ricas para PREDICT, partition: {partition_col_actual}\")\nif len(feature_cols_actual) > 0:\n    print(f\"   Primeras 5 features: {feature_cols_actual[:5]}\")\n",
      "id": "ae9ebc07-a2f0-4d40-93bc-b78f1c34c5cd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 4. Execute partitioned inference\n",
      "id": "ecbdefbe-4c32-4ae5-9411-3fe452fc3d5b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\n\" + \"=\"*80)\nprint(\"üöÄ EXECUTING PARTITIONED INFERENCE\")\nprint(\"=\"*80)\n\nstart_time = time.time()\n# Pass columns as-is; model was registered with sample_input from training (same types).\nfeature_list = \", \".join(f\"i.{col}\" for col in feature_cols_actual)\n\npredictions_sql = f\"\"\"\nWITH model_predictions AS (\n    SELECT \n        p.{customer_id_col},\n        p.{partition_col_actual},\n        p.{week_col},\n        p.{brand_col},\n        p.predicted_uni_box_week\n    FROM BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP i,\n        TABLE(\n            BD_AA_DEV.SC_MODELS_BMX.UNI_BOX_REGRESSION_PARTITIONED!PREDICT(\n                i.{customer_id_col},\n                i.{partition_col_actual},\n                i.{week_col},\n                i.{brand_col},\n                {feature_list}\n            ) OVER (PARTITION BY i.{partition_col_actual})\n        ) p\n)\nSELECT \n    {customer_id_col} AS {customer_id_col},\n    {partition_col_actual} AS {partition_col_actual},\n    {week_col} AS {week_col},\n    {brand_col} AS {brand_col},\n    ROUND(predicted_uni_box_week, 2) AS predicted_uni_box_week\nFROM model_predictions\nORDER BY {partition_col_actual}, {customer_id_col}\n\"\"\"\n\npredictions_df = session.sql(predictions_sql)\nprediction_count = predictions_df.count()\ninference_time = time.time() - start_time\n\nprint(f\"‚úÖ Done in {inference_time:.2f}s ‚Äî {prediction_count:,} predictions\")\npredictions_df.show(10)\n",
      "id": "d8bdca06-43ae-4167-b9e3-c16982176c10",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 5. Statistics\n",
      "id": "9884360e-9bbf-4b8e-ac5f-9b31e461338d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "stats_sql = f\"\"\"\nWITH model_predictions AS (\n    SELECT \n        p.customer_id,\n        p.predicted_uni_box_week\n    FROM BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP i,\n        TABLE(\n            BD_AA_DEV.SC_MODELS_BMX.UNI_BOX_REGRESSION_PARTITIONED!PREDICT(\n                i.{customer_id_col},\n                i.{partition_col_actual},\n                i.{week_col},\n                i.{brand_col},\n                {feature_list}\n            ) OVER (PARTITION BY i.{partition_col_actual})\n        ) p\n)\nSELECT\n    COUNT(*) AS TOTAL_PREDICTIONS,\n    COUNT(DISTINCT customer_id) AS UNIQUE_CUSTOMERS,\n    ROUND(MIN(predicted_uni_box_week), 2) AS MIN_PREDICTION,\n    ROUND(MAX(predicted_uni_box_week), 2) AS MAX_PREDICTION,\n    ROUND(AVG(predicted_uni_box_week), 2) AS AVG_PREDICTION,\n    ROUND(STDDEV(predicted_uni_box_week), 2) AS STDDEV_PREDICTION,\n    ROUND(PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY predicted_uni_box_week), 2) AS Q1,\n    ROUND(PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY predicted_uni_box_week), 2) AS MEDIAN,\n    ROUND(PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY predicted_uni_box_week), 2) AS Q3\nFROM model_predictions\n\"\"\"\n\nsession.sql(stats_sql).show()\n",
      "id": "12fdce0a-6eea-4114-8367-491cbd6c0263",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 6. Save to INFERENCE_LOGS\n",
      "id": "aa87fdd3-c1a1-4a24-8631-690263e08844"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "session.sql(\"\"\"\n    CREATE TABLE IF NOT EXISTS BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_LOGS (\n        customer_id VARCHAR,\n        week VARCHAR,\n        brand_pres_ret VARCHAR,\n        stats_ntile_group VARCHAR,\n        predicted_uni_box_week FLOAT,\n        inference_timestamp TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(),\n        model_version VARCHAR\n    )\n\"\"\").collect()\ninsert_sql = f\"\"\"\nINSERT INTO BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_LOGS\n    (customer_id, week, brand_pres_ret, stats_ntile_group, predicted_uni_box_week, model_version)\nWITH model_predictions AS (\n    SELECT \n        p.customer_id,\n        p.{partition_col_actual},\n        p.predicted_uni_box_week\n    FROM BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP i,\n        TABLE(\n            BD_AA_DEV.SC_MODELS_BMX.UNI_BOX_REGRESSION_PARTITIONED!PREDICT(\n                i.{customer_id_col},\n                i.{partition_col_actual},\n                {feature_list}\n            ) OVER (PARTITION BY i.{partition_col_actual})\n        ) p\n)\nSELECT \n    mp.customer_id,\n    i.{week_col},\n    i.{brand_col},\n    mp.{partition_col_actual},\n    mp.predicted_uni_box_week,\n    '{model_version.version_name}'\nFROM model_predictions mp\nJOIN BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_INPUT_TEMP i \n    ON mp.customer_id = i.{customer_id_col}\n    AND mp.{partition_col_actual} = i.{partition_col_actual}\n\"\"\"\n\nsession.sql(insert_sql).collect()\nlog_count = session.sql(\"SELECT COUNT(*) as CNT FROM BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_LOGS\").collect()[0]['CNT']\nprint(f\"‚úÖ Saved {log_count:,} to INFERENCE_LOGS\")\nsession.sql(\"SELECT * FROM BD_AA_DEV.SC_STORAGE_BMX_PS.INFERENCE_LOGS ORDER BY inference_timestamp DESC LIMIT 5\").show()\n",
      "id": "494fcb0f-15c2-49e0-b39e-15737d77a5c3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 7. Summary\n",
      "id": "5ea44b4f-418c-45fb-aaa5-ee26080c2ea6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(f\"\\nüéâ Done ‚Äî {prediction_count:,} predictions, {inference_time:.2f}s, model {model_version.version_name}\")\n",
      "id": "c45d83bb-19cd-4fcc-aae3-bd98466f531f",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}