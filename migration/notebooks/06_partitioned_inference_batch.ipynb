{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "# Partitioned Inference ‚Äî UNI_BOX_REGRESSION_PARTITIONED\n#\nInference using **PRODUCTION** alias directly, with optional SAMPLE.\n",
      "id": "f699b45c-19b4-4d79-bec1-36d8f490e458"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "from snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark import functions as F\nfrom snowflake.ml.registry import Registry\nimport time\nimport math\n",
      "id": "89f31fbe-2f35-4229-b2f6-522c22f01c75",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Configuration\nINFERENCE_SAMPLE_FRACTION = 1\n\n# Number of rows per batch. Leave as None to disable batching.\nBATCH_SIZE = 1_000_000\n\nDATABASE = \"BD_AA_DEV\"\nSTORAGE_SCHEMA = \"SC_STORAGE_BMX_PS\"\nMODEL_SCHEMA = \"SC_MODELS_BMX\"\nPARTITIONED_MODEL_NAME = \"UNI_BOX_REGRESSION_PARTITIONED\"\nPREDICTIONS_TABLE = f\"{DATABASE}.{STORAGE_SCHEMA}.INFERENCE_PREDICTIONS\"\n\nSOURCE_TABLE = f\"{DATABASE}.{STORAGE_SCHEMA}.INFERENCE_DATASET_CLEANED\"\nMODEL_FQN = f\"{DATABASE}.{MODEL_SCHEMA}.{PARTITIONED_MODEL_NAME}\"\n",
      "id": "f0c5428d-acce-4b9a-af5f-98033b8896d5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "session = get_active_session()\nsession.sql(f\"USE DATABASE {DATABASE}\").collect()\nsession.sql(f\"USE SCHEMA {STORAGE_SCHEMA}\").collect()\n\nprint(\"‚úÖ Connected to Snowflake\")\nprint(f\"   Model: {PARTITIONED_MODEL_NAME} (PRODUCTION alias)\")\n",
      "id": "d0bc542c-f260-48d0-8141-5cdfe9cf14a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## Input sampling\n",
      "id": "8d3e21f9-e981-4b27-8cfa-3b28896fdf11"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "input_df = session.table(SOURCE_TABLE)\n\nif INFERENCE_SAMPLE_FRACTION is not None and 0 < INFERENCE_SAMPLE_FRACTION < 1:\n    input_df = input_df.sample(frac=INFERENCE_SAMPLE_FRACTION)\n    print(f\"‚ö†Ô∏è  Using SAMPLE (Snowpark): {INFERENCE_SAMPLE_FRACTION*100:.2f}%\")\nelse:\n    print(\"‚úÖ Using FULL dataset (Snowpark)\")\n",
      "id": "35d65431-d20f-4f76-a723-ad5ca76a9c17",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Create temporary view of input\ninput_df.create_or_replace_temp_view(\"INFERENCE_INPUT\")\n",
      "id": "86866fae-1a6c-48b8-acee-1333eab2ffe1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## Partitioned Inference and Save to Table (single-pass, explicit PRODUCTION alias)\n",
      "id": "72cafe3f-d2b5-4014-96c2-fd8cfe4b6f7a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Get model version information (used to tag predictions)\ntry:\n    registry = Registry(\n        session=session,\n        database_name=DATABASE,\n        schema_name=MODEL_SCHEMA,\n    )\n    model_ref = registry.get_model(PARTITIONED_MODEL_NAME)\n    model_version = model_ref.version(\"PRODUCTION\")\n    # ModelVersion may expose the version name under different attributes depending on library version\n    model_version_name = getattr(model_version, \"version\", getattr(model_version, \"version_name\", str(model_version)))\n    print(f\"‚úÖ Using model version: {model_version_name}\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è  Could not get model version: {str(e)[:200]}\")\n    model_version_name = \"UNKNOWN\"\n\n# Create predictions table with SQL (including auto-incremental primary key)\ncreate_predictions_table_sql = f\"\"\"\nCREATE TABLE IF NOT EXISTS {PREDICTIONS_TABLE} (\n    PREDICTION_ID NUMBER(38,0) AUTOINCREMENT PRIMARY KEY,\n    CUSTOMER_ID VARCHAR,\n    STATS_NTILE_GROUP VARCHAR,\n    WEEK VARCHAR,\n    BRAND_PRES_RET VARCHAR,\n    PROD_KEY VARCHAR,\n    PREDICTED_UNI_BOX_WEEK FLOAT,\n    MODEL_VERSION VARCHAR,\n    PREDICTION_TIMESTAMP TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()\n)\n\"\"\"\n\nsession.sql(create_predictions_table_sql).collect()\nprint(f\"‚úÖ Predictions table ready: {PREDICTIONS_TABLE} (with auto-incremental PRIMARY KEY)\")\n",
      "id": "d5a065cd-304c-4310-8b76-857066858660",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Truncate predictions table before running inference\nsession.sql(f\"TRUNCATE TABLE {PREDICTIONS_TABLE}\").collect()\nprint(f\"üßπ Predictions table truncated: {PREDICTIONS_TABLE}\")\n",
      "id": "d59ce767-7c40-4118-8727-b48d3f6a592d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Run partitioned inference and insert predictions into table, optionally in batches\nprint(\"üöÄ RUNNING PARTITIONED INFERENCE AND SAVING TO TABLE (MODEL(..., PRODUCTION))\")\nstart_time = time.time()\n\ntotal_rows = input_df.count()\nprint(f\"üìä Input rows (after sampling if applied): {total_rows:,}\")\n\n# Same ORDER BY used for batching (keyset pagination) and for ROW_NUMBER in single-pass\nORDER_COLS = \"CUSTOMER_ID, WEEK, BRAND_PRES_RET, PROD_KEY\"\n\nif BATCH_SIZE is None:\n    # Inference without batching (single pass)\n    insert_predictions_sql = f\"\"\"\n    INSERT INTO {PREDICTIONS_TABLE}\n    (CUSTOMER_ID, STATS_NTILE_GROUP, WEEK, BRAND_PRES_RET, PROD_KEY, PREDICTED_UNI_BOX_WEEK, MODEL_VERSION)\n    SELECT\n        p.CUSTOMER_ID,\n        p.STATS_NTILE_GROUP,\n        p.WEEK,\n        p.BRAND_PRES_RET,\n        p.PROD_KEY,\n        p.predicted_uni_box_week,\n        '{model_version_name}' AS MODEL_VERSION\n    FROM INFERENCE_INPUT t,\n    TABLE(\n      MODEL({MODEL_FQN}, PRODUCTION)!PREDICT(\n        t.CUSTOMER_ID,\n        t.STATS_NTILE_GROUP,\n        t.WEEK,\n        t.BRAND_PRES_RET,\n        t.PROD_KEY,\n        t.SUM_PAST_12_WEEKS,\n        t.AVG_PAST_12_WEEKS,\n        t.MAX_PAST_24_WEEKS,\n        t.SUM_PAST_24_WEEKS,\n        t.WEEK_OF_YEAR,\n        t.AVG_AVG_DAILY_ALL_HOURS,\n        t.SUM_P4W,\n        t.AVG_PAST_24_WEEKS,\n        t.PHARM_SUPER_CONV,\n        t.WINES_LIQUOR,\n        t.GROCERIES,\n        t.MAX_PREV2,\n        t.AVG_PREV2,\n        t.MAX_PREV3,\n        t.AVG_PREV3,\n        t.W_M1_TOTAL,\n        t.W_M2_TOTAL,\n        t.W_M3_TOTAL,\n        t.W_M4_TOTAL,\n        t.SPEC_FOODS,\n        t.NUM_COOLERS,\n        t.NUM_DOORS,\n        t.MAX_PAST_4_WEEKS,\n        t.SUM_PAST_4_WEEKS,\n        t.AVG_PAST_4_WEEKS,\n        t.MAX_PAST_12_WEEKS\n      ) OVER (PARTITION BY t.STATS_NTILE_GROUP)\n    ) p\n    \"\"\"\n\n    session.sql(insert_predictions_sql).collect()\nelse:\n    # Inference in batches: each batch reads ONLY BATCH_SIZE rows via keyset pagination,\n    # so Snowflake never materializes the full table (avoids OOM with INFERENCE_SAMPLE_FRACTION=1).\n    num_batches = math.ceil(total_rows / BATCH_SIZE) if total_rows > 0 else 0\n    print(f\"üì¶ Running in batches of {BATCH_SIZE:,} rows ({num_batches} batch(es)) [keyset pagination]\")\n\n    # Keyset: (CUSTOMER_ID, WEEK, BRAND_PRES_RET, PROD_KEY) for \"next page\"\n    last_customer_id = None\n    last_week = None\n    last_brand_pres_ret = None\n    last_prod_key = None\n\n    for batch_idx in range(num_batches):\n        print(f\"   ‚ûú Batch {batch_idx + 1}/{num_batches}\")\n\n        # Build predicate so we only read this batch's rows (no full-table ROW_NUMBER)\n        if batch_idx == 0:\n            batch_filter = \"TRUE\"\n        else:\n            # (CUSTOMER_ID, WEEK, BRAND_PRES_RET, PROD_KEY) > (last, ...) for deterministic next page\n            parts = [\n                \"CUSTOMER_ID > COALESCE(NULLIF('{}', ''), '')\".format((last_customer_id or \"\").replace(\"'\", \"''\")),\n                \"(CUSTOMER_ID = '{}' AND WEEK > '{}')\".format((last_customer_id or \"\").replace(\"'\", \"''\"), (last_week or \"\").replace(\"'\", \"''\")),\n                \"(CUSTOMER_ID = '{}' AND WEEK = '{}' AND BRAND_PRES_RET > '{}')\".format((last_customer_id or \"\").replace(\"'\", \"''\"), (last_week or \"\").replace(\"'\", \"''\"), (last_brand_pres_ret or \"\").replace(\"'\", \"''\")),\n                \"(CUSTOMER_ID = '{}' AND WEEK = '{}' AND BRAND_PRES_RET = '{}' AND PROD_KEY > '{}')\".format((last_customer_id or \"\").replace(\"'\", \"''\"), (last_week or \"\").replace(\"'\", \"''\"), (last_brand_pres_ret or \"\").replace(\"'\", \"''\"), (last_prod_key or \"\").replace(\"'\", \"''\")),\n            ]\n            batch_filter = \"(\" + \" OR \".join(parts) + \")\"\n\n        insert_predictions_sql_batch = f\"\"\"\n        INSERT INTO {PREDICTIONS_TABLE}\n        (CUSTOMER_ID, STATS_NTILE_GROUP, WEEK, BRAND_PRES_RET, PROD_KEY, PREDICTED_UNI_BOX_WEEK, MODEL_VERSION)\n        WITH BATCH_PAGE AS (\n            SELECT *\n            FROM INFERENCE_INPUT\n            WHERE {batch_filter}\n            ORDER BY {ORDER_COLS}\n            LIMIT {BATCH_SIZE}\n        )\n        SELECT\n            p.CUSTOMER_ID,\n            p.STATS_NTILE_GROUP,\n            p.WEEK,\n            p.BRAND_PRES_RET,\n            p.PROD_KEY,\n            p.predicted_uni_box_week,\n            '{model_version_name}' AS MODEL_VERSION\n        FROM BATCH_PAGE t,\n        TABLE(\n          MODEL({MODEL_FQN}, PRODUCTION)!PREDICT(\n            t.CUSTOMER_ID,\n            t.STATS_NTILE_GROUP,\n            t.WEEK,\n            t.BRAND_PRES_RET,\n            t.PROD_KEY,\n            t.SUM_PAST_12_WEEKS,\n            t.AVG_PAST_12_WEEKS,\n            t.MAX_PAST_24_WEEKS,\n            t.SUM_PAST_24_WEEKS,\n            t.WEEK_OF_YEAR,\n            t.AVG_AVG_DAILY_ALL_HOURS,\n            t.SUM_P4W,\n            t.AVG_PAST_24_WEEKS,\n            t.PHARM_SUPER_CONV,\n            t.WINES_LIQUOR,\n            t.GROCERIES,\n            t.MAX_PREV2,\n            t.AVG_PREV2,\n            t.MAX_PREV3,\n            t.AVG_PREV3,\n            t.W_M1_TOTAL,\n            t.W_M2_TOTAL,\n            t.W_M3_TOTAL,\n            t.W_M4_TOTAL,\n            t.SPEC_FOODS,\n            t.NUM_COOLERS,\n            t.NUM_DOORS,\n            t.MAX_PAST_4_WEEKS,\n            t.SUM_PAST_4_WEEKS,\n            t.AVG_PAST_4_WEEKS,\n            t.MAX_PAST_12_WEEKS\n          ) OVER (PARTITION BY t.STATS_NTILE_GROUP)\n        ) p\n        \"\"\"\n\n        session.sql(insert_predictions_sql_batch).collect()\n\n        # Fetch last row of this batch to resume next batch (keyset)\n        last_row_df = session.sql(f\"\"\"\n            SELECT CUSTOMER_ID, WEEK, BRAND_PRES_RET, PROD_KEY\n            FROM INFERENCE_INPUT\n            WHERE {batch_filter}\n            ORDER BY {ORDER_COLS}\n            LIMIT {BATCH_SIZE}\n            OFFSET {BATCH_SIZE - 1}\n        \"\"\").collect()\n        if last_row_df and len(last_row_df) > 0:\n            row = last_row_df[-1]\n            last_customer_id = str(row[\"CUSTOMER_ID\"]) if row[\"CUSTOMER_ID\"] is not None else None\n            last_week = str(row[\"WEEK\"]) if row[\"WEEK\"] is not None else None\n            last_brand_pres_ret = str(row[\"BRAND_PRES_RET\"]) if row[\"BRAND_PRES_RET\"] is not None else None\n            last_prod_key = str(row[\"PROD_KEY\"]) if row[\"PROD_KEY\"] is not None else None\n        else:\n            break\n\nelapsed = time.time() - start_time\n\npredictions_df = session.table(PREDICTIONS_TABLE).filter(\n    F.col(\"MODEL_VERSION\") == model_version_name\n)\npredictions_count = predictions_df.count()\nprint(f\"‚úÖ {predictions_count:,} predictions saved to {PREDICTIONS_TABLE} in {elapsed:.2f}s (MODEL(..., PRODUCTION))\")\nprint(f\"   Model version: {model_version_name}\")\npredictions_df.order_by(\"PREDICTION_ID\").show(10)\n",
      "id": "62efe11f-1ab1-47b9-ae2e-abc8f7225e31",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## (Optional) Sample Inference via Registry + PRODUCTION (Python/pandas)\n#\nUseful for debugging, quick validation or inspecting model output\ndirectly in Python, using the same version labeled as PRODUCTION.\n",
      "id": "2464614b-996d-4adf-938d-d48a6f7fc8f2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(\"\\nüîç OPTIONAL: SAMPLE PREDICTION VIA REGISTRY (PRODUCTION)\")\n\ntry:\n    # Create Registry pointing to the same database/schema of models\n    registry = Registry(\n        session=session,\n        database_name=DATABASE,\n        schema_name=MODEL_SCHEMA,\n    )\n\n    # Get the model and select the PRODUCTION version\n    model_ref = registry.get_model(PARTITIONED_MODEL_NAME)\n    model_version = model_ref.version(\"PRODUCTION\")\n    # Use force=True to skip package version validation if local environment differs\n    local_model = model_version.load(force=True)\n\n    # Take a small sample of input to avoid loading everything into memory\n    sample_sp = input_df.limit(100)\n    sample_pdf = sample_sp.to_pandas()\n\n    # Execute local prediction using CustomModel (PartitionedUniBoxModel)\n    sample_pred_pdf = local_model.predict(sample_pdf)\n\n    print(\"‚úÖ Sample prediction via Registry (PRODUCTION) completed\")\n    print(sample_pred_pdf.head())\nexcept Exception as e:\n    print(f\"‚ÑπÔ∏è  Skipping optional local prediction via Registry: {e}\")\n    print(\"   Note: This requires local installation of model dependencies (lightgbm, xgboost, etc.)\")\n    print(\"   The main SQL-based inference above works without these local dependencies.\")\n",
      "id": "03bad736-4098-412c-b821-30fb63d32cc6",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}